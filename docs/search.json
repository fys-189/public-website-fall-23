[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SDS 189: Data and Social Justice",
    "section": "",
    "text": "Data is a powerful tool for making claims - claims that can advance equity and social justice, as well as claims that can misrepresent civic issues and marginalize communities. This course examines how power operates in and through the production, analysis, and presentation of data, while helping students develop skill in approaching data science work in more ethical and equitable ways.\nIn this course, students will examine the socio-political forces that impact the availability, structure, and governance of data regarding various social justice issues. Students will also learn techniques for presenting data in ways that foreground the contexts of data production and remain accountable to diverse communities. Datasets about health equity, housing justice, environmental justice, and carceral justice will be studied, analyzed, and visualized. In doing so, students will learn to identify the diverse institutions and stakeholders involved in data production, unpack the cultural histories and vested interests animating data semantics, consider what people and problems gets erased in data structuring, and evaluate the ethical tradeoffs that data scientists grapple with as they plan for the presentation of data.\n\n\n\n\nCommunicate how cultural, political, and technical forces shape the collection, categorization, presentation, and publication of data\nExamine data semantics and the power-laden semiotic systems from which they emerge\nRecognize how diverse data manipulation and visualization techniques applied to the same dataset can produce competing claims and evaluate which techniques best align with advancing social justice and equity\nProduce data visualizations that foreground the contexts of data production and demonstrate accountability to the people represented by the numbers\n\nClasses will be held on Tuesdays and Thursdays from 1:20 PM to 2:35 PM.\n\n\n\n\n\n\n\n\n\nLindsay Poirier, she/her/hers.\n\n\n\n\n\nI am a cultural anthropologist that studies how civic data gets produced, how communities think about and interface with data, and how data infrastructure can be designed more equitably. My Ph.D. is in an interdisciplinary discipline called Science and Technology Studies - a field that studies the intricate ways science, technology, culture, and politics all co-constitute each other. I work on a number of collaborative research projects that leverage public data to deepen understanding of social and environmental inequities in the US, while also qualitatively studying the politics behind data gaps and inconsistencies. As an instructor, I prioritize active learning and often structure courses as flipped classrooms. You can expect in-class time to predominantly involve group activities and live problem-solving exercises.\n\n\n\nSlackMeeting with Me\n\n\nI can best support students in this course when I can readily keep tabs on our course-related communication. Because of this, I ask that you please don’t email me regarding course-related questions or issues. The best way to get in touch with me is via our course Slack. If you have course-related questions, I encourage you to ask them in the #fys-189-questions channel. When discretion is needed, feel free to DM. Please reserve more formal concerns like grades or accommodation requests for an in-person (or in-person virtual) conversation.\nDuring the week, I will try my best to answer all Slack messages within 24 hours of receiving them. Please note that to maintain my own work-life balance, I often don’t answer Slack messages late in the evenings or on the weekends. It’s important that you plan when you start your assignments accordingly.\n\n\nMeeting with me outside of class is a great opportunity for us to chat about what you’re learning in the course, clarify expectations on assignments, and review work in progress. I also love when students drop in to office hours to request book recommendations, discuss career or research paths, or just to say hi!\nThere are two ways to meet with me. If you would like to have a one-on-one private conversation, I ask that you schedule an appointment with me via the booking form on Moodle. For support on class topics, you may drop-in during my regularly scheduled office hours.\n\nMonday, 11-12, McConnell 214\nTuesday, 11-12, McConnell 214\n\n\n\n\n\n\n\n\nI will make all course readings available on Perusall, which can be accessed through our course Moodle page.\n\n\n\nThis course will be graded via a grading contract.\n\n\n\n\n\n\nJacobson Center\n\n\n\nSmith’s Jacobson Center asserts that all students can improve their communication and learning skills. I encourage all students to take advantage of their writing support services, workshops, and tutors.\n\n\n\n\n\n\nPreparationAttendanceExtensionsAcademic HonestyParticipationReadings\n\n\nThis is a 4-credit course with 3 hours per week of in-classroom instructions. Smith expects students to devote 9 out-of-class hours per week to 4-credit classes. I have designed the course assignments and selected the course readings with this target in mind.\n\n\nAttending class is not only important for your learning but also an act of community. Many course assignments will be completed in-class, and many critical thinking skills will be honed in class.\nAttendance will be taken in the first 10 minutes of each class. You may miss three classes with no penalty. You do not need to inform me that you will be absent in these cases. After the third unexcused absence, your grade may drop by a modifier for each class missed. Students arriving more than 10 minutes late for class without having informed me ahead of time will be marked as absent.\nIf you must miss a class entirely, you should contact a peer to discuss what was missed. Please note that the SDS Program has adopted a shared policy regarding in-person attendance this semester:\n\nIn keeping with Smith’s core identity and mission as an in-person, residential college, SDS affirms College policy (as per the Provost and Dean of the College) that students will attend class in person. SDS courses will not provide options for remote attendance. Students who have been determined to require a remote attendance accommodation by the Office of Disability Services will be the only exceptions to this policy. As with any other kind of ADA accommodations, please notify your instructor during the first week of classes to discuss how we can meet your accommodations.\n\n\n\nI understand that you will sometimes need to prioritize other things over meeting assignment deadlines (e.g. your health, wellness, families, communities, jobs, other coursework). There is a 24-hour grace period on all written assignments. There will be no penalties for submitting the written assignment within this 24-hour period, and you do not need to inform me that you intend to take the extra time. You can also request up to a 72-hour extension on any written assignment, as long as you make that request at least 48 hours before the original assignment due date. You can request an extension by filling out the Extension Request form on Moodle, and I will confirm your extension on Slack. Beyond this, late assignments will not be accepted.\nNote that this policy does not apply to reading assignments/Perusall annotations. Reading assignments/Perusall annotations need to be completed by the due date for credit.\n\n\n\nSmith College expects all students to be honest and committed to the principles of academic and intellectual integrity in their preparation and submission of course work and examinations. Students and faculty at Smith are part of an academic community defined by its commitment to scholarship, which depends on scrupulous and attentive acknowledgement of all sources of information, and honest and respectful use of college resources. Any cases of dishonesty or plagiarism will be reported to the Academic Honor Board. Examples of dishonesty or plagiarism include:\n\n\nSubmitting work completed by another student as your own.\nCopying and pasting words from sources without quoting and citing the author.\nParaphrasing material from another source without citing the author.\nFailing to cite your sources correctly.\nFalsifying or misrepresenting information in submitted work.\nPaying another student or service to complete assignments for you.\nSubmitting work generated by artificially intelligent tools such as chatGPT\n\n\n\nActive participation in this course is generally expected and encouraged. That said, we all have off-days - be it from illness, sadness, heartbreak, or exhaustion. I too will have off-days where my words just don’t seem to cohere, or my brain will feel jumbled. Because of this, I’ve provided a number of ways to demonstrate engagement throughout the semester.\n\n\nI have put a lot of thought into the assigned readings for this course - aiming to select pieces that are relevant, engaging, challenging, accessible, and represent a diverse set of voices. Our classroom discussions will be much richer, more meaningful, and fun when all students come to class having completed and annotated assigned course readings. While I know that reading may seem like a low priority when you have impending assignments that you need to physically hand-in, I encourage you not to wait until the last minute to complete course readings. You will get the most out of the content if you give yourself time to digest and reflect on it.\nIf you are struggling to keep up with the readings, please reach out to me. I’m more than happy to talk through effective reading strategies and to provide more guidance on what I’d like you to get out of a specific piece.\n\n\n\n\n\n\n\nCode of ConductPrinciples of CommunityPronouns\n\n\nAs the instructor for this course, I am committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor I have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students and the instructor are expected to adhere to this Code of Conduct in all settings for this course: seminars, office hours, and over Slack.\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here.\n\n\nI hope that we can foster a collaborative and caring environment in this classroom: one that celebrates successes, respects individual strengths and weaknesses, demonstrates compassion for each other’s struggles, and affirms diverse identities. Here are some ideas that I have for creating this environment in our course:\n\nCheck-in with colleagues before starting collaborative work. “What three words describe how you’re feeling?” “Name one challenge and one success from this week.” “What are you doing for self-care right now?” Thank each other for sharing where they’re at.\nConsider when to step up and when to step back in class discussions, creating space for others to contribute. Listening is just as important to community-building as speaking.\nAcknowledge that there is much we don’t know about how our colleagues experience the world. …but don’t ask colleagues to speak on behalf of a social group you perceive them to be a part of.\nCheer on colleagues as they give presentations or try something out for the first time.\nAsk questions often in our #fys-189-questions channel. Help each other out by answering questions when you can.\nMistakes happen. I will certainly make mistakes in class. Admit mistakes, and then move on.\n\n\n\nUsing the proper pronouns for our students is foundational to a safe, respectful classroom environment that creates a culture of trust. For information on pronouns and usage, please see the Office of Equity and Inclusion link here: Pronouns\n\n\n\n\n\n\n\nAccommodationsStudent Well-beingTrigger Warnings\n\n\nIt is my goal for everyone to succeed in this course. If you have personal circumstances that may impact your experience of our classroom, I encourage you to contact Office of Disability Services in College Hall 104 or at ods@smith.edu. The Office will generate a letter that indicates to me what kind of support you need and how I can make your classroom experience more accommodating. Once you have this letter, you are welcome to visit my office hours or email me to discuss ideas about how we can tailor the course accordingly. While you can request accommodations at any time, the sooner we start this conversation, the better. If you have concerns about the course that are not addressed through ODS, please contact me. At no point will I ask you to divulge details about your personal circumstances to me.\n\n\nCollege life is stressful, and life outside of college can be overwhelming. It is my position that attending to your physical and mental health and well-being should be a top priority. I will remind you of this often throughout the semester. I encourage you to schedule a time to talk with me if you are struggling with this course. If you, or anyone you know, is experiencing distress, there are numerous campus resources that can provide support via the Schacht Center. I can point you to these resources at any time throughout the semester.\n\n\nA trigger is a topic or image that can precipitate an intense emotional response. When common triggering topics are to be covered in this course, I will do my best to provide a trigger warning in advance of the discussion. However, I can’t always anticipate triggers. With this in mind I’ve set up an anonymous form, available on Moodle, where you can indicate topics for which you would like me to provide a warning.\n\n\n\n\n\n\n\nMoodlePerusallSlack\n\n\nGrades, forms, and handouts will be available on the course Moodle.\n\n\nAll course readings and recorded lectures will be available on Perusall. You can access Perusall via our course Moodle page.\n\n\n\n#general: Course announcements (only I can post)\n#fys-189-discussions: Share news articles and relevant opportunities\n#fys-189-questions: Ask and answer questions about our course"
  },
  {
    "objectID": "learning_dimensions.html",
    "href": "learning_dimensions.html",
    "title": "Learning Dimensions",
    "section": "",
    "text": "This course is designed to assess your work along five different learning dimensions. Class activities and assignments will reference the learning dimensions engaged, so that you have a clear understanding of what you should take-away from them. Additionally, you may be asked to reference aspects of these learning dimensions in written assignments. The five learning dimensions are as follows:\n\nKnowledge and Understanding\nThis dimension refers to the development of your ability to recall, define, explain, apply, and synthesize course concepts and ideas. Primary course concepts include:\nEPISTEMOLOGY DISCOURSE TRANSLATION INFRASTRUCTURES LABOR RITUALS INCENTIVES MOBILIZATION CREDIBILITY IGNORANCE POWER\n\n\nData Ethnography Methods\nThis dimension refers to the development of your ability to identify, implement, and critique the research methods taught in this course. Principal methods taught in this course include:\nDISCOURSE ANALYSIS INTERVIEWING CULTURAL ANALYSIS OF INFRASTRUCTURE PARTICIPANT OBSERVATION\n\n\nSkills and Competencies\nThis dimension refers to the development of your ability to execute and evaluate further opportunities for growth in the skills and competencies engaged in this course. Skills practiced in this course include:\nVERSION CONTROL IN GITHUB AUTHORING RMARKDOWN THICK DESCRIPTION DATA DOCUMENTATION REVISION WRITING IN GENRE\n\n\nCritical Thinking\nThis dimension refers to the development of your ability to perceive the world in new ways, interpret cultural meaning and import, situate your own perspectives, communicate complexity, and grapple with issues that don’t have easy solutions. Critical modes of thinking engaged in this course include:\nBECOMING OBSERVANT INTERPRETING CULTURAL MEANING ANALYZING SOCIAL FORCES AND SYSTEMS SITUATING KNOWLEDGE COMMUNICATING (IN) CONTEXT EVALUATING ETHICAL DILEMMAS\n\n\nCollective Thinking and Collaborative Engagement\nThis dimension refers to the development of your ability to recognize a diversity of perspectives, learn from others, and contribute to the functioning of a reflective, collaborative learning environment. Opportunities for cooperative engagement include:\n\nConsistently contributing to Slack discussions\nSubmitting thoughtful, critical reflections in Perusall\nFostering discussion in the classroom\nEnsuring equitable divisions of labor and support among final project group members"
  },
  {
    "objectID": "slides/Day19-Mobilization.html",
    "href": "slides/Day19-Mobilization.html",
    "title": "Day Nineteen: Mobilization",
    "section": "",
    "text": "What is evidence?\n\nEtymologically dual meaning:\n\nTransparent, obvious, clear, speaking for itself\nAppearance or indication, requiring interpretation\n\n\n\nBiruk, Cal. 2018. Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books.\n\n\nclass: center, middle # How does evidence get talked about in the media, politics, and society?\n\nclass: center, middle # How do words get their meanings? How did the word ‘she’ acquire meaning? What are some examples of words that have undergone social change in the last five years? How might we map the cultural shifts and social institutions shaping language?\n\nclass: center, middle # On Nov 8, 2022 at 11PM Northampton’s reported AQI was 95.\n\nclass: center, middle # “27 percent of the French population smoke a cigarette every day.”\n\nclass: center, middle # How do numbers acquire meaning? Through what means do we determine their significance?\n\n\n\nFraming Statistics\n\nComparison/Ranking\n\nIs x more/less than y?\n\nStandards-Setting/Benchmarking\n\nDoes x meet z standard/benchmark?\n\nAppealing to Emotion/Lived Experience\n\nHow does x make me feel/relate to my life?\n\n\n\n\n\nMobilizing Data\n\nStrategizing and engaging in the circulation of data\nMeaning-making involves socio-cultural work\nData can have “interpretive flexibility”\n\nDifferent social groups assign different meaning to data.\nExample: “I ran 20 minutes this morning.”\n\n\n\nclass: center, middle # “The actual number of Americans jailed or imprisoned, about 2.3 million.” - Matt Korostoff\n\nhttps://mkorostoff.github.io/incarceration-in-real-numbers/"
  },
  {
    "objectID": "slides/Day22-Credibility.html",
    "href": "slides/Day22-Credibility.html",
    "title": "Day Twenty-Two: Credibility",
    "section": "",
    "text": "class: center, middle # Turn to a neighbor and discuss: What makes science separate from other features on the map? Can you think of stakeholders who might disagree with your map of science? Why?\n\n\nBoundary Work\n\nThomas Gieryn, Cultural Cartographies of Science\nAcknowledges the lack of stable criteria for demarcating science from non-science.\nDifferent people justify what makes something scientific vs unscientific differently.\nAs credibility contests emerge, people make claims based on their own maps of science.\nCulturally chart the boundaries around what we consider scientific.\n\n\nclass: center, middle # Science is a symptom of the legitimate power to decide reality - its edges and contents disputed, moved all over the place, settled here and there as decisions about truthful and reliable claims are acted upon … (Gieryn, Cultural Boundaries of Science)\n\nclass: center, middle # How do we draw the boundaries of credibility in data work? Who gets seen as a legitimate claims-maker in data science work, and whose voices are often denied a seat at the table?\n\n\n\nExample: Lois Gibbs and Love Canal\n\n\n\n\n\nDeficit Model\n\nBelief that the reason people distrust science is because they lack knowledge\nOften casts scientific illiteracy as both a technical problem and a moral problem\nPresumed solution to increasing public trust in science is to teach more science\n\n\nSTS rejects the deficit model…\n\n\nIgnores public’s situated knowledge\nSuggests knowledge is context-free\nDoesn’t get at the root of distrust\n\n\nclass: center, middle # How do we decide who is considered to have expertise?\n\n\n\nEnactments of Expertise\n.pull-left[\n\nExpertise as a signal of authority\nEnacted through credentialing, use of certain vocabularies, creation of exclusive social circles, clothing, norms of behavior\nEnactments also serve a gate-keeping role in determining who gets to contribute to science/data science ]\n\n.pull-right[\nIn her history of the medical activism by the Black Panthers, Alondra Nelson discusses how one way the Black Panthers enacted their expertise was in their choice to wear white lab coats.\n > Sickle cell anemia testing. Oakland, Calif. 1972. credit NY Times\n]\n\n\n\nCitizen Science\n\nExclusionary science as a democratic problem\nExamples of citizen engagement:\n\nCounting declining bird populations\nAir and water quality monitoring\nWriting health books for underrepresented populations\n\nMust learn how to enact expertise to earn a seat at the table\n\n\n\n\nSocial Movement Theory\n\nSociological research that studies how social movements form, operate, sustain, and fizzle out\nPolitical Process Theory: suggests that certain political formations enable social movements to form and operate\nResource Mobilization Theory: suggests that access to certain resources enable social movements to mobilize\nFraming: Suggests that collective ideologies and values bring social movements into fruition"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html",
    "href": "slides/Day4-BinaryOppositions.html",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "",
    "text": "Turn to your neighbor and discuss:\n\nWhat data discourses are the words you wrote on the left side embedded within?\nCan you identify any terms that might fit in between these opposites?\n\n\n\n\nBinary Oppositions\n.pull-left[ * Looking at the world through pairs of terms that we consider to have the opposite meaning * Examples include: * Real/fake * Objective/subjective * Nature/culture * Binary oppositions are reductionist, or oversimplify complexity * Binary oppositions are rooted in ideologies and disseminated through discourse]\n.pull-right[\n ]\n\n\n\nHierarchies in Binary Oppositions\n.pull-left[ * In dominant discourse, one half of a binary opposition tends to be positioned as superior than the other * One half tends to get treated as normal or pure, and other as a deviation from the normal, or tainted * Binary oppositions can reinforce privilege * What are some examples of some hiearchical binary oppositions?]\n.pull-right[\n ]\n\n\n\nNature/Culture\n\nCountless domains (disciplines, newspaper headings, etc.) organized around the divisions between nature and culture\nNature is often associated with purity, innateness, biology, or rawness.\nCulture is seen as ‘Other’ to what is natural\n\ne.g. human judgments bias science and decision-making\ne.g. human cultures destroy the Earth’s purity\n\nFeminist critiques:\n\nShows how purity is political\nArgues that we can’t tell where nature stops and culture starts\nShows how the divisions justify treating certain social groups as superior and others as inferior\nRefers to natureculture: hybrids reverse the logic of binary oppositions\n\n\n\nclass: center, middle # What are some of the discursive risks of talking about raw data?\n\n\n\n\nGood\nBad\n\n\n\n\nRaw\nCooked\n\n\nClean\nDirty\n\n\nObjective\nSubjective\n\n\nTransparent\nOpaque\n\n\nRigid\nLoose\n\n\nNeat\nScruffy\n\n\nNeutral\nPartial\n\n\nScientific\nPolitical\n\n\nCertain\nUncertain\n\n\nObserved\nInterpreted\n\n\nReal\nConstructed\n\n\nUnbiased\nBiased\n\n\nAccurate\nInaccurate\n\n\n\n\nclass: center, middle # How do the metaphors discussed in this week’s reading map on to these binary oppositions?\n\n\n\nActivity\n\n\n\n\n\n\n\nclass: center, middle # What were three takeaways from today?\n\n\n\nFor Monday\n\nNotes on ethnography readings\nMerge your branch into main.\nLet me know if you’d like to lead a class discussion\nCATME survey"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html",
    "href": "slides/Day9-DataDocumentation.html",
    "title": "Day Nine: Data Documentation",
    "section": "",
    "text": "class: center, middle # How do we define metadata?\n\n\n5 W’s of Metadata\n\n\nclass: center, middle # Why is metadata important?\n\n\n\nExample: Library Catalog\n.pull-left[ ]\n.pull-right[ ]\n\n\n\nMetadata Schemas\n\nA standardized labeling system for cataloging or describing data\nEnables search engines to index data by certain criteria\nExamples:\n\nSort by “date created”\nRetrieve all results from a specific “author/creator”\nFilter results to a specific “subject”\nExclude results from a specific “publisher”\n\n\n\n\n\nExample: Citation Manager\n.pull-left[ ]\n.pull-right[ ]\n\n\n\nExample: Citation Manager\n\n\nclass: center, middle # What’s the difference between administrative and descriptive metadata?\n\n\n\n\n\nData Dictionaries\n\nDocuments for holding descriptive metadata\nDefine the variables in a dataset and the values that may fill in those variables\nAre not always as descriptive as we’d like them to be\n\n\nclass: center, middle # Example: NYC Metadata for All\n\n\n\n\nFor Monday\n\nQuestions to consider:\n\nWhat does Biruk mean when they refer to “translation” in this chapter?\nWhere do we see looping effects in this chapter? What gets “lost in translation”?"
  },
  {
    "objectID": "slides/Day23-Ignorance.html",
    "href": "slides/Day23-Ignorance.html",
    "title": "Day Twenty-Three: Data Agnotology",
    "section": "",
    "text": "Feminist arguments on the study of ignorance\n\nIgnorance is more than a gap in knowledge.\n“Ignorance, like knowledge, is situated.”\n\n\nTuana, Nancy. 2006. “The Speculum of Ignorance: The Women’s Health Movement and Epistemologies of Ignorance.” Hypatia 21 (3): 1–19. https://doi.org/10.1111/j.1527-2001.2006.tb01110.x.\n\n\n\n\nFeminist Epistemologies\n.pull-left[\n\nAll knowledge is embodied\nBodies are situated in certain social positions and have a finite point of view (Haraway 1991)\nKnowledge is tied to particular standpoints\nStronger objectivity achieved by diversifying standpoints ]\n\n.pull-right[ \n]\n\n\n\nTaxonomy of Ignorance\n\nEngineered Ignorance\nUndone Science\nOrganized Ignorance\nLoving Ignorance\n\n\nclass: center, middle # Engineered ignorance: Knowledge that gets deliberately hidden from the public\n\n\n\nBig Tobacco Hides Cancer Risks\n\nEarly 1950s, considerable expansion of research on tobacco health risks (e.g. lung cancer)\nTobacco industry seeks to produce knowledge that will undo effects of emerging research:\n\nEnlisted public relations firm Hill & Knowlton\nDetermined that advertising won’t work because self-interested by definition\nSought out credentialed medical skeptics to engineer controversy\nCreated Tobacco Industry Research Committee and funded research to sew doubt/uncertainty\n\n\n\n.pull-left[ ] .pull-right[\n\n]\n\n\n\nMerchants of Doubt\n\n\n\nclass: center, middle # Undone science: Areas of research that go unfunded, left incomplete, or get ignored\n\nFrickel, Scott, Sahra Gibbon, Jeff Howard, Joanna Kempner, Gwen Ottinger, and David J. Hess. 2010. “Undone Science: Charting Social Movement and Civil Society Challenges to Research Agenda Setting.” Science, Technology & Human Values 35 (4): 444–73. https://doi.org/10.1177/0162243909345836.\n\n\n\n\nMedical Funding\n\nNature reports that much medical funding goes to the “big three” - HIV/AIDS, malaria and tuberculosis\nFunding diverted away from “neglected tropical diseases”\n\nImpact billions of people and disproportionately impact most vulnerable populations\nExamples: dengue, leprosy, trachoma\n\nCovid-19 further diverted funding from these programs\n\n\n\n\nOur Bodies Ourselves\n\n\n\nTuana, Nancy. 2006. “The Speculum of Ignorance: The Women’s Health Movement and Epistemologies of Ignorance.” Hypatia 21 (3): 1–19. https://doi.org/10.1111/j.1527-2001.2006.tb01110.x.\n\n\nclass: center, middle # Organized Ignorance: Knowledge that doesn’t get produced because of the way science is organized\n\nFrickel, Scott, and M. Bess Vincent. 2007. “Hurricane Katrina, Contamination, and the Unintended Organization of Ignorance.” Technology in Society, Perspectives on Hurricane Katrina, 29 (2): 181–88. https://doi.org/10.1016/j.techsoc.2007.01.007.\n\n\n\n\nEnvironmental Testing following Hurricane Katrina\n\nOnly test contaminants designated by law (<200 of 8200 in TSCA) on public properties\nTend to test where there was flooding, not where there may be the most contaminants\n\nMost serious flooding escaped “sliver along the river” - location of the city’s industrial corridor\nUntested areas include several brownfields and areas with history of manufacturing expansion\n\n\n\n\n\nColony Collapse Disease\n\nUS beekeepers have lost almost 1/3 of bees every year since 2006\nScientific studies of insecticides on bees were designed to test the individual lethal effects of a chemical on a bee population\n\nPart of a “control-oriented” scientific culture\n\nFailed to account for slow, cumulative effects over time and the interactions of chemicals and pathogens\n\n\nKleinman, Daniel Lee, and Sainath Suryanarayanan. 2013. “Dying Bees and the Social Production of Ignorance.” Science, Technology & Human Values 38 (4): 492–517. https://doi.org/10.1177/0162243912442575.\n\n\nclass: center, middle # Ignorance as humility, or loving ignorance"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html",
    "href": "slides/Day8-ResearchEthics.html",
    "title": "Day Eight: Research Ethics",
    "section": "",
    "text": "class: center, middle # Quick note about reading for this course.\n\n\nI encourage you to come to office hours if…\n\nYou’d like to discuss strategies for managing the reading/workload.\nYou’d like clarifications on any of the assignment expectations/course infrastructure.\nYou’d like to review certain concepts discussed in lecture or the readings.\nYou’d like to chat about opportunities for exploring more about data ethnography.\nYou’re stressed and need some positive affirmation.\n\n\nclass: center, middle # What were some takeaways from Monday’s class?\n\n\n\nCommon Rule\n\nIn the US, research organizations receiving federal funding are subject to the Common Rule\n\nLaws and regulations regarding how Institutional Review Boards are to operate\nIRBs are organizational bodies that review the ethics of human subjects research in order to protect human welfare, rights, and privacy before a study gets carried out\n\nUsually composed of representatives from an institution with a diverse background\n\n\n\n\nTuskegee Study\n\nConducted from 1932 to 1972 by US Public Health Services and Center for Disease Control, in collaboration with Tuskegee University in Alabama\nInvolved 400 African Americans with syphilis\nStudy of leaving the disease untreated even though it was treatable\n\nWere told they would receive free medical care\nNever informed of their diagnosis\nProvided with placebos and ineffective methods\n\n\n\n\n\nFacebook’s Emotional Contagion Study\n\nJanuary 2012, Facebook data scientists manipulated what 700,000 users saw on feeds to examine emotional contagion\n\nSome shown happy, positive content\nOthers shown sad, negative content\n\nLegal?\nEthical?\n\n\n\n\nEthics of ethnographic research\n\nEthnography different than many other forms of human subjects research in that it takes place in natural settings vs in clinical settings\nQuestion of how to balance benefits of the research with the potential harms posed to the participants\nPotential harms:\n\nReputation\nDisclosure of personal information\nDisruption of relationships\nLoss of claims\n\n\n\nclass: center, middle # What about informed consent in virtual spaces?\n\nclass: center, middle # What about informed consent in virtual spaces?\n\nclass: center, middle # Dataset Review in Project Groups\n\nclass: center, middle # What were three takeaways from today?\n\n\n\nFor Monday\n\nGet approval for dataset\nReadings:\n\nWhy does good data documentation matter?"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html",
    "href": "slides/Day6-Reflexivity.html",
    "title": "Day Six: Reflexivity",
    "section": "",
    "text": "Turn to your neighbor and discuss:\n\nWhy would it be important to consider these aspects of your cultural identity as you engaged in ethnographic fieldwork?\n\n\nclass: center, middle # What are Biruk’s research questions?\n\n\nHow do raw units of information - numbers written onto a questionnaire by data collectors - acquire value as statistics that inform national AIDS policy and interventions?\n\n\nHow do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\n\n\nFinally, how are quantitative health data and their social worlds co-produced and with what consequences for local economies, formulations of expertise, and lived experience?\n\n\nclass: center, middle # What does Biruk make known about her assumptions/beliefs/values as she begins to interpret data?\n\n\n\nCritiques and Criticisms of Ethnographic Research\n\nEthnographic research (like many other forms of research) has been historically complicit in imperialism and colonialism\nMethods emerged as part of European colonial efforts to document folks “Native” to “other” lands - often to enable control and exploitation of those cultures\nMany binary oppositions indicate how power operated here:\n\nStudier/studied\nResearcher/researched\n\nConcerns over who gets to “write culture”\n\n\n\n\nReflexive Turn\n\nEmerged in the 1970s as a result of feminist and post-colonial critiques\n\nFeminist: Where do we stand? Can we ever observe from an objective or neutral place?\nPost-colonial: What do we consider “Other,” and how do we portray what is “Other”?\n\nCalled on ethnographers to engage in self-reflection (standpoints, assumptions, etc.)\nCan we write another culture “objectively” when our own biases and epistemologies, and social capital are inevitably involved in the research?\n\n\n\n\n…aka the Literary Turn\n\nEthnography was often understood to be about writing (documenting observations and interpreting them)\nBegan to pay attention to power in the language used to “write culture”\n\nBinary oppositions\nGenre and representations of “fact”\n\nCalled for making ethnographic writing more polyphonous (or represent a plurality of voices)\nSometimes invited “poetics” and “experimentalism”\n\n\nIn other words, there are political reasons as to why the fieldnotes that you read for Monday felt different than other scientific genres!\n\n\n\n\nReflexivity for Each of our Methods\n\nParticipant Observation\n\nObserving interaction and behaviors “in the field”\n\nInterviewing\n\nEngaging in semi-structured conversations with informants\n\nArchival Research\n\nCurating and interpreting historical documents and artifacts\n\nDiscourse analysis\n\nInterpreting the cultural meaning interwoven in texts and speech\n\n\n\nIn your groups, be sure to introduce yourselves to each other (pronounds, majors, etc.)\n\n\n\n\nInfrastructure Overview\n\nGroup project\nFirst fieldnote\nReview of labor log\n\n\nclass: center, middle # What were three takeaways from today?\n\n\n\nFor Monday\n\nComplete group contract\nQuestions to consider:\n\nWhat are looping effects, how do they emerge, and why should we pay attention to them?\nWhat are data assemblages, and why is “assemblage” a powerful concept for understanding data?"
  },
  {
    "objectID": "slides/Day7-Looping.html",
    "href": "slides/Day7-Looping.html",
    "title": "Day Seven: Data Looping Effects",
    "section": "",
    "text": "Turn to your neighbor and discuss:\n\nWhy does this category or label exist?\nIn what ways has this category or label been normalized in society?\nWhat happens when folks don’t agree with the assignment? Can they contest it?\n\n\n\n\nAssemblages\n\nContests the idea that data are hard, shiny objects that can be held, acquired, etc.\nWhen we talk about data, we are actually referring to many interrelated things:\n\nMaterialities, practices, subjectivities, places, governmentalities, etc.\nSee table in this week’s reading\n\n“Data” emerges in the wake of these interrelated assemblages\n\n\n\n\nHacking’s Looping Effect\n > Tekin, Serife. 2014. “The Missing Self in Hacking’s Looping Effect.” In Classifying Psychopathology: Mental Kinds and Natural Kinds, edited by Harold Kincaid and Jacqueline A. Sullivan. MIT Press.\n\n\n\n\nclass: center, middle # What were three takeaways from today?\n\n\n\nFor Monday\n\nComplete group contract\nQuestions to consider:\n\nWhat does Biruk mean when they refer to “translation” in this chapter?\nWhere do we see looping effects in this chapter? What gets “lost in translation”?"
  },
  {
    "objectID": "slides/Day20-EthnographicArguments.html",
    "href": "slides/Day20-EthnographicArguments.html",
    "title": "Day Twenty: Ethnographic Arguments",
    "section": "",
    "text": "What is an ethnographic argument?\n\nCentral theme derived from an ethnographic study\nIdentifies a certain cultural pattern or phenomena\nExamples:\n\nHow data is talked about\nThe cultural assumptions underpinning a data infrastructure\nHow labor is recognized in a data practice\n\n\n\n\n\nWriting an Ethnographic Argument\n\nParagraph 1: Introduction and thesis\nParagraph 2-x: Sub-arguments supporting thesis\n\nPresents evidence from data collection to support sub-argument\n\nParagraph Final: Summarize thesis and wrap-up\n\n\n\n\nWhat counts as evidence/data in ethnographic arguments?\n\nDiscourse Analysis/Interview\n\nDirect quotes and their context\n\nParticipant Observation\n\nVignettes/thick description\n\nCultural Analysis of Infrastructure\n\nMaterial from secondary sources\nFacts about the infrastructure’s historical development\nDescriptions of the organization of the infrastructure\n\n\n\n\n\nRevision Expectations\n\nRevision = re - vision = seeing again\nInvolves more than spelling and grammar fixes and word changes; editing is only one component of revision\nThings to consider:\n\nRecognize and re-articulate the purpose\nRefine the focus (audience and presentation)\nClarify the argument\nStrengthen and hone evidence\n\n\n\nhttps://writingcenter.unc.edu/tips-and-tools/revising-drafts/"
  },
  {
    "objectID": "slides/Day1-Intro.html#what-is-ethnography",
    "href": "slides/Day1-Intro.html#what-is-ethnography",
    "title": "Day One: Introductions",
    "section": "What is ethnography?",
    "text": "What is ethnography?\n\nstudy of human culture and social relations\ninvolves interactions and observations, recording, and analysis\ndata collection methods are predominantly qualitative\nanalysis is predominantly inductive and interpretive"
  },
  {
    "objectID": "slides/Day1-Intro.html#what-fields-of-research-inform-data-ethnography",
    "href": "slides/Day1-Intro.html#what-fields-of-research-inform-data-ethnography",
    "title": "Day One: Introductions",
    "section": "What fields of research inform data ethnography?",
    "text": "What fields of research inform data ethnography?\n\nScience and Technology Studies (STS)\n\nan interdisciplinary field that examines how science, technology, politics, and culture all co-produce each other\nSTS disciplines include anthropology, sociology, literary studies, political science, economics, and more\nWhat might be some examples?\n\nCritical Data Studies\n\nan interdisciplinary field examining the epistemological, political, social, and ethical aspects of data artifacts, practices, and infrastructures\nWhat are some political dimensions of data? Examples?\nWhat are some ethical dimensions of data? Examples?\nIs there a difference?"
  },
  {
    "objectID": "slides/Day1-Intro.html#who-is-the-professor-why-is-an-anthropologist-teaching-data-science",
    "href": "slides/Day1-Intro.html#who-is-the-professor-why-is-an-anthropologist-teaching-data-science",
    "title": "Day One: Introductions",
    "section": "Who is the professor? Why is an anthropologist teaching data science?",
    "text": "Who is the professor? Why is an anthropologist teaching data science?\n\nPlease call me Lindsay (preferred), Professor Poirier, or Dr. Poirier\nPreviously Assistant Professor of Science and Technology Studies at UC Davis\nLab Manager at BetaNYC\nM.S./Ph.D. in Science and Technology Studies from Rensselaer Polytechnic Institute\nB.S. in Information Technology and Web Science from Rensselaer Polytechnic Institute\nDancing, crafting, cooking, re-watching the same TV series over and over again.\nI have a very spunky dog Madison."
  },
  {
    "objectID": "slides/Day1-Intro.html#exercise",
    "href": "slides/Day1-Intro.html#exercise",
    "title": "Day One: Introductions",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nEthnographers often collect more data than they know what to do with\nWrite as much as possible about:\n\nwhat people do/why they do it\nbeliefs/values/expertise\nsocial structures\nquestions you are left with"
  },
  {
    "objectID": "slides/Day1-Intro.html#syllabus-review",
    "href": "slides/Day1-Intro.html#syllabus-review",
    "title": "Day One: Introductions",
    "section": "Syllabus Review",
    "text": "Syllabus Review\n\nPolicies\nGrading Contract\nCourse Website\nPerusall\nSlack"
  },
  {
    "objectID": "slides/Day1-Intro.html#reading-tuesday",
    "href": "slides/Day1-Intro.html#reading-tuesday",
    "title": "Day One: Introductions",
    "section": "Reading Tuesday",
    "text": "Reading Tuesday\n\nBe sure to leave three substantive comments."
  },
  {
    "objectID": "slides/Day10-Translation.html",
    "href": "slides/Day10-Translation.html",
    "title": "Day Ten: Translation",
    "section": "",
    "text": "class: center, middle # Take out a sheet of paper and write happiness in the middle. Around that word, list ways that we might quantitatively measure happiness so that we might rank countries by their happiness. Be sure your ideas would produce a number.\n\n\nTurn to your neighbor and discuss:\n\nThrough what processes would we have to translate happiness into a number?\nWhat gets lost in translation?\n\n\n\n\n\n\n\nCantril Ladder\n\nThink of a ladder, with the best possible life for them being a 10, and the worst possible life being a 0. * Rate current lives on that 0 to 10 scale.\nSub-bars: levels of GDP, life expectancy, generosity, social support, freedom, and corruption\n\nNo impact on final score, only explanatory\n\n\n\nclass: center, middle # What does Biruk mean when they refer to “translation” in this chapter?\n\n\n\nExample\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nPg. 48 “Are you comfortable walking to the market alone?”\nWhat were the responses?\nHow would you interpret what Biruk is seeing here? What’s the significance of this example?\n\n\nclass: center, middle # Where do we see looping effects in this chapter? What gets “lost in translation”?\n\n\n\nExample\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nPg. 61: Question D13\nWhat does Biruk describe as the “fetish for codes?”\nHow would you interpret what Biruk is seeing here?\nWhat’s the significance of this example?\n\n\n\n\nExample\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nWhy does Biruk emphasize how stakeholders perceive “the field”? How would you interpret what Biruk is seeing here? What’s the significance of this?\n\n\n\n\nFor Monday\n\nQuestions to consider:\n\nHow does Star define infrastructure?\nWhy study infrastructure ethnographically?"
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day2-Epstemologies.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhat does it mean that you know this to be true? What counts as knowing?\nHow/through what means do you know this to be true?\nWhat are the limits of your knowledge on this?"
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#epistemology",
    "href": "slides/Day2-Epstemologies.html#epistemology",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "Epistemology",
    "text": "Epistemology\n\nGreek words\n\nEpisteme”: knowledge; understanding\n“Logos”: reason; argument\n\nPhilosophical study of the nature and limits of knowledge\n\nWhat conditions must be met for us to say that we “know” something to be true?\nHow do a group of people come to acquire knowledge?"
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#what-counts-as-knowledge",
    "href": "slides/Day2-Epstemologies.html#what-counts-as-knowledge",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "What counts as knowledge?",
    "text": "What counts as knowledge?\n\nHistorically knowledge defined as “justified true belief”\nDoes knowledge exist independently of a knowing mind?\n\nPositivists claim yes, there is objective truth independent of a knower\nInterpretivists and constructivists claim no, truths are subjective or tied to a knowing mind"
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#how-do-we-acquire-knowledge",
    "href": "slides/Day2-Epstemologies.html#how-do-we-acquire-knowledge",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "How do we acquire knowledge?",
    "text": "How do we acquire knowledge?\n\nEmpiricists claim that knowledge emerges from direct observation\nRationalists claim that knowledge emerges from logic and reason\n…and then there’s testimony, memory, intuition, feeling"
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#reading-discussion",
    "href": "slides/Day2-Epstemologies.html#reading-discussion",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "Reading Discussion",
    "text": "Reading Discussion\n\nFacilitator: Introduces the question. Keeps time. Points out when the group has gone on a tangent. Encourages everyone to share thoughts.\nConnector: Draws connections across peer contributions. Also connects to current events or “real world” examples.\nSummarizer: Keeps track (via notes) of the most important points made in the conversation. At a summary break and at the end of discussion, recites a summary of three key points made so far.\nDevil’s Advocate: Offers counter-arguments and polite critiques to keep the conversation.\nReporter: Reports the key points from the conversation out the the class at the conclusion of the exercise."
  },
  {
    "objectID": "slides/Day2-Epstemologies.html#feminist-epistemologies",
    "href": "slides/Day2-Epstemologies.html#feminist-epistemologies",
    "title": "Day Two: Epistemologies of Big Data",
    "section": "Feminist Epistemologies",
    "text": "Feminist Epistemologies\n\nAll knowledge is embodied\n\nContrast with disembodied knowledge - i.e. not tied to a specific body\n\nBodies are situated in certain social positions and have a finite point of view (Haraway 1991)\n\nCritique of the “unmarked body,” the “God trick,” or the “view from nowhere”\n\nKnowledge is tied to particular standpoints\n\nOur experiences, what we’ve read, our education, our social positions, and what our bodies enable us to do, see, hear, taste, touch, and smell\nFactors are innumerable and unique to every person"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html",
    "href": "slides/Day3-BigDataDiscourse.html",
    "title": "Day Three: Big Data Discourse",
    "section": "",
    "text": "class: center, middle # Pull out a piece of paper, and write three words that society often uses to talk about data.\n\n\nTurn to your neighbor and discuss:\n\nWhere have you seen these words used?\nWhere do these ideas about data originate?\nDoes a certain social group benefit from talking about data this why? Are certain social groups harmed? If yes, who and why?\n\n\n\n\nDiscourse\n\nHow we communicate or converse about topics, people, and things\nDominant discourse characterizes the discourses that emerge as predominant throughout society\n\nShapes our values, identities, behaviors, and interactions with each other\nAlso shapes, disseminates, and is prodded by our ideologies, or worldviews\n\nCultural hegemony describes when our ideologies reflect those with power over us\n\n\nclass: center, middle # What social institutions shape predominant ways we talk about things?\n\nclass: center, middle # What are some examples of dominant discourse?\n\n\n\nTechnology Discourse\n\nTechnocratic: Technology will fix social problems.\n\nComputers will save the world!\nOther examples?\n\nDystopian: Technology is frightening or debilitating.\n\nRobots will take over all jobs.\nOther examples?\n\nDeterminist: Technology determines how society operates.\n\nMobile phones are making us anti-social.\n\nOther examples?\n\n\n\n\n\n\nDiscourse Analysis in Nine Steps\n\nEstablish the context\nConsider the medium\nDiscern the intended audience\nAssess assumptions\nIdentify cultural cues and references\nEvaluate rhetorical strategies and methods of delivery\nConsider the social structures the discourse operates within\nAssess how the discourse disseminates\nReflect on what is not said or who is not included\n\n\nclass: center, middle # What were some of the metaphors for big data discussed in this week’s reading?\n\nclass: center, middle # In what ways do dominant metaphors give us insight into dominant dicourse? What were the key takeaways from this week’s reading?\n\n\n\nActivity\n\nRead article linked under today’s announcements\nHighlight statements that indicate Anderson’s worldview as you read\nReferencing the Discourse Analysis in 9 Steps, discuss components of Anderson’s discourse in small groups. Be sure to discuss Steps 4, 5, and 6 particularly."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html",
    "href": "slides/Day5-ThickDescription.html",
    "title": "Day Five: Thick Data for Big Data",
    "section": "",
    "text": "Discliplinary Conventions\n\nWhat is considered a relevant research question?\nWhat kind of arguments are made?\nWhat kind of data is collected/produced/presented?\nHow is collaboration valued?\nWhen/how is data shared?\n\n\n\n\nDisciplinary Genres\n\nIs text written in active or passive voice? Personal pronouns?\nAre subheadings chosen based on academic conventions?\nWhat kind of evidence is presented to persuade the reader? Statistics? Anecdotes?\nIn what ways are research methods explicated?\nHow and with what sort of detail are objects of study described?\nWhat role do poetics and metaphor play in the text? Can you identify emotion?\nWhat reflexive moves (self-reflection) does the author make? How do they elaborate their standpoint in/through the text?\n\n\n\n\nWhat is ethnography?\n\nStudy of human cultures\n\nCulture often defined as “semiotic”\nEthnographers aim to interpret the underlying meanings of surface actions and expressions\nMake the “familiar strange”\n\nOften characterized as interpretivist and qualitative\nTypically involves extended, immersive fieldwork\nHas historically been a solo discipline\nQualitative data rarely shared\n\n\n\n\nMethods of Ethnography\n\nParticipant Observation\n\nObserving interaction and behaviors “in the field”\n\nInterviewing\n\nEngaging in semi-structured conversations with informants\n\nArchival Research\n\nCurating and interpreting historical documents and artifacts\n\nDiscourse analysis\n\nInterpreting the cultural meaning interwoven in texts and speech\n\n\n\n\n\nTools of Ethnography\n\nField Notebooks\n\nDocument thick descriptions of observations\n\nRecording Devices\n\nAudio and video documentation of interviews\n\nCoding Software\n\nDraw out consistent themes of notes and interviews\n\n\n\n\n\nWhat is thick description?\n.pull-left[ \n]\n.pull-right[\n\nDescribe in the “thinnest” terms possible what is happening in this image.\nThick description moves towards interpreting its cultural meaning.\nExample drawn from a famous 1973 chapter by Clifford Geertz: “Thick Description: Towards an Interpretive Theory of Culture.”\n\n]\n\nclass: center, middle # How might we interpret the role of hex stickers in the R community?  Image source: Beiers, Sophie. 2020. “Tips & Tricks from the Newbies of Rstudio::Conf2020.” ACLU Tech & Analytics (blog). March 13, 2020. https://medium.com/aclu-tech-analytics/tips-tricks-from-the-newbies-of-rstudio-conf2020-5ccc780ba0e7.\n\nclass: center, middle # What were three takeaways from today?\n\n\n\nFor Wednesday\n\nLet me know if you’d like to lead a class discussion\nBe on the lookout for project group posting\nReading for Wednesday\n\nWhat are Biruk’s research questions?\nWhat does Biruk make known about her assumptions/beliefs/values as she begins to interpret data?"
  },
  {
    "objectID": "slides/Day13-Interviewing.html",
    "href": "slides/Day13-Interviewing.html",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "",
    "text": "When do ethnographers interview…\n\nTo gather historical narratives based on insider knowledge\nTo ascertain individual assumptions and commitments\nTo deepen understanding of how people see themselves fitting into the world and how they communicate that\n\n\n\n\nThings to keep in mind…\n\nInterviews are co-constructed by the interviewer and the interviewee\n\n\nWhat does that mean? Why does it matter?\n\n\nInterviews are not aiming to get at the “truth” of events but to capture how people narrate them\n\n\nWhat does that mean? Why does it matter?\n\n\n\n\nQualitative Interviews\n\nInvolve open-ended questions seeking in-depth explanations and articulations\nAre often semi-structured where a research develops questions beforehand and is prepared to veer from the script as the conversation develops\n\nEnables researchers to follow-up, asking the hows and the whys\nAllows the interviewee the flexibility to communicate from their perspectives rather than through the frames proposed by the interviewer\n\n\n\n\n\nPreparing for an interview\n\nIdentify an individual that can provide unique perspective on a research question\nReach out to that individual requesting an interview (See recruitment email in Moodle as template)\nCoordinate a date, time, and location for the interview. If conducting through Zoom, create a shared meeting link. Note how location matters for the tone of the interview.\nAsk interviewee to sign informed consent form (see attachment in Moodle)\nConduct background research on the individual being interviewed and the institutions they are a part of.\nCreate an interview guide - with framing questions and transitions.\n\n\nclass: center, middle # How might we structure the flow of an interview? What kinds of questions do we start with and end with?\n\n\n\nInterview Guides\n\nGeneral flow:\n\nStart with more general question and move to more specific questions\nStart with more matter-of-fact questions and move to more intimate questions as you build trust\nClose with a few lighter questions that prepare for friendly conclusion\n\nPreparing the guide:\n\nWrite more interview questions than you will have time to get to.\nAfter writing questions, group them according to similar topics and themes.\nPrepare transitions for moving between topics.\n\n\n\n\n\nFraming Questions\n\nAvoid questions that prompt a yes or no answer. Ask questions that encourage elaboration and description.\nConsider how to frame questions so that they make sense to the interviewee:\n\nMy research question: What values inform your data work?\nMy interview questions:\n\nWhat motivated you get involved in this work?\nWho were your primary inspirations in this area and why?\nWhat theorists/books were you reading as you got involved in this work? Do you find that relevant to your work today?\n\n\n\n\n\n\nDuring the Interview\n\nThank the individual for joining, introduce yourself, and remind them of the purpose of the interview\nStart the recording, and state your name, the date/time, the location, and the person being interviewed\nConfirm on the recording that the interviewee agrees to be interviewed\nDraw questions from the interview guide that maintain the overall flow of the interview. Regularly ask interviewees to elaborate by asking “how?” and “why?” questions.\nTakes notes on things the recording can’t pick up on (e.g. Body language, Tone, Things you are reminded of as they’re speaking)\n\n\n\n\nEngaging during the Interview\n\nEngage in active listening (direct eye contact, nodding)\nDon’t rush the interviewee to move onto a new question.\nIf the conversation veers allow it momentarily and then politely redirect it with a statement like, “I’d like to return to what you were saying about… Can you describe…?”\nInterviews can be vulnerable experiences. Earning trust demands demonstrating empathy and non-judgment. Preface difficult conversations, and offer breaks if appropriate.\n\n\n\n\nEngaging during the Interview, cont.\n\nDon’t try and finish an interviewee’s sentences. Allow for small moments of silence between questions to confirm that they’re done speaking.\nAvoid explicitly sharing personal opinions on what they’ve said. This can change how they respond in to future questions.\nContemplate ways to reframe questions that an interviewee evades, exaggerates, or provides limited information on.\n\n\n\n\nQuestions to consider:\n\nWhy does Biruk refer to the fieldworkers as “knowledge workers”? What kind of ethnographic move is this?\nBiruk continuously refers to “boundary work” in this chapter? Can you extrapolate what she means by this? What are the effects of enacting boundary work in fieldwork?\nWhat is “local knowledge”? How do credibility contests around “local knowledge” play out in this chapter?"
  },
  {
    "objectID": "slides/Day11-Infrastructure.html",
    "href": "slides/Day11-Infrastructure.html",
    "title": "Day Eleven: Ethnographies of Infrastructure",
    "section": "",
    "text": "class: center, middle # Identify something that meets Star’s definition of an infrastructure. Jot down some ideas about how.when this infrastructure has broken down.\n\n\nTurn to your neighbor and discuss:\n\nHow often do you think about this infrastructure? Did you notice it pre-breakdown?\nWho has a say in the design of this infrastructure, and who is excluded?\n\n\n\n\nMeasuring Contaminants\n.pull-left[ * Levels are not set based on potential impact to human health or degree of environmental degradation * Levels are set based on the degree of precision that can be achieved by all laboratories]\n.pull-right[ * Minimum Reporting Levels for water pollution: minimum concentration at which EPA requires contaminant detections to be reported\n ]\n\n\n\nCounting Deaths\n.pull-left[ * Standards for coding information death certifications such as standard definitions of “death” * Classification systems such as Sex and Race categories and Causes of Death * Electronic systems for reporting local data to counties to states to federal (NVSS)]\n.pull-right[ * Systems for producing and archiving death certificates\n ]\n\nclass: center, middle # Other examples? Databases? Packages?\n\n\n\nCase Study: Deforestation\n\nSelect one team member to take notes and another team member to serve as an ambassador.\nImagine that your team has been hired by US to study deforestation in one of your team member’s home states.\nTo do so you will compare satellite data of forests in 2010 to satellite data today.\n…but first your team needs to decide what counts as a forest.\nTogether come up with a standard definition of a forest. Your definition should be specific. How are we going to figure out what land to include or exclude in the study? Jot this definition down.\n\n\n\n\nFor Monday\n\nQuestions to consider:\n\nWhat’s the difference between a prototypical and Aristotelian classification?\nWhat cultural narratives can we draw from studying classifications?"
  },
  {
    "objectID": "grading_contract.html",
    "href": "grading_contract.html",
    "title": "Grading Contract",
    "section": "",
    "text": "This course will be using a grading contract. This means that the grade you ultimately receive for this course is primarily based on the labor that you perform rather than a subjective evaluation of the quality of your work and writing in relation to your peers. Your grade will be determined by the extent of your engagement in class, your timely completion of assignments, and how you support the course community. You will still attend to and work to improve the quality of your writing and thinking in this course. You will receive extensive feedback on all of your submissions (from me and from your peers), and you will have opportunities to revise. However, you will not receive points or an A, B, C, D, etc. on assignments."
  },
  {
    "objectID": "grading_contract.html#grade-breakdown",
    "href": "grading_contract.html#grade-breakdown",
    "title": "Grading Contract",
    "section": "Grade Breakdown",
    "text": "Grade Breakdown\nEach row indicates what labor you need to complete in the course to earn the grade indicated in the first column of that row. Note that to earn a particular grade all minimum labor criteria in the corresponding row must be met.\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\nBlog Posts\nBlog Post Peer Review\nFinal Project Checkpoints\nReading Annotations\nCommunity Labor Points\nEnrichment\n\n\n\n\nA\n2 + 1 substantive revision\n2\n4 + Final Project\n10\n8 or more\n3\n\n\nB\n2 + 1 substantive revision\n2\n4 + Final Project\n10\n8 or more\n0\n\n\nC\n1 + 1 substantive revision\n1\n3 + Final Project\n8\n6 or more\n0\n\n\nD\n1, no revision\n1\n2 + Final Project\n6\n4 or more\n0\n\n\nE\n0\n0\n<2\n<6\n3 or fewer\n0\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that while you can miss final project checkpoints, a first and final draft must be submitted on time and a final presentation must be delivered in order to pass the course."
  },
  {
    "objectID": "grading_contract.html#faq",
    "href": "grading_contract.html#faq",
    "title": "Grading Contract",
    "section": "FAQ",
    "text": "FAQ\n\nWhat do I need to do to earn an A in this course?\n‘A’ grades will be assigned to students that meet the requirements to earn a ‘B’ in the course and enrich those assignments by completing three additional reflective assignments. Prompts for these assignments will be included in the GitHub repository for your learning portfolio. The deadline for completion of enrichment assignments is the last day class meets. It will be the students’ responsibility to stay on top of completion of these assignments. Furthermore, enrichment assignments completed prior to the last two weeks of class will receive more substantive feedback from me than assignments completed in the last two weeks.\n\n\nWhat kind of feedback will I receive regarding my work?\nYou will receive extensive feedback on all of your submissions (from me and from your colleagues), and you will have opportunities to revise. I will also provide rubrics for most assignments to indicate how I will evaluate your work. However, you will not receive points or an A, B, C, D, etc. on individual assignments.\n\n\nHow can I best keep track of my labor in this course?\nThroughout the semester, you will be asked to keep track of your labor via a log that will be available in your GitHub portfolio. I will reference this log to calculate certain aspects of your final grade. Instructions for using the labor log will be provided in the second week of the course.\n\n\nCan I earn +/- grades in this course?\n+/- will be assigned to final grades at my discretion in cases where a student’s work consistently exceeds the expectations (+) of their contracted grade or is in some way insufficient (-). Students can track their progress towards a grade modifier in feedback that I provide throughout the semester. Your grade may also be reduced by a grade modifier for each missed class beyond three absences.\n\n\nWhat if I need an extension on an assignment?\nThere is a 24-hour grace period on all written assignments, except for reading annotations. There will be no penalties for submitting the written assignment within this 24-hour period, and you do not need to inform me that you intend to take the extra time. You can also request up to a 72-hour extension on any written assignment, as long as you make that request at least 48 hours before the original assignment due date. You can request an extension by filling out the Extension Request form on Moodle, and I will confirm your extension on Slack. Beyond this, late assignments will not be accepted.\n\n\nCan I ask for extensions or use the grade period for reading annotations?\nReading assignments/Perusall annotations prepare you to participate in class discussions. For this reason, they need to be completed by the due date for credit. I’ve provided considerable leeway to miss a reading annotation assignment from time-to-time in order to accommodate flexibility in this regard.\n\n\nAn assignment deadline is approaching, and I’m unhappy with the quality of my work. What should I do?\nWhile I always encourage students to strive to submit the best work they can, this course’s grading contract, coupled with the course’s revision assignments, permits you to submit work that you know you want to continue to improve upon without penalty. Not submitting assignments at all has the potentially to significantly lower your grade in this course, whereas submitting an assignment that could benefit from more revision will not be detrminental to your grade as long as the minimum submission requirements are met."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "::: .callout-tip"
  },
  {
    "objectID": "schedule.html#january-26-2022",
    "href": "schedule.html#january-26-2022",
    "title": "Schedule",
    "section": "January 26, 2022",
    "text": "January 26, 2022\n\nIntroductions\nBECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n Fill out the First Day of Class Questionnaire\n\n\n Course slides are here."
  },
  {
    "objectID": "schedule.html#january-31-2022",
    "href": "schedule.html#january-31-2022",
    "title": "Schedule",
    "section": "January 31, 2022",
    "text": "January 31, 2022\n\nHegemonic Backdrops of Big Data\nEPISTEMOLOGY DISCOURSE ANALYSIS BECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) boyd, danah and Kate Crawford (2012). “Critical Questions for Big Data”. In: Information, Communication & Society 15.5, pp. 662-679. (Visited on Jan. 19, 2018).\n Fill out the Trigger Warnings Questionnaire in Moodle.\n Install Desktop version of Slack and configure notifications for our course.\n\n\n Course slides are here\n (Read in Perusall) Kitchin, Rob (2014). “Big Data, new epistemologies and paradigm shifts”. En. In: Big Data & Society 1.1, p. 2053951714528481. (Visited on Jul. 16, 2019).\n (Read in Perusall) Leonelli, S. (2014). “What difference does quantity make? On the epistemology of Big Data in biology:”. En. In: Big Data & Society. Publisher: SAGE PublicationsSage UK: London, England. (Visited on Mar. 28, 2020).\n (Read in Perusall) Onuoha, Mimi (2016). The Point of Collection. En. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#february-02-2022",
    "href": "schedule.html#february-02-2022",
    "title": "Schedule",
    "section": "February 02, 2022",
    "text": "February 02, 2022\n\nMetaphors of Big Data\nDISCOURSE ANALYSIS DISCOURSE\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Levy Karen, Tim Hwang (2015). ‘The Cloud’ and Other Dangerous Metaphors. En. Section: Technology. (Visited on Aug. 29, 2021).\n (Read in Perusall) Puschmann, Cornelius and Jean Burgess (2014). “Metaphors of Big Data”. En. In: International Journal of Communication 8.0, p. 20. (Visited on May. 02, 2016).\n Create a GitHub account if you don’t have one\n Click on the Student Portfolio GitHub Repo in Moodle to create your portfolio\n Acknowledge that you’ve read and understand the grading contract by completing the Grading Contract Acknowledgement in Moodle\n Direct message Rose in Slack if you would like to lead a class discussion enrichment assignment.\n\n\n Here is the article we will engage in today’s activity.\n Discourse Analysis in Nine Steps is here.\n (Read in Perusall) Watson, Sarah M. (2021). Metaphors of Big Data. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#february-07-2022",
    "href": "schedule.html#february-07-2022",
    "title": "Schedule",
    "section": "February 07, 2022",
    "text": "February 07, 2022\n\nBinary Oppositions in Big Data Discourse\nDISCOURSE ANALYSIS INTERPRETING CULTURAL MEANING\n\nDue TodayFurther Resources\n\n\n Complete course infrastructure set-up by following instructions in the setting-up-r-environment directory in your GitHub portfolio\n DM Rose if you’d like to lead a class discussion for enrichment"
  },
  {
    "objectID": "schedule.html#february-09-2022",
    "href": "schedule.html#february-09-2022",
    "title": "Schedule",
    "section": "February 09, 2022",
    "text": "February 09, 2022\n\nThick Data for Big Data\nTHICK DESCRIPTION BECOMING OBSERVANT COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Fiore-Silfvast, Brittany (2014). Hacked Ethnographic Fieldnotes. En. (Visited on Feb. 18, 2021).\n (Read in Perusall) Burrell, Jenna (2012). The Ethnographer’s Complete Guide to Big Data: Small Data People in a Big Data World. (Visited on Aug. 20, 2021).\n Fill out CATME Survey (link sent to your email)\n DM Rose if you’d like to lead a class discussion for enrichment\n\n\n (Read in Perusall) Wang, Tricia (2013). Big Data Needs Thick Data. (Visited on Sep. 10, 2019)."
  },
  {
    "objectID": "schedule.html#february-14-2022",
    "href": "schedule.html#february-14-2022",
    "title": "Schedule",
    "section": "February 14, 2022",
    "text": "February 14, 2022\n\nEthnography in Data Land\nTHICK DESCRIPTION BECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Introduction , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1."
  },
  {
    "objectID": "schedule.html#february-16-2022",
    "href": "schedule.html#february-16-2022",
    "title": "Schedule",
    "section": "February 16, 2022",
    "text": "February 16, 2022\n\nData Looping Effects\nANALYZING SOCIAL FORCES AND SYSTEMS EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Kitchin, Rob and Tracey P. Lauriault (2014). Towards Critical Data Studies: Charting and Unpacking Data Assemblages and Their Work. SSRN Scholarly Paper ID 2474112. Rochester, NY: Social Science Research Network. (Visited on Nov. 07, 2017).\n\n\n (Read in Perusall) Hacking, Ian (2006). “Making Up People”. In: London Review of Books 28.\n (Read in Perusall) Urla, Jacqueline (1993). “Cultural Politics in an Age of Statistics: Numbers, Nations, and the Making of Basque Identity”. In: American Ethnologist 20.4. Publisher: [Wiley, American Anthropological Association], pp. 818-843. (Visited on Aug. 30, 2021).\n (Read in Perusall) Kristensen, Dorthe Brogård and Minna Ruckenstein (2018). “Co-evolving with self-tracking technologies”. En. In: New Media & Society 20.10. Publisher: SAGE Publications, pp. 3624-3640. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#february-21-2022",
    "href": "schedule.html#february-21-2022",
    "title": "Schedule",
    "section": "February 21, 2022",
    "text": "February 21, 2022\n\nEthics of Qualitative Research\nPOWER\n\nDue TodayFurther Resources\n\n\n Team Contract\n Fieldnote 1"
  },
  {
    "objectID": "schedule.html#february-23-2022",
    "href": "schedule.html#february-23-2022",
    "title": "Schedule",
    "section": "February 23, 2022",
    "text": "February 23, 2022\n\nDocumenting Datasets\nDATA DOCUMENTATION COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Gebru, Timnit, Jamie Morgenstern, Briana Vecchione, et al. (2020). “Datasheets for Datasets”. In: arXiv:1803.09010 [cs]. arXiv: 1803.09010. (Visited on Jan. 24, 2021).\n Get approval for dataset\n\n\n Potential final project datasets are here.\n (Read in Perusall) Bender, Emily M. and Batya Friedman (2018). “Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science”. In: Transactions of the Association for Computational Linguistics 6, pp. 587-604. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#february-28-2022",
    "href": "schedule.html#february-28-2022",
    "title": "Schedule",
    "section": "February 28, 2022",
    "text": "February 28, 2022\n\nMaking Measures Commensurate: Translation and Reductionism\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING TRANSLATION INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Chapter 1 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n\n\n (Read in Perusall) Espeland, Wendy Nelson and Mitchell L. Stevens (1998). “Commensuration as a Social Process”. In: Annual Review of Sociology 24.1. Publisher: Annual Reviews, pp. 313-343. (Visited on Aug. 30, 2021).\n (Read in Perusall) Merry, Sally Engle (2016). The Seductions of Quantification: Measuring Human Rights, Gender Violence, and Sex Trafficking. En. Google-Books-ID: 0FcqDAAAQBAJ. University of Chicago Press. ISBN: 978-0-226-26131-7."
  },
  {
    "objectID": "schedule.html#march-02-2022",
    "href": "schedule.html#march-02-2022",
    "title": "Schedule",
    "section": "March 02, 2022",
    "text": "March 02, 2022\n\nEthnographies of Infrastructure\nCULTURAL ANALYSIS OF INFRASTRUCTURE BECOMING OBSERVANT INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Star, Susan Leigh (1999). “The Ethnography of Infrastructure”. En. In: American Behavioral Scientist 43.3, pp. 377-391. (Visited on Feb. 18, 2016).\n Work on semiotic analysis\n\n\n (Read in Perusall) Lampland, Martha and Susan Leigh Star, ed. (2008). Standards and Their Stories: How Quantifying, Classifying, and Formalizing Practices Shape Everyday Life. 1 edition. Ithaca: Cornell University Press. ISBN: 978-0-8014-7461-3.\n (Read in Perusall) Ottinger, Gwen (2010). “Buckets of Resistance: Standards and the Effectiveness of Citizen Science”. En. In: Science, Technology, & Human Values 35.2, pp. 244-270. (Visited on Oct. 05, 2019).\n (Read in Perusall) Timmermans, Stefan and Steven Epstein (2010). “A World of Standards but not a Standard World: Toward a Sociology of Standards and Standardization*“. In: Annual Review of Sociology 36.1, pp. 69-89. (Visited on Oct. 16, 2014)."
  },
  {
    "objectID": "schedule.html#march-07-2022",
    "href": "schedule.html#march-07-2022",
    "title": "Schedule",
    "section": "March 07, 2022",
    "text": "March 07, 2022\n\nSorting Things Out: Cultural Analyses of Categories\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Bowker, Geoffrey C. (1998). “The Kindness of Strangers: Kinds and Politics in Classification Systems”. En. In: Library Trends 47.2, pp. 255-292. (Visited on Oct. 14, 2019).\n Fieldnote 2\n Be sure to get approval for the TED Talks you plan to view for Mini-Project 1.\n\n\n (Read in Perusall) Bowker, Geoffrey C. and Susan Leigh Star (1999). Sorting Things Out: Classification and Its Consequences. En. Cambridge, MA: MIT Press. ISBN: 978-0-262-52295-3.\n (Read in Perusall) Waterton, Claire (2002). “From Field to Fantasy: Classifying Nature, Constructing Europe”. En. In: Social Studies of Science 32.2, pp. 177-204. (Visited on May. 15, 2019).\n (Read in Perusall) Kirksey, Eben (2015). “Species: a praxiographic study”. Fr. In: Journal of the Royal Anthropological Institute 21.4, pp. 758-780. (Visited on Oct. 05, 2019)."
  },
  {
    "objectID": "schedule.html#march-09-2022",
    "href": "schedule.html#march-09-2022",
    "title": "Schedule",
    "section": "March 09, 2022",
    "text": "March 09, 2022\n\nInfrastructure Field Day\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources"
  },
  {
    "objectID": "schedule.html#march-21-2022",
    "href": "schedule.html#march-21-2022",
    "title": "Schedule",
    "section": "March 21, 2022",
    "text": "March 21, 2022\n\nData Ghost Work\nINTERVIEWING ANALYZING SOCIAL FORCES AND SYSTEMS LABOR\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Chapter 1 , Gray, Mary L. and Siddharth Suri (2019). Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. Illustrated edition. Boston: Mariner Books. ISBN: 978-1-328-56624-9.\n Work on stakholder analysis\n\n\n (Read in Perusall) Irani, Lilly (2015). Justice for “Data Janitors”. En-US. (Visited on Dec. 13, 2018).\n (Read in Perusall) Plantin, Jean-Christophe (2019). “Data Cleaners for Pristine Datasets: Visibility and Invisibility of Data Processors in Social Science”. En. In: Science, Technology, & Human Values 44.1. Publisher: SAGE Publications Inc, pp. 52-73. (Visited on Aug. 20, 2021).\n (Read in Perusall) Forsythe, Diana E. (1993). “The Construction of Work in Artificial Intelligence”. En. In: Science, Technology, & Human Values 18.4. Publisher: SAGE Publications Inc, pp. 460-479. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#march-23-2022",
    "href": "schedule.html#march-23-2022",
    "title": "Schedule",
    "section": "March 23, 2022",
    "text": "March 23, 2022\n\nSocial Constructions of Expertise in Data Work\nINTERVIEWING INTERPRETING CULTURAL MEANING LABOR\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Chapter 2 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Mini-Project 1\n\n\n Here is a link to the Final Project guide that Rose developed.\n (Read in Perusall) Gieryn, Thomas F. (1999). Cultural Boundaries of Science: Credibility on the Line. En. University of Chicago Press. ISBN: 978-0-226-29261-8."
  },
  {
    "objectID": "schedule.html#march-28-2022",
    "href": "schedule.html#march-28-2022",
    "title": "Schedule",
    "section": "March 28, 2022",
    "text": "March 28, 2022\n\nHow Data Domesticates Us: Rituals for Data Cleaning\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Ribes, David and Steven J Jackson (2013). “Data bite man: The work of sustaining a long-term study”. In: Raw data” is an oxymoron. Ed. by Lisa Gitelman. Cambridge, MA: MIT Press, pp. 147-166.\n Work on ritual analysis\n\n\n (Read in Perusall) Bowker, Geoffrey C. (2000). “Biodiversity Datadiversity”. En. In: Social Studies of Science 30.5, pp. 643-683. (Visited on May. 14, 2014).\n (Read in Perusall) Walford, Antonia (2017). “Raw Data: Making Relations Matter”. En_US. In: Social Analysis 61.2. Publisher: Berghahn Journals Section: Social Analysis, pp. 65-80. (Visited on Aug. 20, 2021).\n (Read in Perusall) Pink, Sarah, Shanti Sumartojo, Deborah Lupton, et al. (2017). “Mundane data: The routines, contingencies and accomplishments of digital living”. En. In: Big Data & Society 4.1. Publisher: SAGE Publications Ltd, p. 2053951717700924. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#march-30-2022",
    "href": "schedule.html#march-30-2022",
    "title": "Schedule",
    "section": "March 30, 2022",
    "text": "March 30, 2022\n\nCooking Data\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n Fieldnote 3"
  },
  {
    "objectID": "schedule.html#april-04-2022",
    "href": "schedule.html#april-04-2022",
    "title": "Schedule",
    "section": "April 04, 2022",
    "text": "April 04, 2022\n\nInstitutional Incentives in Data Reporting\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n Work on institutional analysis"
  },
  {
    "objectID": "schedule.html#april-06-2022",
    "href": "schedule.html#april-06-2022",
    "title": "Schedule",
    "section": "April 06, 2022",
    "text": "April 06, 2022\n\nEconomies of Data Production: Gifts and Transactions\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Chapter 4 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n\n\n (Read in Perusall) Gerlitz, Carolin and Anne Helmond (2013). “The like economy: Social buttons and the data-intensive web”. En. In: New Media & Society 15.8. Publisher: SAGE Publications, pp. 1348-1365. (Visited on Aug. 30, 2021).\n (Read in Perusall) Beer, David (2015). “Productive measures: Culture and measurement in the context of everyday neoliberalism”. En. In: Big Data & Society 2.1. Publisher: SAGE Publications Ltd, p. 2053951715578951. (Visited on Aug. 29, 2021)."
  },
  {
    "objectID": "schedule.html#april-11-2022",
    "href": "schedule.html#april-11-2022",
    "title": "Schedule",
    "section": "April 11, 2022",
    "text": "April 11, 2022\n\nMobilizing Data: Making Numbers Actionable\nDISCOURSE ANALYSIS SITUATING KNOWLEDGE MOBILIZATION\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Ottinger, Gwen and Rachel Zurer (2011). New Voices, New Approaches: Drowning in Data. En-US. (Visited on Dec. 13, 2018).\n Work on discourse analysis\n Mini-Project 2\n\n\n (Read in Perusall) Pine, Kathleen H. and Max Liboiron (2015). “The Politics of Measurement and Action”. In: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery, pp. 3147-3156. ISBN: 978-1-4503-3145-6. (Visited on Aug. 30, 2021).\n (Read in Perusall) Dourish, Paul and Edgar Gómez Cruz (2018). “Datafication and data fiction: Narrating data and narrating with data”. En. In: Big Data & Society 5.2. Publisher: SAGE Publications Ltd, p. 2053951718784083. (Visited on Apr. 05, 2021)."
  },
  {
    "objectID": "schedule.html#april-13-2022",
    "href": "schedule.html#april-13-2022",
    "title": "Schedule",
    "section": "April 13, 2022",
    "text": "April 13, 2022\n\nData Circulation\nDISCOURSE ANALYSIS COMMUNICATING (IN) CONTEXT MOBILIZATION\n\nDue TodayFurther Resources\n\n\n Fieldnote 4\n\n\n (Read in Perusall) Bates, Jo, Yu-Wei Lin, and Paula Goodale (2016). “Data journeys: Capturing the socio-material constitution of data objects and flows”. En. In: Big Data & Society 3.2. Publisher: SAGE Publications Ltd, p. 2053951716654502. (Visited on Mar. 28, 2020).\n (Read in Perusall) Leonelli, Sabina (2010). “Packaging Small Fact for Re-use: Databases in Model Organism Biology”. En. In: How Well Do Facts Travel?: The Dissemination of Reliable Knowledge. Ed. by Peter Howlett and Mary S. Morgan. Cambridge, MA: Cambridge University Press, pp. 325-348. ISBN: 978-1-139-49239-3."
  },
  {
    "objectID": "schedule.html#april-18-2022",
    "href": "schedule.html#april-18-2022",
    "title": "Schedule",
    "section": "April 18, 2022",
    "text": "April 18, 2022\n\nMobilizing Data Otherwise: Citizen Science and Sensing\nDISCOURSE SITUATING KNOWLEDGE MOBILIZATION CREDIBILITY\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Gabrys, Jennifer, Helen Pritchard, and Benjamin Barratt (2016). “Just good enough data: Figuring data citizenships through air pollution sensing and data stories”. En. In: Big Data & Society 3.2. Publisher: SAGE Publications Ltd, p. 2053951716679677. (Visited on Mar. 28, 2020).\n First draft due\n\n\n (Read in Perusall) Calvillo, Nerea (2018). “Political airs: From monitoring to attuned sensing air pollution”. En. In: Social Studies of Science 48.3, pp. 372-388. (Visited on Sep. 24, 2019).\n (Read in Perusall) Jalbert, Kirk and Abby J. Kinchy (2016). “Sense and Influence: Environmental Monitoring Tools and the Power of Citizen Science”. In: Journal of Environmental Policy & Planning 18.3. Publisher: Routledge _ eprint: https://doi.org/10.1080/1523908X.2015.1100985, pp. 379-397. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#april-20-2022",
    "href": "schedule.html#april-20-2022",
    "title": "Schedule",
    "section": "April 20, 2022",
    "text": "April 20, 2022\n\nData Activism and Advocacy\nSITUATING KNOWLEDGE MOBILIZATION CREDIBILITY\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Liboiron, Max (2015). “Disaster Data, Data Activism : Grassroots Responses to Representing Superstorm Sandy”. En. In: Extreme Weather and Global Media. Ed. by Julia Leyda and Diane Negra. Taylor & Francis Group. (Visited on Aug. 27, 2019).\n\n\n (Read in Perusall) Bruno, Isabelle, Emmanuel Didier, and Tommaso Vitale (2014). Statactivism: Forms of Action between Disclosure and Affirmation. En. SSRN Scholarly Paper ID 2466882. Rochester, NY: Social Science Research Network. (Visited on Dec. 18, 2018).\n (Read in Perusall) Milan, Stefania and Lonneke van der Velden (2016). “The Alternative Epistemologies of Data Activism”. In: Digital Culture & Society 2.2, pp. 57-74. (Visited on Jul. 16, 2019).\n (Read in Perusall) Currie, Morgan, Britt S Paris, Irene Pasquetto, et al. (2016). “The conundrum of police officer-involved homicides: Counter-data in Los Angeles County”. En. In: Big Data & Society 3.2, p. 2053951716663566. (Visited on Aug. 08, 2018)."
  },
  {
    "objectID": "schedule.html#april-25-2022",
    "href": "schedule.html#april-25-2022",
    "title": "Schedule",
    "section": "April 25, 2022",
    "text": "April 25, 2022\n\nData Agnotology: Ignorance and Knowledge Gaps\nEPISTEMOLOGY IGNORANCE SITUATING KNOWLEDGE\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) mimimimimi (2021). On Missing Data Sets. original-date: 2016-02-03T16:30:28Z. (Visited on Aug. 20, 2021).\n (Read in Perusall) Milan, Stefania and Emiliano Treré (2020). “The Rise of the Data Poor: The COVID-19 Pandemic Seen From the Margins”. En. In: Social Media + Society 6.3. Publisher: SAGE Publications Ltd, p. 2056305120948233. (Visited on Aug. 31, 2021).\n\n\n (Read in Perusall) D’Ignazio, Catherine and Lauren F. Klein (2020). Data Feminism. Cambridge, Massachusetts: The MIT Press. ISBN: 978-0-262-04400-4."
  },
  {
    "objectID": "schedule.html#april-27-2022",
    "href": "schedule.html#april-27-2022",
    "title": "Schedule",
    "section": "April 27, 2022",
    "text": "April 27, 2022\n\nData and Algorithmic Power\nPOWER SITUATING KNOWLEDGE EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n (Read in Perusall) Eubanks, Virginia (2018). “A Child Abuse Prediction Model Fails Poor Families”. In: Wired. (Visited on Mar. 28, 2019).\n Fieldnote 5\n\n\n (Read in Perusall) Brayne, Sarah (2017). “Big Data Surveillance: The Case of Policing”. In: American Sociological Review 82.5. Publisher: SAGE Publications Inc, pp. 977-1008. (Visited on Aug. 18, 2021).\n (Read in Perusall) Christin, Angèle (2020). “The ethnographer and the algorithm: beyond the black box”. En. In: Theory and Society 49.5, pp. 897-918. (Visited on Aug. 31, 2021).\n (Read in Perusall) Seaver, Nick (2017). “Algorithms as culture: Some tactics for the ethnography of algorithmic systems”. En. In: Big Data & Society 4.2. Publisher: SAGE Publications Ltd, p. 2053951717738104. (Visited on Jan. 22, 2021)."
  },
  {
    "objectID": "schedule.html#may-02-2022",
    "href": "schedule.html#may-02-2022",
    "title": "Schedule",
    "section": "May 02, 2022",
    "text": "May 02, 2022\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Mini-Project Revisions"
  },
  {
    "objectID": "schedule.html#may-04-2022",
    "href": "schedule.html#may-04-2022",
    "title": "Schedule",
    "section": "May 04, 2022",
    "text": "May 04, 2022\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Final project due\n Enrichment"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day3-BigDataDiscourse.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Three: Big Data Discourse",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhere have you seen these words used?\nWhere do these ideas about data originate?\nDoes a certain social group benefit from talking about data this why? Are certain social groups harmed? If yes, who and why?"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#discourse",
    "href": "slides/Day3-BigDataDiscourse.html#discourse",
    "title": "Day Three: Big Data Discourse",
    "section": "Discourse",
    "text": "Discourse\n\nHow we communicate or converse about topics, people, and things\nDominant discourse characterizes the discourses that emerge as predominant throughout society\n\nShapes our values, identities, behaviors, and interactions with each other\nAlso shapes, disseminates, and is prodded by our ideologies, or worldviews\n\nCultural hegemony describes when our ideologies reflect those with power over us"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#technology-discourse",
    "href": "slides/Day3-BigDataDiscourse.html#technology-discourse",
    "title": "Day Three: Big Data Discourse",
    "section": "Technology Discourse",
    "text": "Technology Discourse\n\nTechnocratic: Technology will fix social problems.\n\nComputers will save the world!\nOther examples?\n\nDystopian: Technology is frightening or debilitating.\n\nRobots will take over all jobs.\nOther examples?\n\nDeterminist: Technology determines how society operates.\n\nMobile phones are making us anti-social.\n\nOther examples?"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#discourse-analysis-in-nine-steps",
    "href": "slides/Day3-BigDataDiscourse.html#discourse-analysis-in-nine-steps",
    "title": "Day Three: Big Data Discourse",
    "section": "Discourse Analysis in Nine Steps",
    "text": "Discourse Analysis in Nine Steps\n\nEstablish the context\nConsider the medium\nDiscern the intended audience\nAssess assumptions\nIdentify cultural cues and references\nEvaluate rhetorical strategies and methods of delivery\nConsider the social structures the discourse operates within\nAssess how the discourse disseminates\nReflect on what is not said or who is not included"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#activity",
    "href": "slides/Day3-BigDataDiscourse.html#activity",
    "title": "Day Three: Big Data Discourse",
    "section": "Activity",
    "text": "Activity\n\nRead article linked under today’s announcements\nHighlight statements that indicate Anderson’s worldview as you read\nReferencing the Discourse Analysis in 9 Steps, discuss components of Anderson’s discourse in small groups. Be sure to discuss Steps 4, 5, and 6 particularly."
  },
  {
    "objectID": "schedule.html#january-26-2023",
    "href": "schedule.html#january-26-2023",
    "title": "Schedule",
    "section": "January 26, 2023",
    "text": "January 26, 2023\n\nIntroductions\nBECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n Fill out the First Day of Class Questionnaire\n\n\n Course slides are here."
  },
  {
    "objectID": "schedule.html#january-31-2023",
    "href": "schedule.html#january-31-2023",
    "title": "Schedule",
    "section": "January 31, 2023",
    "text": "January 31, 2023\n\nHegemonic Backdrops of Big Data\nEPISTEMOLOGY DISCOURSE ANALYSIS BECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n boyd, danah and Kate Crawford (2012). “Critical Questions for Big Data”. In: Information, Communication & Society 15.5, pp. 662-679. (Visited on Jan. 19, 2018).\n Fill out the Trigger Warnings Questionnaire in Moodle.\n Install Desktop version of Slack and configure notifications for our course.\n\n\n Course slides are here\n Kitchin, Rob (2014). “Big Data, new epistemologies and paradigm shifts”. En. In: Big Data & Society 1.1, p. 2053951714528481. (Visited on Jul. 16, 2019).\n Leonelli, S. (2014). “What difference does quantity make? On the epistemology of Big Data in biology:”. En. In: Big Data & Society. Publisher: SAGE PublicationsSage UK: London, England. (Visited on Mar. 28, 2020).\n Onuoha, Mimi (2016). The Point of Collection. En. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#february-02-2023",
    "href": "schedule.html#february-02-2023",
    "title": "Schedule",
    "section": "February 02, 2023",
    "text": "February 02, 2023\n\nMetaphors of Big Data\nDISCOURSE ANALYSIS DISCOURSE\n\nDue TodayFurther Resources\n\n\n Levy Karen, Tim Hwang (2015). ‘The Cloud’ and Other Dangerous Metaphors. En. Section: Technology. (Visited on Aug. 29, 2021).\n Puschmann, Cornelius and Jean Burgess (2014). “Metaphors of Big Data”. En. In: International Journal of Communication 8.0, p. 20. (Visited on May. 02, 2016).\n Create a GitHub account if you don’t have one\n Click on the Student Portfolio GitHub Repo in Moodle to create your portfolio\n Acknowledge that you’ve read and understand the grading contract by completing the Grading Contract Acknowledgement in Moodle\n Direct message Rose in Slack if you would like to lead a class discussion enrichment assignment.\n\n\n Course slides are here\n Here is the article we will engage in today’s activity.\n Discourse Analysis in Nine Steps is here.\n Watson, Sarah M. (2021). Metaphors of Big Data. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#february-07-2023",
    "href": "schedule.html#february-07-2023",
    "title": "Schedule",
    "section": "February 07, 2023",
    "text": "February 07, 2023\n\nBinary Oppositions in Big Data Discourse\nDISCOURSE ANALYSIS INTERPRETING CULTURAL MEANING\n\nDue TodayFurther Resources\n\n\n Complete course infrastructure set-up by following instructions in the setting-up-r-environment directory in your GitHub portfolio\n DM Rose if you’d like to lead a class discussion for enrichment\n\n\n Course slides are here"
  },
  {
    "objectID": "schedule.html#february-09-2023",
    "href": "schedule.html#february-09-2023",
    "title": "Schedule",
    "section": "February 09, 2023",
    "text": "February 09, 2023\n\nThick Data for Big Data\nTHICK DESCRIPTION BECOMING OBSERVANT COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Fiore-Silfvast, Brittany (2014). Hacked Ethnographic Fieldnotes. En. (Visited on Feb. 18, 2021).\n Burrell, Jenna (2012). The Ethnographer’s Complete Guide to Big Data: Small Data People in a Big Data World. (Visited on Aug. 20, 2021).\n Fill out CATME Survey (link sent to your email)\n DM Rose if you’d like to lead a class discussion for enrichment\n\n\n Course slides are here\n Here’s an example of some very short “thick description” write-ups of two data environments from my own research.\n Wang, Tricia (2013). Big Data Needs Thick Data. (Visited on Sep. 10, 2019)."
  },
  {
    "objectID": "schedule.html#february-14-2023",
    "href": "schedule.html#february-14-2023",
    "title": "Schedule",
    "section": "February 14, 2023",
    "text": "February 14, 2023\n\nEthnography in Data Land\nTHICK DESCRIPTION BECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n Introduction , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n\n\n Course slides are here"
  },
  {
    "objectID": "schedule.html#february-16-2023",
    "href": "schedule.html#february-16-2023",
    "title": "Schedule",
    "section": "February 16, 2023",
    "text": "February 16, 2023\n\nData Looping Effects\nANALYZING SOCIAL FORCES AND SYSTEMS EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n Kitchin, Rob and Tracey P. Lauriault (2014). Towards Critical Data Studies: Charting and Unpacking Data Assemblages and Their Work. SSRN Scholarly Paper ID 2474112. Rochester, NY: Social Science Research Network. (Visited on Nov. 07, 2017).\n\n\n Course slides are here.\n Hacking, Ian (2006). “Making Up People”. In: London Review of Books 28.\n Urla, Jacqueline (1993). “Cultural Politics in an Age of Statistics: Numbers, Nations, and the Making of Basque Identity”. In: American Ethnologist 20.4. Publisher: [Wiley, American Anthropological Association], pp. 818-843. (Visited on Aug. 30, 2021).\n Kristensen, Dorthe Brogård and Minna Ruckenstein (2018). “Co-evolving with self-tracking technologies”. En. In: New Media & Society 20.10. Publisher: SAGE Publications, pp. 3624-3640. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#february-21-2023",
    "href": "schedule.html#february-21-2023",
    "title": "Schedule",
    "section": "February 21, 2023",
    "text": "February 21, 2023\n\nEthics of Qualitative Research\nPOWER\n\nDue TodayFurther Resources\n\n\n Team Contract\n Fieldnote 1\n\n\n Course slides are here."
  },
  {
    "objectID": "schedule.html#february-23-2023",
    "href": "schedule.html#february-23-2023",
    "title": "Schedule",
    "section": "February 23, 2023",
    "text": "February 23, 2023\n\nDocumenting Datasets\nDATA DOCUMENTATION COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Gebru, Timnit, Jamie Morgenstern, Briana Vecchione, et al. (2020). “Datasheets for Datasets”. In: arXiv:1803.09010 [cs]. arXiv: 1803.09010. (Visited on Jan. 24, 2021).\n Get approval for dataset\n\n\n Course slides are here\n Potential final project datasets are here.\n Bender, Emily M. and Batya Friedman (2018). “Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science”. In: Transactions of the Association for Computational Linguistics 6, pp. 587-604. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#february-28-2023",
    "href": "schedule.html#february-28-2023",
    "title": "Schedule",
    "section": "February 28, 2023",
    "text": "February 28, 2023\n\nMaking Measures Commensurate: Translation and Reductionism\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING TRANSLATION INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Chapter 1 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n\n\n Course slides are here\n Activity link is here and here and here\n Espeland, Wendy Nelson and Mitchell L. Stevens (1998). “Commensuration as a Social Process”. In: Annual Review of Sociology 24.1. Publisher: Annual Reviews, pp. 313-343. (Visited on Aug. 30, 2021).\n Merry, Sally Engle (2016). The Seductions of Quantification: Measuring Human Rights, Gender Violence, and Sex Trafficking. En. Google-Books-ID: 0FcqDAAAQBAJ. University of Chicago Press. ISBN: 978-0-226-26131-7."
  },
  {
    "objectID": "schedule.html#march-02-2023",
    "href": "schedule.html#march-02-2023",
    "title": "Schedule",
    "section": "March 02, 2023",
    "text": "March 02, 2023\n\nEthnographies of Infrastructure\nCULTURAL ANALYSIS OF INFRASTRUCTURE BECOMING OBSERVANT INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Star, Susan Leigh (1999). “The Ethnography of Infrastructure”. En. In: American Behavioral Scientist 43.3, pp. 377-391. (Visited on Feb. 18, 2016).\n Work on semiotic analysis\n\n\n Course slides are here\n Lampland, Martha and Susan Leigh Star, ed. (2008). Standards and Their Stories: How Quantifying, Classifying, and Formalizing Practices Shape Everyday Life. 1 edition. Ithaca: Cornell University Press. ISBN: 978-0-8014-7461-3.\n Ottinger, Gwen (2010). “Buckets of Resistance: Standards and the Effectiveness of Citizen Science”. En. In: Science, Technology, & Human Values 35.2, pp. 244-270. (Visited on Oct. 05, 2019).\n Timmermans, Stefan and Steven Epstein (2010). “A World of Standards but not a Standard World: Toward a Sociology of Standards and Standardization*“. In: Annual Review of Sociology 36.1, pp. 69-89. (Visited on Oct. 16, 2014)."
  },
  {
    "objectID": "schedule.html#march-07-2023",
    "href": "schedule.html#march-07-2023",
    "title": "Schedule",
    "section": "March 07, 2023",
    "text": "March 07, 2023\n\nSorting Things Out: Cultural Analyses of Categories\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Bowker, Geoffrey C. (1998). “The Kindness of Strangers: Kinds and Politics in Classification Systems”. En. In: Library Trends 47.2, pp. 255-292. (Visited on Oct. 14, 2019).\n Be sure to get approval for the TED Talks you plan to view for Mini-Project 1.\n\n\n Bowker, Geoffrey C. and Susan Leigh Star (1999). Sorting Things Out: Classification and Its Consequences. En. Cambridge, MA: MIT Press. ISBN: 978-0-262-52295-3.\n Waterton, Claire (2002). “From Field to Fantasy: Classifying Nature, Constructing Europe”. En. In: Social Studies of Science 32.2, pp. 177-204. (Visited on May. 15, 2019).\n Kirksey, Eben (2015). “Species: a praxiographic study”. Fr. In: Journal of the Royal Anthropological Institute 21.4, pp. 758-780. (Visited on Oct. 05, 2019)."
  },
  {
    "objectID": "schedule.html#march-09-2023",
    "href": "schedule.html#march-09-2023",
    "title": "Schedule",
    "section": "March 09, 2023",
    "text": "March 09, 2023\n\nInfrastructure Field Day\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Fieldnote 2"
  },
  {
    "objectID": "schedule.html#march-21-2023",
    "href": "schedule.html#march-21-2023",
    "title": "Schedule",
    "section": "March 21, 2023",
    "text": "March 21, 2023\n\nData Ghost Work\nINTERVIEWING ANALYZING SOCIAL FORCES AND SYSTEMS LABOR\n\nDue TodayFurther Resources\n\n\n Chapter 1 , Gray, Mary L. and Siddharth Suri (2019). Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. Illustrated edition. Boston: Mariner Books. ISBN: 978-1-328-56624-9.\n Work on stakholder analysis\n\n\n Course slides are here\n Irani, Lilly (2015). Justice for “Data Janitors”. En-US. (Visited on Dec. 13, 2018).\n Plantin, Jean-Christophe (2019). “Data Cleaners for Pristine Datasets: Visibility and Invisibility of Data Processors in Social Science”. En. In: Science, Technology, & Human Values 44.1. Publisher: SAGE Publications Inc, pp. 52-73. (Visited on Aug. 20, 2021).\n Forsythe, Diana E. (1993). “The Construction of Work in Artificial Intelligence”. En. In: Science, Technology, & Human Values 18.4. Publisher: SAGE Publications Inc, pp. 460-479. (Visited on Aug. 20, 2021)."
  },
  {
    "objectID": "schedule.html#march-23-2023",
    "href": "schedule.html#march-23-2023",
    "title": "Schedule",
    "section": "March 23, 2023",
    "text": "March 23, 2023\n\nSocial Constructions of Expertise in Data Work\nINTERVIEWING INTERPRETING CULTURAL MEANING LABOR\n\nDue TodayFurther Resources\n\n\n Chapter 2 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Mini-Project 1\n\n\n Here is a link to the Final Project guide that Rose developed.\n Gieryn, Thomas F. (1999). Cultural Boundaries of Science: Credibility on the Line. En. University of Chicago Press. ISBN: 978-0-226-29261-8."
  },
  {
    "objectID": "schedule.html#march-28-2023",
    "href": "schedule.html#march-28-2023",
    "title": "Schedule",
    "section": "March 28, 2023",
    "text": "March 28, 2023\n\nHow Data Domesticates Us: Rituals for Data Cleaning\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n Ribes, David and Steven J Jackson (2013). “Data bite man: The work of sustaining a long-term study”. In: Raw data” is an oxymoron. Ed. by Lisa Gitelman. Cambridge, MA: MIT Press, pp. 147-166.\n Work on ritual analysis\n\n\n Course slides are here\n Bowker, Geoffrey C. (2000). “Biodiversity Datadiversity”. En. In: Social Studies of Science 30.5, pp. 643-683. (Visited on May. 14, 2014).\n Walford, Antonia (2017). “Raw Data: Making Relations Matter”. En_US. In: Social Analysis 61.2. Publisher: Berghahn Journals Section: Social Analysis, pp. 65-80. (Visited on Aug. 20, 2021).\n Pink, Sarah, Shanti Sumartojo, Deborah Lupton, et al. (2017). “Mundane data: The routines, contingencies and accomplishments of digital living”. En. In: Big Data & Society 4.1. Publisher: SAGE Publications Ltd, p. 2053951717700924. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#march-30-2023",
    "href": "schedule.html#march-30-2023",
    "title": "Schedule",
    "section": "March 30, 2023",
    "text": "March 30, 2023\n\nCooking Data\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n Fieldnote 3\n\n\n Course slides are here"
  },
  {
    "objectID": "schedule.html#april-04-2023",
    "href": "schedule.html#april-04-2023",
    "title": "Schedule",
    "section": "April 04, 2023",
    "text": "April 04, 2023\n\nInstitutional Incentives in Data Reporting\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n Work on institutional analysis\n\n\n Course slides are here"
  },
  {
    "objectID": "schedule.html#april-06-2023",
    "href": "schedule.html#april-06-2023",
    "title": "Schedule",
    "section": "April 06, 2023",
    "text": "April 06, 2023\n\nEconomies of Data Production: Gifts and Transactions\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n Chapter 4 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n\n\n Gerlitz, Carolin and Anne Helmond (2013). “The like economy: Social buttons and the data-intensive web”. En. In: New Media & Society 15.8. Publisher: SAGE Publications, pp. 1348-1365. (Visited on Aug. 30, 2021).\n Beer, David (2015). “Productive measures: Culture and measurement in the context of everyday neoliberalism”. En. In: Big Data & Society 2.1. Publisher: SAGE Publications Ltd, p. 2053951715578951. (Visited on Aug. 29, 2021)."
  },
  {
    "objectID": "schedule.html#april-11-2023",
    "href": "schedule.html#april-11-2023",
    "title": "Schedule",
    "section": "April 11, 2023",
    "text": "April 11, 2023\n\nMobilizing Data: Making Numbers Actionable\nDISCOURSE ANALYSIS SITUATING KNOWLEDGE MOBILIZATION\n\nDue TodayFurther Resources\n\n\n Ottinger, Gwen and Rachel Zurer (2011). New Voices, New Approaches: Drowning in Data. En-US. (Visited on Dec. 13, 2018).\n Work on discourse analysis\n Mini-Project 2\n\n\n Course slides are here.\n Pine, Kathleen H. and Max Liboiron (2015). “The Politics of Measurement and Action”. In: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery, pp. 3147-3156. ISBN: 978-1-4503-3145-6. (Visited on Aug. 30, 2021).\n Dourish, Paul and Edgar Gómez Cruz (2018). “Datafication and data fiction: Narrating data and narrating with data”. En. In: Big Data & Society 5.2. Publisher: SAGE Publications Ltd, p. 2053951718784083. (Visited on Apr. 05, 2021)."
  },
  {
    "objectID": "schedule.html#april-13-2023",
    "href": "schedule.html#april-13-2023",
    "title": "Schedule",
    "section": "April 13, 2023",
    "text": "April 13, 2023\n\nData Circulation\nDISCOURSE ANALYSIS COMMUNICATING (IN) CONTEXT MOBILIZATION\n\nDue TodayFurther Resources\n\n\n Fieldnote 4\n\n\n Bates, Jo, Yu-Wei Lin, and Paula Goodale (2016). “Data journeys: Capturing the socio-material constitution of data objects and flows”. En. In: Big Data & Society 3.2. Publisher: SAGE Publications Ltd, p. 2053951716654502. (Visited on Mar. 28, 2020).\n Leonelli, Sabina (2010). “Packaging Small Fact for Re-use: Databases in Model Organism Biology”. En. In: How Well Do Facts Travel?: The Dissemination of Reliable Knowledge. Ed. by Peter Howlett and Mary S. Morgan. Cambridge, MA: Cambridge University Press, pp. 325-348. ISBN: 978-1-139-49239-3."
  },
  {
    "objectID": "schedule.html#april-18-2023",
    "href": "schedule.html#april-18-2023",
    "title": "Schedule",
    "section": "April 18, 2023",
    "text": "April 18, 2023\n\nMobilizing Data Otherwise: Citizen Science and Sensing\nDISCOURSE SITUATING KNOWLEDGE MOBILIZATION CREDIBILITY\n\nDue TodayFurther Resources\n\n\n Gabrys, Jennifer, Helen Pritchard, and Benjamin Barratt (2016). “Just good enough data: Figuring data citizenships through air pollution sensing and data stories”. En. In: Big Data & Society 3.2. Publisher: SAGE Publications Ltd, p. 2053951716679677. (Visited on Mar. 28, 2020).\n\n\n Course slides are here.\n Calvillo, Nerea (2018). “Political airs: From monitoring to attuned sensing air pollution”. En. In: Social Studies of Science 48.3, pp. 372-388. (Visited on Sep. 24, 2019).\n Jalbert, Kirk and Abby J. Kinchy (2016). “Sense and Influence: Environmental Monitoring Tools and the Power of Citizen Science”. In: Journal of Environmental Policy & Planning 18.3. Publisher: Routledge _ eprint: https://doi.org/10.1080/1523908X.2015.1100985, pp. 379-397. (Visited on Aug. 30, 2021)."
  },
  {
    "objectID": "schedule.html#april-20-2023",
    "href": "schedule.html#april-20-2023",
    "title": "Schedule",
    "section": "April 20, 2023",
    "text": "April 20, 2023\n\nData Activism and Advocacy\nSITUATING KNOWLEDGE MOBILIZATION CREDIBILITY\n\nDue TodayFurther Resources\n\n\n Liboiron, Max (2015). “Disaster Data, Data Activism : Grassroots Responses to Representing Superstorm Sandy”. En. In: Extreme Weather and Global Media. Ed. by Julia Leyda and Diane Negra. Taylor & Francis Group. (Visited on Aug. 27, 2019).\n\n\n Bruno, Isabelle, Emmanuel Didier, and Tommaso Vitale (2014). Statactivism: Forms of Action between Disclosure and Affirmation. En. SSRN Scholarly Paper ID 2466882. Rochester, NY: Social Science Research Network. (Visited on Dec. 18, 2018).\n Milan, Stefania and Lonneke van der Velden (2016). “The Alternative Epistemologies of Data Activism”. In: Digital Culture & Society 2.2, pp. 57-74. (Visited on Jul. 16, 2019).\n Currie, Morgan, Britt S Paris, Irene Pasquetto, et al. (2016). “The conundrum of police officer-involved homicides: Counter-data in Los Angeles County”. En. In: Big Data & Society 3.2, p. 2053951716663566. (Visited on Aug. 08, 2018)."
  },
  {
    "objectID": "schedule.html#april-25-2023",
    "href": "schedule.html#april-25-2023",
    "title": "Schedule",
    "section": "April 25, 2023",
    "text": "April 25, 2023\n\nData Agnotology: Ignorance and Knowledge Gaps\nEPISTEMOLOGY IGNORANCE SITUATING KNOWLEDGE\n\nDue TodayFurther Resources\n\n\n mimimimimi (2021). On Missing Data Sets. original-date: 2016-02-03T16:30:28Z. (Visited on Aug. 20, 2021).\n Milan, Stefania and Emiliano Treré (2020). “The Rise of the Data Poor: The COVID-19 Pandemic Seen From the Margins”. En. In: Social Media + Society 6.3. Publisher: SAGE Publications Ltd, p. 2056305120948233. (Visited on Aug. 31, 2021).\n First draft due\n\n\n Course slides are here\n D’Ignazio, Catherine and Lauren F. Klein (2020). Data Feminism. Cambridge, Massachusetts: The MIT Press. ISBN: 978-0-262-04400-4."
  },
  {
    "objectID": "schedule.html#april-27-2023",
    "href": "schedule.html#april-27-2023",
    "title": "Schedule",
    "section": "April 27, 2023",
    "text": "April 27, 2023\n\nData and Algorithmic Power\nPOWER SITUATING KNOWLEDGE EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n Eubanks, Virginia (2018). “A Child Abuse Prediction Model Fails Poor Families”. In: Wired. (Visited on Mar. 28, 2019).\n Fieldnote 5\n\n\n Brayne, Sarah (2017). “Big Data Surveillance: The Case of Policing”. In: American Sociological Review 82.5. Publisher: SAGE Publications Inc, pp. 977-1008. (Visited on Aug. 18, 2021).\n Christin, Angèle (2020). “The ethnographer and the algorithm: beyond the black box”. En. In: Theory and Society 49.5, pp. 897-918. (Visited on Aug. 31, 2021).\n Seaver, Nick (2017). “Algorithms as culture: Some tactics for the ethnography of algorithmic systems”. En. In: Big Data & Society 4.2. Publisher: SAGE Publications Ltd, p. 2053951717738104. (Visited on Jan. 22, 2021)."
  },
  {
    "objectID": "schedule.html#may-02-2023",
    "href": "schedule.html#may-02-2023",
    "title": "Schedule",
    "section": "May 02, 2023",
    "text": "May 02, 2023\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Mini-Project Revisions"
  },
  {
    "objectID": "schedule.html#may-04-2023",
    "href": "schedule.html#may-04-2023",
    "title": "Schedule",
    "section": "May 04, 2023",
    "text": "May 04, 2023\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Final project due\n Enrichment"
  },
  {
    "objectID": "slides/Day3-BigDataDiscourse.html#feminist-epistemologies",
    "href": "slides/Day3-BigDataDiscourse.html#feminist-epistemologies",
    "title": "Day Three: Big Data Discourse",
    "section": "Feminist Epistemologies",
    "text": "Feminist Epistemologies\n\nAll knowledge is embodied\n\nContrast with disembodied knowledge - i.e. not tied to a specific body\n\nBodies are situated in certain social positions and have a finite point of view (Haraway 1991)\n\nCritique of the “unmarked body,” the “God trick,” or the “view from nowhere”\n\nKnowledge is tied to particular standpoints\n\nOur experiences, what we’ve read, our education, our social positions, and what our bodies enable us to do, see, hear, taste, touch, and smell\nFactors are innumerable and unique to every person"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#announcements",
    "href": "slides/Day4-BinaryOppositions.html#announcements",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Announcements",
    "text": "Announcements\n\nPlease merge your branches into main!\nBe sure not to close the Feedback pull request.\nBe sure to fill out CATME survey for next week."
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day4-BinaryOppositions.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhat data discourses are the words you wrote on the left side embedded within?\nCan you identify any terms that might fit in between these opposites?"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#binary-oppositions",
    "href": "slides/Day4-BinaryOppositions.html#binary-oppositions",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Binary Oppositions",
    "text": "Binary Oppositions\n\nLooking at the world through pairs of terms that we consider to have the opposite meaning\nExamples include:\n\nReal/fake\nObjective/subjective\nNature/culture\n\nBinary oppositions are reductionist, or oversimplify complexity\nBinary oppositions are rooted in ideologies and disseminated through discourse"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#hierarchies-in-binary-oppositions",
    "href": "slides/Day4-BinaryOppositions.html#hierarchies-in-binary-oppositions",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Hierarchies in Binary Oppositions",
    "text": "Hierarchies in Binary Oppositions\n\nIn dominant discourse, one half of a binary opposition tends to be positioned as superior than the other\nOne half tends to get treated as normal or pure, and other as a deviation from the normal, or tainted\nBinary oppositions can reinforce privilege\nWhat are some examples of some hiearchical binary oppositions?"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#natureculture",
    "href": "slides/Day4-BinaryOppositions.html#natureculture",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Nature/Culture",
    "text": "Nature/Culture\n\nCountless domains (disciplines, newspaper headings, etc.) organized around the divisions between nature and culture\nNature is often associated with purity, innateness, biology, or rawness.\nCulture is seen as ‘Other’ to what is natural\n\ne.g. human judgments bias science and decision-making\ne.g. human cultures destroy the Earth’s purity\n\nFeminist critiques:\n\nShows how purity is political\nArgues that we can’t tell where nature stops and culture starts\nShows how the divisions justify treating certain social groups as superior and others as inferior\nRefers to natureculture: hybrids reverse the logic of binary oppositions"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#activity",
    "href": "slides/Day4-BinaryOppositions.html#activity",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "slides/Day4-BinaryOppositions.html#pull-out-a-piece-of-paper-and-draw-a-line-down-the-center.-on-the-left-side-list-adjectives-that-people-use-to-describe-good-data.-on-the-right-side-write-the-opposite-of-each-word-you-wrote-on-the-left-side.",
    "href": "slides/Day4-BinaryOppositions.html#pull-out-a-piece-of-paper-and-draw-a-line-down-the-center.-on-the-left-side-list-adjectives-that-people-use-to-describe-good-data.-on-the-right-side-write-the-opposite-of-each-word-you-wrote-on-the-left-side.",
    "title": "Day Four: Binary Oppositions of Big Data",
    "section": "Pull out a piece of paper, and draw a line down the center. On the left side, list adjectives that people use to describe “good” data. On the right side, write the opposite of each word you wrote on the left side.",
    "text": "Pull out a piece of paper, and draw a line down the center. On the left side, list adjectives that people use to describe “good” data. On the right side, write the opposite of each word you wrote on the left side."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#announcements",
    "href": "slides/Day5-ThickDescription.html#announcements",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Announcements",
    "text": "Announcements\n\nYou will be assigned project groups by Tuesday.\nYour first group project - the team contract - will be due the following week.\nDM Rose if you’d like to lead class discussion."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day5-ThickDescription.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nHow would these research projects look different?\nWhat kind of data would you collect?\nHow would you interpret the data differently?"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#discliplinary-conventions",
    "href": "slides/Day5-ThickDescription.html#discliplinary-conventions",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Discliplinary Conventions",
    "text": "Discliplinary Conventions\n\nWhat is considered a relevant research question?\nWhat kind of arguments are made?\nWhat kind of data is collected/produced/presented?\nHow is collaboration valued?\nWhen/how is data shared?"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#disciplinary-genres",
    "href": "slides/Day5-ThickDescription.html#disciplinary-genres",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Disciplinary Genres",
    "text": "Disciplinary Genres\n\nIs text written in active or passive voice? Personal pronouns?\nAre subheadings chosen based on academic conventions?\nWhat kind of evidence is presented to persuade the reader? Statistics? Anecdotes?\nIn what ways are research methods explicated?\nHow and with what sort of detail are objects of study described?\nWhat role do poetics and metaphor play in the text? Can you identify emotion?\nWhat reflexive moves (self-reflection) does the author make? How do they elaborate their standpoint in/through the text?"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#what-is-ethnography",
    "href": "slides/Day5-ThickDescription.html#what-is-ethnography",
    "title": "Day Five: Thick Data for Big Data",
    "section": "What is ethnography?",
    "text": "What is ethnography?\n\nStudy of human cultures\n\nCulture often defined as “semiotic”\nEthnographers aim to interpret the underlying meanings of surface actions and expressions\nMake the “familiar strange”\n\nOften characterized as interpretivist and qualitative\nTypically involves extended, immersive fieldwork\nHas historically been a solo discipline\nQualitative data rarely shared"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#methods-of-ethnography",
    "href": "slides/Day5-ThickDescription.html#methods-of-ethnography",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Methods of Ethnography",
    "text": "Methods of Ethnography\n\nParticipant Observation\n\nObserving interaction and behaviors “in the field”\n\nInterviewing\n\nEngaging in semi-structured conversations with informants\n\nArchival Research\n\nCurating and interpreting historical documents and artifacts\n\nDiscourse analysis\n\nInterpreting the cultural meaning interwoven in texts and speech"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#tools-of-ethnography",
    "href": "slides/Day5-ThickDescription.html#tools-of-ethnography",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Tools of Ethnography",
    "text": "Tools of Ethnography\n\nField Notebooks\n\nDocument thick descriptions of observations\n\nRecording Devices\n\nAudio and video documentation of interviews\n\nCoding Software\n\nDraw out consistent themes of notes and interviews"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#what-is-thick-description",
    "href": "slides/Day5-ThickDescription.html#what-is-thick-description",
    "title": "Day Five: Thick Data for Big Data",
    "section": "What is thick description?",
    "text": "What is thick description?\n\n\n\n\n\nDescribe in the “thinnest” terms possible what is happening in this image.\nThick description moves towards interpreting its cultural meaning.\nExample drawn from a famous 1973 chapter by Clifford Geertz: “Thick Description: Towards an Interpretive Theory of Culture.”"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#practicing-thick-description",
    "href": "slides/Day5-ThickDescription.html#practicing-thick-description",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Practicing Thick Description",
    "text": "Practicing Thick Description\n Image source: XKCD, https://xkcd.com/1838/\nCreative Commons Attribution-NonCommercial 2.5 License."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#how-might-we-interpret-the-role-of-hex-stickers-in-the-r-community",
    "href": "slides/Day5-ThickDescription.html#how-might-we-interpret-the-role-of-hex-stickers-in-the-r-community",
    "title": "Day Five: Thick Data for Big Data",
    "section": "How might we interpret the role of hex stickers in the R community?",
    "text": "How might we interpret the role of hex stickers in the R community?\n Image source: Beiers, Sophie. 2020. “Tips & Tricks from the Newbies of Rstudio::Conf2020.” ACLU Tech & Analytics (blog). March 13, 2020. https://medium.com/aclu-tech-analytics/tips-tricks-from-the-newbies-of-rstudio-conf2020-5ccc780ba0e7."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#fieldnotes-assignment",
    "href": "slides/Day5-ThickDescription.html#fieldnotes-assignment",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Fieldnotes Assignment",
    "text": "Fieldnotes Assignment\n\nSubmitted via your GitHub portfolio\nMust be >300 words\nMust include and define one Knowledge and Understanding concept\nMust be about a data environment encountered in the past two weeks\nMust not only describe, but also interpret a data environment"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#mondays-reading",
    "href": "slides/Day5-ThickDescription.html#mondays-reading",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Monday’s Reading",
    "text": "Monday’s Reading\n\nWhat are Biruk’s research questions?\nWhat does Biruk make known about her assumptions/beliefs/values as she begins to interpret data?"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#recommendations",
    "href": "slides/Day5-ThickDescription.html#recommendations",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Recommendations",
    "text": "Recommendations\n\nDiscern something very small - the smaller the better - for your first field note.\nExamples include one headline, a poster, one line of code, etc.\nStick with prompts and concepts that we’ve already learned (e.g. discourse, epistemology).\nReview the rubric on GitHub"
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#imagine-you-were-an-ethnographer-attending-astro-hack-week.-write-a-quantitative-research-question-for-a-study-you-might-conduct.-now-write-a-qualitative-research-question.",
    "href": "slides/Day5-ThickDescription.html#imagine-you-were-an-ethnographer-attending-astro-hack-week.-write-a-quantitative-research-question-for-a-study-you-might-conduct.-now-write-a-qualitative-research-question.",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Imagine you were an ethnographer attending Astro Hack Week. Write a quantitative research question for a study you might conduct. Now write a qualitative research question.",
    "text": "Imagine you were an ethnographer attending Astro Hack Week. Write a quantitative research question for a study you might conduct. Now write a qualitative research question."
  },
  {
    "objectID": "slides/Day5-ThickDescription.html#tuesdays-reading",
    "href": "slides/Day5-ThickDescription.html#tuesdays-reading",
    "title": "Day Five: Thick Data for Big Data",
    "section": "Tuesday’s Reading",
    "text": "Tuesday’s Reading\n\nWhat are Biruk’s research questions?\nWhat does Biruk make known about her assumptions/beliefs/values as she begins to interpret data?"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#imagine-that-you-are-an-ethnographer-attending-astro-hack-week.-pull-out-a-sheet-of-paper-and-jot-your-name-in-the-center.-around-your-name-list-aspects-of-your-cultural-identity-that-would-be-important-to-acknowledge-as-you-studied-this-space.",
    "href": "slides/Day6-Reflexivity.html#imagine-that-you-are-an-ethnographer-attending-astro-hack-week.-pull-out-a-sheet-of-paper-and-jot-your-name-in-the-center.-around-your-name-list-aspects-of-your-cultural-identity-that-would-be-important-to-acknowledge-as-you-studied-this-space.",
    "title": "Day Six: Reflexivity",
    "section": "Imagine that you are an ethnographer attending Astro Hack Week. Pull out a sheet of paper and jot your name in the center. Around your name, list aspects of your cultural identity that would be important to acknowledge as you studied this space.",
    "text": "Imagine that you are an ethnographer attending Astro Hack Week. Pull out a sheet of paper and jot your name in the center. Around your name, list aspects of your cultural identity that would be important to acknowledge as you studied this space."
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day6-Reflexivity.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Six: Reflexivity",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhy would it be important to consider these aspects of your cultural identity as you engaged in ethnographic fieldwork?"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#critiques-and-criticisms-of-ethnographic-research",
    "href": "slides/Day6-Reflexivity.html#critiques-and-criticisms-of-ethnographic-research",
    "title": "Day Six: Reflexivity",
    "section": "Critiques and Criticisms of Ethnographic Research",
    "text": "Critiques and Criticisms of Ethnographic Research\n\nEthnographic research (like many other forms of research) has been historically complicit in imperialism and colonialism\nMethods emerged as part of European colonial efforts to document folks “Native” to “other” lands - often to enable control and exploitation of those cultures\nMany binary oppositions indicate how power operated here:\n\nStudier/studied\nResearcher/researched\n\nConcerns over who gets to “write culture”"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#reflexive-turn",
    "href": "slides/Day6-Reflexivity.html#reflexive-turn",
    "title": "Day Six: Reflexivity",
    "section": "Reflexive Turn",
    "text": "Reflexive Turn\n\nEmerged in the 1970s as a result of feminist and post-colonial critiques\n\nFeminist: Where do we stand? Can we ever observe from an objective or neutral place?\nPost-colonial: What do we consider “Other,” and how do we portray what is “Other”?\n\nCalled on ethnographers to engage in self-reflection (standpoints, assumptions, etc.)\nCan we write another culture “objectively” when our own biases and epistemologies, and social capital are inevitably involved in the research?"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#aka-the-literary-turn",
    "href": "slides/Day6-Reflexivity.html#aka-the-literary-turn",
    "title": "Day Six: Reflexivity",
    "section": "…aka the Literary Turn",
    "text": "…aka the Literary Turn\n\nEthnography was often understood to be about writing (documenting observations and interpreting them)\nBegan to pay attention to power in the language used to “write culture”\n\nBinary oppositions\nGenre and representations of “fact”\n\nCalled for making ethnographic writing more polyphonous (or represent a plurality of voices)\nSometimes invited “poetics” and “experimentalism”\n\n\nIn other words, there are political reasons as to why the fieldnotes that you read felt different than other scientific genres!"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#reflexivity-for-each-of-our-methods",
    "href": "slides/Day6-Reflexivity.html#reflexivity-for-each-of-our-methods",
    "title": "Day Six: Reflexivity",
    "section": "Reflexivity for Each of our Methods",
    "text": "Reflexivity for Each of our Methods\n\nParticipant Observation\n\nObserving interaction and behaviors “in the field”\n\nInterviewing\n\nEngaging in semi-structured conversations with informants\n\nArchival Research\n\nCurating and interpreting historical documents and artifacts\n\nDiscourse analysis\n\nInterpreting the cultural meaning interwoven in texts and speech\n\n\n\nIn your groups, be sure to introduce yourselves to each other (pronouns, majors, etc.)"
  },
  {
    "objectID": "slides/Day6-Reflexivity.html#infrastructure-overview",
    "href": "slides/Day6-Reflexivity.html#infrastructure-overview",
    "title": "Day Six: Reflexivity",
    "section": "Infrastructure Overview",
    "text": "Infrastructure Overview\n\nGroup project\nFirst fieldnote\nReview of labor log"
  },
  {
    "objectID": "slides/Day7-Looping.html#announcements",
    "href": "slides/Day7-Looping.html#announcements",
    "title": "Day Seven: Data Looping Effects",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours for help with labor log.\nGroup contract and first field note due next Tuesday."
  },
  {
    "objectID": "slides/Day7-Looping.html#think-about-a-category-or-label-that-institutions-assign-to-a-group-of-people.-free-write-for-about-2-minutes-on-the-following-prompt-how-does-the-existence-of-this-category-or-label-impact-certain-social-groups",
    "href": "slides/Day7-Looping.html#think-about-a-category-or-label-that-institutions-assign-to-a-group-of-people.-free-write-for-about-2-minutes-on-the-following-prompt-how-does-the-existence-of-this-category-or-label-impact-certain-social-groups",
    "title": "Day Seven: Data Looping Effects",
    "section": "Think about a category or label that institutions assign to a group of people. Free-write for about 2 minutes on the following prompt: How does the existence of this category or label impact certain social groups?",
    "text": "Think about a category or label that institutions assign to a group of people. Free-write for about 2 minutes on the following prompt: How does the existence of this category or label impact certain social groups?"
  },
  {
    "objectID": "slides/Day7-Looping.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day7-Looping.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Seven: Data Looping Effects",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhy does this category or label exist?\nIn what ways has this category or label been normalized in society?\nWhat happens when folks don’t agree with the assignment? Can they contest it?"
  },
  {
    "objectID": "slides/Day7-Looping.html#assemblages",
    "href": "slides/Day7-Looping.html#assemblages",
    "title": "Day Seven: Data Looping Effects",
    "section": "Assemblages",
    "text": "Assemblages\n\nContests the idea that data are hard, shiny objects that can be held, acquired, etc.\nWhen we talk about data, we are actually referring to many interrelated things:\n\nMaterialities, practices, subjectivities, places, governmentalities, etc.\nSee table in this week’s reading\n\n“Data” emerges in the wake of these interrelated assemblages"
  },
  {
    "objectID": "slides/Day7-Looping.html#hackings-looping-effect",
    "href": "slides/Day7-Looping.html#hackings-looping-effect",
    "title": "Day Seven: Data Looping Effects",
    "section": "Hacking’s Looping Effect",
    "text": "Hacking’s Looping Effect\n > Tekin, Serife. 2014. “The Missing Self in Hacking’s Looping Effect.” In Classifying Psychopathology: Mental Kinds and Natural Kinds, edited by Harold Kincaid and Jacqueline A. Sullivan. MIT Press."
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#ws-of-metadata",
    "href": "slides/Day9-DataDocumentation.html#ws-of-metadata",
    "title": "Day Nine: Data Documentation",
    "section": "5 W’s of Metadata",
    "text": "5 W’s of Metadata"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#example-library-catalog",
    "href": "slides/Day9-DataDocumentation.html#example-library-catalog",
    "title": "Day Nine: Data Documentation",
    "section": "Example: Library Catalog",
    "text": "Example: Library Catalog"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#metadata-schemas",
    "href": "slides/Day9-DataDocumentation.html#metadata-schemas",
    "title": "Day Nine: Data Documentation",
    "section": "Metadata Schemas",
    "text": "Metadata Schemas\n\nA standardized labeling system for cataloging or describing data\nEnables search engines to index data by certain criteria\nExamples:\n\nSort by “date created”\nRetrieve all results from a specific “author/creator”\nFilter results to a specific “subject”\nExclude results from a specific “publisher”"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#example-citation-manager",
    "href": "slides/Day9-DataDocumentation.html#example-citation-manager",
    "title": "Day Nine: Data Documentation",
    "section": "Example: Citation Manager",
    "text": "Example: Citation Manager"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#whats-the-difference-between-administrative-and-descriptive-metadata",
    "href": "slides/Day9-DataDocumentation.html#whats-the-difference-between-administrative-and-descriptive-metadata",
    "title": "Day Nine: Data Documentation",
    "section": "What’s the difference between administrative and descriptive metadata?",
    "text": "What’s the difference between administrative and descriptive metadata?"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#data-dictionaries",
    "href": "slides/Day9-DataDocumentation.html#data-dictionaries",
    "title": "Day Nine: Data Documentation",
    "section": "Data Dictionaries",
    "text": "Data Dictionaries\n\nDocuments for holding descriptive metadata\nDefine the variables in a dataset and the values that may fill in those variables\nAre not always as descriptive as we’d like them to be"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#example-nyc-metadata-for-all",
    "href": "slides/Day9-DataDocumentation.html#example-nyc-metadata-for-all",
    "title": "Day Nine: Data Documentation",
    "section": "Example: NYC Metadata for All",
    "text": "Example: NYC Metadata for All"
  },
  {
    "objectID": "slides/Day9-DataDocumentation.html#for-monday",
    "href": "slides/Day9-DataDocumentation.html#for-monday",
    "title": "Day Nine: Data Documentation",
    "section": "For Monday",
    "text": "For Monday\n\nQuestions to consider:\n\nWhat does Biruk mean when they refer to “translation” in this chapter?\nWhere do we see looping effects in this chapter? What gets “lost in translation”?"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#free-write-for-the-next-2-minutes-youve-submitted-your-first-assignment---both-individual-and-group.-what-have-you-learned-so-far-thats-sticking-with-you-the-most-what-questions-do-you-have-about-course-infrastructure-what-challenges-have-you-run-into",
    "href": "slides/Day8-ResearchEthics.html#free-write-for-the-next-2-minutes-youve-submitted-your-first-assignment---both-individual-and-group.-what-have-you-learned-so-far-thats-sticking-with-you-the-most-what-questions-do-you-have-about-course-infrastructure-what-challenges-have-you-run-into",
    "title": "Day Eight: Research Ethics",
    "section": "Free-write for the next 2 minutes: You’ve submitted your first assignment - both individual and group. What have you learned so far that’s sticking with you the most? What questions do you have about course infrastructure? What challenges have you run into?",
    "text": "Free-write for the next 2 minutes: You’ve submitted your first assignment - both individual and group. What have you learned so far that’s sticking with you the most? What questions do you have about course infrastructure? What challenges have you run into?"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#i-encourage-you-to-come-to-office-hours-if",
    "href": "slides/Day8-ResearchEthics.html#i-encourage-you-to-come-to-office-hours-if",
    "title": "Day Eight: Research Ethics",
    "section": "I encourage you to come to office hours if…",
    "text": "I encourage you to come to office hours if…\n\nYou’d like to discuss strategies for managing the reading/workload.\nYou’d like clarifications on any of the assignment expectations/course infrastructure.\nYou’d like to review certain concepts discussed in lecture or the readings.\nYou’d like to chat about opportunities for exploring more about data ethnography.\nYou’re stressed and need some positive affirmation."
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#common-rule",
    "href": "slides/Day8-ResearchEthics.html#common-rule",
    "title": "Day Eight: Research Ethics",
    "section": "Common Rule",
    "text": "Common Rule\n\nIn the US, research organizations receiving federal funding are subject to the Common Rule\n\nLaws and regulations regarding how Institutional Review Boards are to operate\nIRBs are organizational bodies that review the ethics of human subjects research in order to protect human welfare, rights, and privacy before a study gets carried out\n\nUsually composed of representatives from an institution with a diverse background"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#tuskegee-study",
    "href": "slides/Day8-ResearchEthics.html#tuskegee-study",
    "title": "Day Eight: Research Ethics",
    "section": "Tuskegee Study",
    "text": "Tuskegee Study\n\nConducted from 1932 to 1972 by US Public Health Services and Center for Disease Control, in collaboration with Tuskegee University in Alabama\nInvolved 400 African Americans with syphilis\nStudy of leaving the disease untreated even though it was treatable\n\nWere told they would receive free medical care\nNever informed of their diagnosis\nProvided with placebos and ineffective methods"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#facebooks-emotional-contagion-study",
    "href": "slides/Day8-ResearchEthics.html#facebooks-emotional-contagion-study",
    "title": "Day Eight: Research Ethics",
    "section": "Facebook’s Emotional Contagion Study",
    "text": "Facebook’s Emotional Contagion Study\n\nJanuary 2012, Facebook data scientists manipulated what 700,000 users saw on feeds to examine emotional contagion\n\nSome shown happy, positive content\nOthers shown sad, negative content\n\nLegal?\nEthical?"
  },
  {
    "objectID": "slides/Day8-ResearchEthics.html#ethics-of-ethnographic-research",
    "href": "slides/Day8-ResearchEthics.html#ethics-of-ethnographic-research",
    "title": "Day Eight: Research Ethics",
    "section": "Ethics of ethnographic research",
    "text": "Ethics of ethnographic research\n\nEthnography different than many other forms of human subjects research in that it takes place in natural settings vs in clinical settings\nQuestion of how to balance benefits of the research with the potential harms posed to the participants\nPotential harms:\n\nReputation\nDisclosure of personal information\nDisruption of relationships\nLoss of claims"
  },
  {
    "objectID": "slides/Day10-Translation.html#take-out-a-sheet-of-paper-and-write-happiness-in-the-middle.-around-that-word-list-ways-that-we-might-quantitatively-measure-happiness-so-that-we-might-rank-countries-by-their-happiness.-be-sure-your-ideas-would-produce-a-number.",
    "href": "slides/Day10-Translation.html#take-out-a-sheet-of-paper-and-write-happiness-in-the-middle.-around-that-word-list-ways-that-we-might-quantitatively-measure-happiness-so-that-we-might-rank-countries-by-their-happiness.-be-sure-your-ideas-would-produce-a-number.",
    "title": "Day Ten: Translation",
    "section": "Take out a sheet of paper and write happiness in the middle. Around that word, list ways that we might quantitatively measure happiness so that we might rank countries by their happiness. Be sure your ideas would produce a number.",
    "text": "Take out a sheet of paper and write happiness in the middle. Around that word, list ways that we might quantitatively measure happiness so that we might rank countries by their happiness. Be sure your ideas would produce a number."
  },
  {
    "objectID": "slides/Day10-Translation.html#cantril-ladder",
    "href": "slides/Day10-Translation.html#cantril-ladder",
    "title": "Day Ten: Translation",
    "section": "Cantril Ladder",
    "text": "Cantril Ladder\n\nThink of a ladder, with the best possible life for them being a 10, and the worst possible life being a 0.\nRate current lives on that 0 to 10 scale.\nSub-bars: levels of GDP, life expectancy, generosity, social support, freedom, and corruption\n\nNo impact on final score, only explanatory"
  },
  {
    "objectID": "slides/Day10-Translation.html#example",
    "href": "slides/Day10-Translation.html#example",
    "title": "Day Ten: Translation",
    "section": "Example",
    "text": "Example\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nPg. 48 “Are you comfortable walking to the market alone?”\nWhat were the responses?\nHow would you interpret what Biruk is seeing here? What’s the significance of this example?"
  },
  {
    "objectID": "slides/Day10-Translation.html#example-1",
    "href": "slides/Day10-Translation.html#example-1",
    "title": "Day Ten: Translation",
    "section": "Example",
    "text": "Example\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nPg. 61: Question D13\nWhat does Biruk describe as the “fetish for codes?”\nHow would you interpret what Biruk is seeing here?\nWhat’s the significance of this example?"
  },
  {
    "objectID": "slides/Day10-Translation.html#example-2",
    "href": "slides/Day10-Translation.html#example-2",
    "title": "Day Ten: Translation",
    "section": "Example",
    "text": "Example\n\nResearch question: How do on-the-ground dynamics and practices of survey research cultures mediate the production of numbers?\nWhy does Biruk emphasize how stakeholders perceive “the field”? How would you interpret what Biruk is seeing here? What’s the significance of this?"
  },
  {
    "objectID": "slides/Day10-Translation.html#global-multidimensional-poverty-index",
    "href": "slides/Day10-Translation.html#global-multidimensional-poverty-index",
    "title": "Day Ten: Translation",
    "section": "Global Multidimensional Poverty Index",
    "text": "Global Multidimensional Poverty Index\n\n\n\n\n\nUNDP Human Development Report\n\n\n\n\nIndex that measures degrees of poverty in developing countries\nComplements monetary poverty measures by capturing other dimensions of poverty"
  },
  {
    "objectID": "slides/Day10-Translation.html#activity",
    "href": "slides/Day10-Translation.html#activity",
    "title": "Day Ten: Translation",
    "section": "Activity",
    "text": "Activity\n\nWhat is the purpose of this measure?\nWhat is the definition of poverty according to this standard?\nThrough what means did this definition get established?\nWhat assumptions are built into this definition?\nWhat might get lost in translation?"
  },
  {
    "objectID": "slides/Day10-Translation.html#discussion-questions",
    "href": "slides/Day10-Translation.html#discussion-questions",
    "title": "Day Ten: Translation",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nWhy is pain difficult to quantify?\nWhat is the definition of pain in this standard?\nHow did the folks devising this standard attempt to make the measures commensurate?\nWhat might get lost in translation?"
  },
  {
    "objectID": "slides/Day10-Translation.html#analyzing-poverty-definitions-activity-if-time",
    "href": "slides/Day10-Translation.html#analyzing-poverty-definitions-activity-if-time",
    "title": "Day Ten: Translation",
    "section": "Analyzing Poverty Definitions Activity (if time)",
    "text": "Analyzing Poverty Definitions Activity (if time)\n\nWhat is the purpose of this measure?\nWhat is the definition of poverty according to this standard?\nThrough what means did this definition get established?\nWhat assumptions are built into this definition?\nWhat might get lost in translation?"
  },
  {
    "objectID": "slides/Day11-Infrastructure.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day11-Infrastructure.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Eleven: Ethnographies of Infrastructure",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nHow often do you think about this infrastructure? Did you notice it pre-breakdown?\nWho has a say in the design of this infrastructure, and who is excluded?"
  },
  {
    "objectID": "slides/Day11-Infrastructure.html#stars-definition-of-infrastructure",
    "href": "slides/Day11-Infrastructure.html#stars-definition-of-infrastructure",
    "title": "Day Eleven: Ethnographies of Infrastructure",
    "section": "Star’s Definition of Infrastructure",
    "text": "Star’s Definition of Infrastructure\n\nEmbeddedness: Sunk into other socio-technical structures\nTransparency: Does not need to continuously be reassembled\nReach or Scope: Connects more than one site\nLearned as part of membership: Use naturalized through communities of practice\nEmbodiment of standards: Component parts can connect through standardized conventions\nBuilt on an installed base: Wrestles with the logics of its underlying infrastructures\nVisible upon breakdown: Often taken for granted until breaking"
  },
  {
    "objectID": "slides/Day11-Infrastructure.html#identify-something-that-meets-stars-definition-of-an-infrastructure.-jot-down-some-ideas-about-howwhen-this-infrastructure-has-broken-down.",
    "href": "slides/Day11-Infrastructure.html#identify-something-that-meets-stars-definition-of-an-infrastructure.-jot-down-some-ideas-about-howwhen-this-infrastructure-has-broken-down.",
    "title": "Day Eleven: Ethnographies of Infrastructure",
    "section": "Identify something that meets Star’s definition of an infrastructure. Jot down some ideas about how/when this infrastructure has broken down.",
    "text": "Identify something that meets Star’s definition of an infrastructure. Jot down some ideas about how/when this infrastructure has broken down."
  },
  {
    "objectID": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-of-your-work.",
    "href": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-of-your-work.",
    "title": "Day Twelve: Classification",
    "section": "Identify a classification system that structures some of your work.",
    "text": "Identify a classification system that structures some of your work."
  },
  {
    "objectID": "slides/Day12-Classification.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day12-Classification.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Twelve: Classification",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhat is the master narrative running through this classification system?"
  },
  {
    "objectID": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-aspect-of-your-work.",
    "href": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-aspect-of-your-work.",
    "title": "Day Twelve: Classification",
    "section": "Identify a classification system that structures some aspect of your “work”.",
    "text": "Identify a classification system that structures some aspect of your “work”."
  },
  {
    "objectID": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-aspect-of-your-work.-how-are-concepts-organized-in-this-classification-system",
    "href": "slides/Day12-Classification.html#identify-a-classification-system-that-structures-some-aspect-of-your-work.-how-are-concepts-organized-in-this-classification-system",
    "title": "Day Twelve: Classification",
    "section": "Identify a classification system that structures some aspect of your “work”. How are concepts organized in this classification system?",
    "text": "Identify a classification system that structures some aspect of your “work”. How are concepts organized in this classification system?"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#reminders",
    "href": "slides/Day13-Interviewing.html#reminders",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Reminders",
    "text": "Reminders\n\nFirst MP due Thursday\n\nToday is the last day to request an extension\nVideo instructions in Perusall\nExemplary MPs in Slack\n\nReading for Thursday is optional (We won’t have time to discuss it in class)"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#when-do-ethnographers-interview",
    "href": "slides/Day13-Interviewing.html#when-do-ethnographers-interview",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "When do ethnographers interview…",
    "text": "When do ethnographers interview…\n\nTo gather historical narratives based on insider knowledge\nTo gather detail about how people narrate their activities/work\nTo ascertain individual assumptions and commitments\nTo deepen understanding of how people see themselves fitting into their social worlds and how they communicate that"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#things-to-keep-in-mind",
    "href": "slides/Day13-Interviewing.html#things-to-keep-in-mind",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Things to keep in mind…",
    "text": "Things to keep in mind…\n\nInterviews are co-constructed by the interviewer and the interviewee\n\n\nWhat does that mean? Why does it matter?\n\n\nInterviews are not aiming to get at the “truth” of events but to capture how people narrate them\n\n\nWhat does that mean? Why does it matter?"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#qualitative-interviews",
    "href": "slides/Day13-Interviewing.html#qualitative-interviews",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Qualitative Interviews",
    "text": "Qualitative Interviews\n\nInvolve open-ended questions seeking in-depth explanations and articulations\nAre often semi-structured\n\nEnables researchers to follow-up, asking the hows and the whys\nAllows the interviewee the flexibility to communicate from their perspective"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#preparing-for-an-interview",
    "href": "slides/Day13-Interviewing.html#preparing-for-an-interview",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Preparing for an interview",
    "text": "Preparing for an interview\n\nIdentify an individual that can provide unique perspective\nReach out to that individual requesting an interview (See recruitment email in GitHub as template)\nCoordinate a date, time, and location for the interview. If conducting through Zoom, create a shared meeting link. Note how location matters for the tone of the interview.\nAsk interviewee to sign informed consent form (see attachment in GitHub)\nConduct background research on the individual being interviewed and the institutions they are a part of.\nCreate an interview guide - with framing questions and transitions."
  },
  {
    "objectID": "slides/Day13-Interviewing.html#interview-guides",
    "href": "slides/Day13-Interviewing.html#interview-guides",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Interview Guides",
    "text": "Interview Guides\n\nGeneral flow:\n\nStart with more general question and move to more specific questions\nStart with more matter-of-fact questions and move to more intimate questions as you build trust\nClose with a few lighter questions that prepare for friendly conclusion\n\nPreparing the guide:\n\nWrite more interview questions than you will have time to get to.\nGroup questions according to similar topics and themes.\nPrepare transitions for moving between topics."
  },
  {
    "objectID": "slides/Day13-Interviewing.html#framing-questions",
    "href": "slides/Day13-Interviewing.html#framing-questions",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Framing Questions",
    "text": "Framing Questions\n\nAsk questions that encourage elaboration and description.\nConsider how to frame questions so that they make sense to the interviewee:\n\nMy research question: What values inform your data work?\nMy interview questions:\n\nWhat motivated you get involved in this work?\nWho were your primary inspirations in this area and why?\nWhat theorists/books were you reading as you got involved in this work? Do you find that relevant to your work today?"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#during-the-interview",
    "href": "slides/Day13-Interviewing.html#during-the-interview",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "During the Interview",
    "text": "During the Interview\n\nThank the individual for joining, introduce yourself, and remind them of the purpose of the interview\nStart the recording, and state your name, the date/time, the location, and the person being interviewed\nConfirm on the recording that the interviewee agrees to be interviewed\nDraw questions from the interview guide that maintain the overall flow of the interview. Regularly ask interviewees to elaborate by asking “how?” and “why?” questions.\nTakes notes on things the recording can’t pick up on (e.g. Body language, Tone, Things you are reminded of as they’re speaking)"
  },
  {
    "objectID": "slides/Day13-Interviewing.html#engaging-during-the-interview",
    "href": "slides/Day13-Interviewing.html#engaging-during-the-interview",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Engaging during the Interview",
    "text": "Engaging during the Interview\n\nEngage in active listening (direct eye contact, nodding)\nDon’t rush the interviewee to move onto a new question.\nIf the conversation veers allow it momentarily and then politely redirect it with a statement like, “I’d like to return to what you were saying about… Can you describe…?”\nPreface difficult conversations, and offer breaks if appropriate.\nDon’t try and finish an interviewee’s sentences.\nAvoid explicitly sharing personal opinions on what they’ve said.\nContemplate ways to reframe questions that an interviewee evades, exaggerates, or provides limited information on."
  },
  {
    "objectID": "slides/Day13-Interviewing.html#questions-to-consider",
    "href": "slides/Day13-Interviewing.html#questions-to-consider",
    "title": "Day Thirteen: Labor and Interviewing",
    "section": "Questions to consider:",
    "text": "Questions to consider:\n\nWhy does Biruk refer to the fieldworkers as “knowledge workers”? What kind of ethnographic move is this?\nBiruk continuously refers to “boundary work” in this chapter? Can you extrapolate what she means by this? What are the effects of enacting boundary work in fieldwork?\nWhat is “local knowledge”? How do credibility contests around “local knowledge” play out in this chapter?"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#reminders",
    "href": "slides/Day15-ParticipantObservation.html#reminders",
    "title": "Day Fifteen: Participant Observation",
    "section": "Reminders",
    "text": "Reminders\n\nFieldnote 3 due Thursday\nMP 2 due April 11\nNow is the time to start thinking about an interview"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#what-is-participant-observation",
    "href": "slides/Day15-ParticipantObservation.html#what-is-participant-observation",
    "title": "Day Fifteen: Participant Observation",
    "section": "What is participant observation?",
    "text": "What is participant observation?\n\nAn ethnographic method that involves embedding oneself in a community’s day-to-day activities\nEthnographer observes how people behave and interact through participation\nEthnographer takes written notes on what they observe which are later elaborated"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#when-do-ethnographers-do-participant-observation",
    "href": "slides/Day15-ParticipantObservation.html#when-do-ethnographers-do-participant-observation",
    "title": "Day Fifteen: Participant Observation",
    "section": "When do ethnographers do participant observation?",
    "text": "When do ethnographers do participant observation?\n\nTo figure out what kinds of interview questions to ask\nTo place checks on what people say during interviews\nTo gather details about the physical and social environments in which individuals engage\nTo deepen the ethnographer’s understanding of social contexts"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#what-gets-recorded-in-participant-observation",
    "href": "slides/Day15-ParticipantObservation.html#what-gets-recorded-in-participant-observation",
    "title": "Day Fifteen: Participant Observation",
    "section": "What gets recorded in participant observation?",
    "text": "What gets recorded in participant observation?\n\nDetails about:\n\nThe physical setting\nThe quantity and demographics of participants\nTheir physical appearance (such as attire)\nTheir traffic\nThe tools they use and/or exchange\nTheir physical movements\nThe way they communicate with one another\n…and more."
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#ethical-guidelines",
    "href": "slides/Day15-ParticipantObservation.html#ethical-guidelines",
    "title": "Day Fifteen: Participant Observation",
    "section": "Ethical Guidelines",
    "text": "Ethical Guidelines\n\nWhen should you announce yourself?\nDo you need informed consent?\nWhen is it advisable to identify participants?\nHow should I behave in the space?"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#tips-for-taking-field-notes",
    "href": "slides/Day15-ParticipantObservation.html#tips-for-taking-field-notes",
    "title": "Day Fifteen: Participant Observation",
    "section": "Tips for Taking Field Notes",
    "text": "Tips for Taking Field Notes\n\nRecord the date, time, and place of data collection\nRecord as much detail as you can about what you observe\nLeave space in notes to expand later\nUse abbreviations and shorthand when possible\nCreate maps and graphics to help you remember details\n\n–"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#expanding-field-notes",
    "href": "slides/Day15-ParticipantObservation.html#expanding-field-notes",
    "title": "Day Fifteen: Participant Observation",
    "section": "Expanding Field Notes",
    "text": "Expanding Field Notes\n\nSchedule a time to do it shortly after observation\nConvert your notes into a descriptive narrative\nLayer interpretations of your observations"
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#think-about-a-data-collection-practice-that-you-are-acquainted-with.-identify-one-specific-thing-that-people-try-to-always-do-when-collecting-that-data.",
    "href": "slides/Day15-ParticipantObservation.html#think-about-a-data-collection-practice-that-you-are-acquainted-with.-identify-one-specific-thing-that-people-try-to-always-do-when-collecting-that-data.",
    "title": "Day Fifteen: Participant Observation",
    "section": "Think about a data collection practice that you are acquainted with. Identify one specific thing that people try to always do when collecting that data.",
    "text": "Think about a data collection practice that you are acquainted with. Identify one specific thing that people try to always do when collecting that data."
  },
  {
    "objectID": "slides/Day15-ParticipantObservation.html#turn-to-your-neighbor-and-discuss",
    "href": "slides/Day15-ParticipantObservation.html#turn-to-your-neighbor-and-discuss",
    "title": "Day Fifteen: Participant Observation",
    "section": "Turn to your neighbor and discuss:",
    "text": "Turn to your neighbor and discuss:\n\nWhy do people try to do this?\nWhat meaning does it have for the data?\nHow does it shape the environments/social worlds for the people that engage in this “ritual”?"
  },
  {
    "objectID": "slides/Day16-Rituals.html#reminders",
    "href": "slides/Day16-Rituals.html#reminders",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Reminders",
    "text": "Reminders\n\nNow is the time to start thinking about MP 2!\nYou must submit your MP 1 on Moodle by 5 PM tomorrow if you wish to participate in peer review."
  },
  {
    "objectID": "slides/Day16-Rituals.html#discussion",
    "href": "slides/Day16-Rituals.html#discussion",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Discussion",
    "text": "Discussion\n\nWhat did our ethnographers notice about the data collection? What questions did our data collectors have about how to measure the height of a student?\nWhat were our shared goals and beliefs about what would make “good data”?\nHow did the rituals we designed shape the data? How did we organize ourselves to create pathways for the data to be comparable?"
  },
  {
    "objectID": "slides/Day16-Rituals.html#reading-review-what-are-rituals",
    "href": "slides/Day16-Rituals.html#reading-review-what-are-rituals",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Reading Review: What are rituals?",
    "text": "Reading Review: What are rituals?\n\nStylized repetitive activities engaged in different cultural contexts\nMay involve words, gestures, movements, exchanges\nCan sometimes be taken-for-granted and other times front and center\nMark the shared beliefs of a social group and membership in a community"
  },
  {
    "objectID": "slides/Day16-Rituals.html#turn-to-a-neighbor-and-discuss",
    "href": "slides/Day16-Rituals.html#turn-to-a-neighbor-and-discuss",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Turn to a neighbor and discuss:",
    "text": "Turn to a neighbor and discuss:\n\nHow might this ritual be taken for granted by different social groups?\nWhat are some of the shared beliefs that shape the rationale for engaging this ritual?"
  },
  {
    "objectID": "slides/Day16-Rituals.html#north-american-bird-breeding-survey",
    "href": "slides/Day16-Rituals.html#north-american-bird-breeding-survey",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "North American Bird Breeding Survey",
    "text": "North American Bird Breeding Survey\n\n\n\nIntroduced by Chan Robbins in 1966 as a result of rising concerns about the effects of DDT on bird populations\nAims to measure trends in bird populations over time\nNot a total population count\nResults in a longitudinal dataset of bird species counts at different stops along standardized routes\n\n\n\n\nDiego Delso"
  },
  {
    "objectID": "slides/Day16-Rituals.html#take-aways",
    "href": "slides/Day16-Rituals.html#take-aways",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Take-aways",
    "text": "Take-aways\n\nShared aims of making data comparable, clean, and well-cared for are held by data collectors\nEnvironmental forces constantly threaten these aims\nData collectors organize their social worlds towards these aims (e.g. establishing rituals)\nThis shapes the context of recorded data"
  },
  {
    "objectID": "slides/Day16-Rituals.html#jot-down-some-ideas-of-what-this-means-to-you",
    "href": "slides/Day16-Rituals.html#jot-down-some-ideas-of-what-this-means-to-you",
    "title": "Day Sixteen: Rituals of Data Collection",
    "section": "Jot down some ideas of what this means to you:",
    "text": "Jot down some ideas of what this means to you:\n\nThis chapter makes one basic point: the work of producing, preserving, and sharing data reshapes the organizational, technological, and cultural worlds around them. - Jackson and Ribes, 2013"
  },
  {
    "objectID": "slides/Day17-Incentives.html#reminders",
    "href": "slides/Day17-Incentives.html#reminders",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Reminders",
    "text": "Reminders\n\nIf you have not started on MP2 yet, you are late in doing so.\nThere is reading from Cooking Data due this Thursday."
  },
  {
    "objectID": "slides/Day17-Incentives.html#consider-a-time-that-you-would-be-rewarded-or-penalized-based-on-your-performance-towards-a-numeric-metric.",
    "href": "slides/Day17-Incentives.html#consider-a-time-that-you-would-be-rewarded-or-penalized-based-on-your-performance-towards-a-numeric-metric.",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Consider a time that you would be rewarded or penalized based on your performance towards a numeric metric.",
    "text": "Consider a time that you would be rewarded or penalized based on your performance towards a numeric metric."
  },
  {
    "objectID": "slides/Day17-Incentives.html#turn-to-a-neighbor-and-discuss",
    "href": "slides/Day17-Incentives.html#turn-to-a-neighbor-and-discuss",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Turn to a neighbor and discuss:",
    "text": "Turn to a neighbor and discuss:\n\nWhat kinds of decisions did you have to make about how to behave in relation to this metric?\nHow might people “game” this metric?"
  },
  {
    "objectID": "slides/Day17-Incentives.html#nyc-stop-question-and-frisk",
    "href": "slides/Day17-Incentives.html#nyc-stop-question-and-frisk",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "NYC Stop, Question, and Frisk",
    "text": "NYC Stop, Question, and Frisk\n\n\n\nPermits officers to stop individuals when “reasonable suspicion” of crime committed\n2011 District Court Floyd and Ourlicht vs. City of New York\n\nPresents data to show degree of racial profiling in practice\nAggregated from series of UF-250 forms officers fill out\n\n\n\n\nj-No, Flickr\n\n\n\nIn 2011, New York City’s controversial stop, question, and frisk policy – which permits officers to stop and question an individual when they have “reasonable suspicion” but not “probable cause” that the individual committed a crime – went before the US District Court. David Floyd and David Ourlicht argued that the NYPD had stopped them without reasonable suspicion, and the resulting high-profile case centered around issues of racial profiling in NYC policing. Much of the case against stop and frisk was built from data documenting racial breakdowns of the individuals stopped each year, along with the reason for the stop and the results of the stop. This data was aggregated from a series of forms (known as UF-250s) that officers are required to fill out and report following a stop. These forms collectively showed that 85% of those stopped were Black and Latino despite these sub-groups comprising just over half of the city’s population."
  },
  {
    "objectID": "slides/Day17-Incentives.html#hon.-scheindlins-ruling",
    "href": "slides/Day17-Incentives.html#hon.-scheindlins-ruling",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Hon. Scheindlin’s Ruling",
    "text": "Hon. Scheindlin’s Ruling\n\n\n\nJoel Spector ⓒ2013\n\n\nBecause it is impossible to individually analyze each of those stops, plaintiffs’ case was based on the imperfect information contained in the NYPD’s database of forms (‘UF-250s’) that officers are required to prepare after each stop.\n\n\n\n\nUltimately Judge Shira Schiedlen ruled that stop and frisk was being carried out in an unconstitutional way and ordered a scaling back of the practice. I want to start off the presentation by reciting an (admittedly) long quote from Sheindlen’s ruling that I think captures the key issues of this presentation:\nBecause it is impossible to individually analyze each of those stops, plaintiffs’ case was based on the imperfect information contained in the NYPD’s database of forms (‘UF-250s’) that officers are required to prepare after each stop. The central flaws in this database all skew toward underestimating the number of unconstitutional stops that occur: the database is incomplete, in that officers do not prepare a UF-250 for every stop they make; it is one-sided, in that the UF250 only records the officer’s version of the story; the UF-250 permits the officer to merely check a series of boxes, rather than requiring the officer to explain the basis for her suspicion; and many of the boxes on the form are inherently subjective and vague (such as ‘furtive movements’). Nonetheless, the analysis of the UF-250 database reveals that at least 200,000 stops were made without reasonable suspicion."
  },
  {
    "objectID": "slides/Day17-Incentives.html#juking-the-stats",
    "href": "slides/Day17-Incentives.html#juking-the-stats",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Juking the Stats",
    "text": "Juking the Stats\n\n\n\nCompStat: crime reduction strategy instituted in NYC in the 1990s\nUsed crime and deployment data as performance metrics\nInstitutionally incentivized data manipulation\n\n\n\npardonmeforasking, Flickr\n\n\n\nThe “imperfections” in this dataset have a history. This database came into existence alongside CompStat- a crime reduction strategy implemented in NYC in the 1990s. CompStat required precincts to produce weekly statistics regarding crime rates, officer deployments, stops, and arrests in their communities in order to generate evidence of policing effectiveness. The idea was to hold officers accountable through “timely and accurate intelligence” and “relentless follow-up and assessment.” However, with certain consequences tied to failures to demonstrate reductions in crime, the policies institutionally incentivized data manipulation - an issue colloquially referred to as “juking the stats.” Whistleblowing officers have presented audio recordings of their commanders demanding that they conduct more stops to meet quotas, and deceptively classifying crimes."
  },
  {
    "objectID": "slides/Day17-Incentives.html#disclosure-datasets",
    "href": "slides/Day17-Incentives.html#disclosure-datasets",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Disclosure Datasets",
    "text": "Disclosure Datasets\n\n\n\nTabular datasets that aggregate information produced and reported by the same institutions they are meant to hold accountable.\n\n\n\nSelf-disclosure concerns:\n\n“Juking the stats” (policing)\n“Cooking the books” (campaign finance)\n“Phantom reductions” (environmental monitoring)\n\n\n\n\n\nNotably, this idea of “juking the stats” has equivalent terms in other domains involving data produced by self-disclosure. For instance, we talk of political candidates “cooking the books” when it comes to disclosing data about campaign contributions and expenditures, and as I will turn to soon, environmental activists refer to industries reporting “phantom reductions” when it comes to disclosing information about their polluting activities. These are all examples of data quality issues regarding “disclosure datasets” - tabular datasets produced in accordance with laws requiring various kinds of disclosure. The most significant defining feature of disclosure datasets is that they aggregate information produced and reported by the same institutions they are meant to hold accountable. Further, the values reported in disclosure datasets can lead to adverse actions - either formal or informal – taken against the reporting institutions. Combined, these issues institutionally incentivize misreporting and deceptive accounting practices."
  },
  {
    "objectID": "slides/Day17-Incentives.html#classes-of-accountability-data",
    "href": "slides/Day17-Incentives.html#classes-of-accountability-data",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Classes of Accountability Data",
    "text": "Classes of Accountability Data\n\n\nDisclosure Data\n\nDan Nguyen\n\nEvaluative Data\n Digits.co.uk Images\n\nMonitoring Data\n\nIvan Radic, on Flickr\n\n\n\nDisclosure data is just one class of data used to hold people and institutions accountable. We might, for instance, contrast disclosure data with evaluative data – where people and institutions are not self-assessed, but instead assessed by an external evaluator. Examples include Yelp reviews of businesses and student evaluations of teaching effectiveness. We might also contrast disclosure data with surveillance data – where real-time technological systems track activities to hold folks accountable. Examples of such data include police body cameras and consumer credit tracking. Karen Levy’s work on electronic monitoring systems in the US trucking industry provides a compelling narrative on the social impact of surveillance data. In recognition that each of these datasets emerge from situated and delimited perspectives, we can point to concerns regarding data quality and bias in all of these classes of accountability data.\nIn what follows, I will focus on three kinds of data quality concerns that arise based on the institutional configurations that underpin the production of records for disclosure datasets:"
  },
  {
    "objectID": "slides/Day17-Incentives.html#false-reporting",
    "href": "slides/Day17-Incentives.html#false-reporting",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "False Reporting",
    "text": "False Reporting\n\n\n\nLying or misreporting data\nAuditing can be challenging\n\n\n Sample HMDA Data Collection Form\n\n\n\nFalse reporting involves deliberate efforts to falsify records; it’s flat out lying. While institutions that aggregate disclosure reports into a dataset often attempt to curb false reporting through auditing efforts, small scale instances of false reporting can be inordinately difficult to detect given that the data systems are designed to tell the story from the perspective of the reporters.\nFor example, in order to ensure that financial institutions are in compliance with fair lending laws in the U.S. (such as the Equal Credit Opportunity Act and the Fair Housing Act), lenders are required to collect and report data on an applicant’s ethnicity, race, gender, and income when they apply for a mortgage. When reporting data relating to race, ethnicity, and gender, lenders are legally required to submit the information that applicants self-report when filling out a loan application to the Consumer Financial Protection Bureau (CFPB). However, in cases where an applicant elects not to provide their demographic data, lenders are required to record race, ethnicity, and gender based on visual observation of the applicant or the applicant’s surname. In one of the most notable cases of intentional HMDA misreporting, a CFPB investigation found that, for over three years, loan officers at Freedom Mortgage (one of the top ten lending institutions in the U.S.) were instructed to list “non-Hispanic White” as the race and ethnicity for every applicant that elected not to provide demographic data.\nSimilarly one of the most novel disclosure datasets my lab has been looking at is called Open Payments. To monitor for potential medical conflicts of interest, medical drug and device companies are required to disclose payments and other transfers of value made to physicians and teaching hospitals. This is mandated by the passing of the Physician Payments Sunshine Act (2010). Until recently, there has been little enforcement of the Sunshine Act, so cases of misreporting or failures to report have gone largely unrecognized. …but in 2020, the first settlement for violations to the Sunshine Act was announced. In efforts to get a South Dakota neurosurgeon to adopt their infusion pumps, Medtronic agreed to sponsor more than 100 events at a restaurant the neurosurgeon owned. Medtronic agreed to pay $9.2 million to resolve allegations for failure to report.\nIn terms of data quality, false reporting calls into question the accuracy and validity of the data."
  },
  {
    "objectID": "slides/Day17-Incentives.html#deceptive-accounting",
    "href": "slides/Day17-Incentives.html#deceptive-accounting",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Deceptive Accounting",
    "text": "Deceptive Accounting\n\n\n\nNot technically false but deliberately misleading\nTakes advantage of ambiguities in standards or laws\nOften involves “creative” approaches to measurement or classification\n\n\n\n\n\n\nWe can trace other cases of reporting that result in information that is not technically false, but deliberately misleading. For instance, institutions might take advantage of loopholes in reporting standards or leverage vagueness in the reporting requirements to cast their activities in a more positive light.\nAn example of this comes from the environmental health domain. The EPA’s Emergency Planning and Community Right to Know Act (EPCRA) of 1986 established the Toxic Release Inventory as a mechanism to monitor and inform the public of toxic emissions released in their communities. Every year, certain U.S. industrial facilities are required to report to the EPA the amounts of certain chemical on-site and off-site releases.\nNotably, while this Act mandates reporting of emissions, it does not mandate monitoring of emissions. While other environmental regulations do set certain monitoring standards for specific TRI chemicals and pollution activities, for all other chemicals and activities, facilities are required to report based on a “reasonable estimate” of releases and other waste management quantities. Because the data is self-reported, this provides a lot of flexibility to facilities to determine how they go about measuring emissions. Studies have shown that year-to-year changes in emissions at large facilities often have more to do with changes in estimation methods and interpretations of the law, rather than actual reductions in emissions. These are often called “phantom reductions” - where emissions just disappear from the books without indication of how the facility actually cleaned up their act.\nIn our research into disclosure datasets, my lab has identified a number of other examples of deceptive accounting. For instance, when reporting campaign spending, candidates will sometimes hide large payments by submitting them to consulting firms that then disburse the payments to other organizations. Historically, candidates did not have to disclose the payments’ ultimate recipients. …and the concept of “juking the stats” in policing is a direct example of this deceptive accounting practice, with officers learning to play the CompStat numbers game.\nIn terms of data quality, deceptive accounting calls into question the representativeness of the data - or in other words, the degree to which it represents what we think it represents."
  },
  {
    "objectID": "slides/Day17-Incentives.html#discursive-risk-of-regulatory-burden",
    "href": "slides/Day17-Incentives.html#discursive-risk-of-regulatory-burden",
    "title": "Day Seventeen: Institutional Incentives",
    "section": "Discursive Risk of Regulatory Burden",
    "text": "Discursive Risk of Regulatory Burden\n\nScope of dataset determined by reporting thresholds\nStakeholders have advocated for strengthening or loosening thresholds in line with certain political commitments\n“Regulatory burden” discourse has been powerful tool for loosening reporting requirements\n\n\nFinally, the information that ultimately appears in a disclosure dataset is often shaped by a series of legal standards regarding who has to report and when they have to report. These standards are not neutral, and tend to evolve as stakeholders with certain political commitments towards transparency and institutional accountability call for amendments. Certain stakeholders advocate on behalf of stricter requirements and more data reporting in efforts to secure transparency and accountability, whereas other stakeholders advocate on behalf of loosening the requirements. Notably, one of the most powerful weapons against strengthening disclosure dataset programs has been discourse around “regulatory burden”. Businesses cite the cost and lack of feasibility of filling out paperwork when advocating against data collection. For instance, under the George W. Bush Administration, the TRI “Burden Reduction Rule” significantly raised the threshold regarding how much pollution a facility needed to emit before reporting requirements kicked in. Just recently, amendments to HMDA raised the threshold regarding the volume of loans a bank needs a originate for reporting requirements to kick in. The pressures Covid-19 had placed on banks was cited as a reason for this change. … and regulatory burden discourse has been effectively leveraged to keep the US’s National Use of Force database – where police officers disclose when they use force against citizens – a voluntary data program.\nWhen regulatory burden discourse is successful, fewer institutions are required to report on fewer activities, diminishing what is tracked in the data. Thresholds tend to fluctuate in line with political changeover. For instance, the stringency of TRI reporting often correlates with the political leanings of presidential administrations. This has meant that the definitions underpinning disclosure datasets are quite malleable - subject to change in conjunction with different modes of social advocacy. This malleability is a double-edged sword for many community groups calling for increased accountability. In one sense, it ensures that disclosure programs can continuously be strengthened. However, changing reporting standards makes it difficult to perform year-to-year comparisons of the data. …which is often needed to measure whether institutions are “cleaning up” their acts.\nIn terms of data quality, this discursive risk calls into question the scope and comprehensiveness of the data."
  },
  {
    "objectID": "slides/Day19-Mobilization.html#what-does-the-following-statement-mean-to-you",
    "href": "slides/Day19-Mobilization.html#what-does-the-following-statement-mean-to-you",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "What does the following statement mean to you?",
    "text": "What does the following statement mean to you?\n\nOn April 10, 2023 at 9AM Northampton’s reported AQI was 54."
  },
  {
    "objectID": "slides/Day19-Mobilization.html#turn-to-a-neighbor-and-discuss",
    "href": "slides/Day19-Mobilization.html#turn-to-a-neighbor-and-discuss",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Turn to a neighbor and discuss:",
    "text": "Turn to a neighbor and discuss:\n\nWhat information do we need to be able to interpret the meaning of the number 54 in the following slide?"
  },
  {
    "objectID": "slides/Day19-Mobilization.html#what-is-evidence",
    "href": "slides/Day19-Mobilization.html#what-is-evidence",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "What is ‘evidence’?",
    "text": "What is ‘evidence’?\n\nEtymologically dual meaning:\n\nTransparent, obvious, clear, speaking for itself\nAppearance or indication, requiring interpretation\n\n\n\nBiruk, Cal. 2018. Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books."
  },
  {
    "objectID": "slides/Day19-Mobilization.html#turn-to-a-neighbor-and-discuss-1",
    "href": "slides/Day19-Mobilization.html#turn-to-a-neighbor-and-discuss-1",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Turn to a neighbor and discuss:",
    "text": "Turn to a neighbor and discuss:\n\nHow do you know if this is a big or small quantity?\nDo you have a yardstick to help you determine this?\nHow might this number mean different things to different social groups?"
  },
  {
    "objectID": "slides/Day19-Mobilization.html#interpretive-flexibility",
    "href": "slides/Day19-Mobilization.html#interpretive-flexibility",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Interpretive Flexibility",
    "text": "Interpretive Flexibility\n\nAnti-determinist frameworks\nRefers to the differing meanings that social groups assign to technologies\nExplain how technologies are “socially constructed”"
  },
  {
    "objectID": "slides/Day19-Mobilization.html#mobilizing-data-narratives",
    "href": "slides/Day19-Mobilization.html#mobilizing-data-narratives",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Mobilizing Data Narratives",
    "text": "Mobilizing Data Narratives\n\nMobilization refers to the processes by which people prepare something to be put to use or into action\nStakeholders strategically engage in meaning-making activities around data\nShapes societal interpretations of data"
  },
  {
    "objectID": "slides/Day19-Mobilization.html#framing-statistics",
    "href": "slides/Day19-Mobilization.html#framing-statistics",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Framing Statistics",
    "text": "Framing Statistics\n\nComparison/Ranking\n\nIs x more/less than y?\n\nStandards-Setting/Benchmarking\n\nDoes x meet z standard/benchmark?\n\nAppealing to Emotion/Lived Experience\n\nHow does x make me feel/relate to my life?"
  },
  {
    "objectID": "slides/Day19-Mobilization.html#take-aways",
    "href": "slides/Day19-Mobilization.html#take-aways",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Take-aways",
    "text": "Take-aways\n\nThe meaning/significance of numbers is not self-evident.\nData becomes meaningful as stakeholders develop tools for narrating the significance of a number.\nEthnographers can study these meaning-making practices."
  },
  {
    "objectID": "slides/Day19-Mobilization.html#announcements",
    "href": "slides/Day19-Mobilization.html#announcements",
    "title": "Day Nineteen: Mobilizating Meaning",
    "section": "Announcements",
    "text": "Announcements\n\n\n\nOptional group work time with Rose on Thursday.\nDon’t forget to fill out the group evaluations.\nAdditional enrichment option\n\nAttend this event and write 400-word memo analyzing the topic using one of the key concepts from data activism readings (Concept must be approved by me.)"
  },
  {
    "objectID": "grading_contract.html#final-project-resources",
    "href": "grading_contract.html#final-project-resources",
    "title": "Grading Contract",
    "section": "Final Project Resources",
    "text": "Final Project Resources\nThis semester your project group will develop a user guide for a federal dataset. You will complete a series of exercises in class to support you in writing the guide. These exercises are not graded; they are meant to frame your research and help you generate material for the project. You should work on relevant aspects of them weekly with your group in order to make progress towards the final product. While these exercises will include both qualitative and computational exercises, the point of this project is not to perform a statistical analysis on this dataset. Instead, you will study the dataset ethnographically and strive to effectively communicate how the dataset came to be, how it has disseminated, how it can be used, and what some of its limitations are.\n\nProject Description\nRose’s Project Guide Sheet\nDataset Loading Instructions\nExample User Guide\n\nBelow I’ve outlined completion criteria for the two non-written assignments for this course.\n\nReading Annotations\nEach week a selection of course readings will be posted as a single assignment on Perusall - a system for students to collaboratively annotate course readings. To earn this credit, you will be expected to post 3 quality annotations per assignment to Perusall. (Note that a single assignment can have multiple readings, but you need only submit 3 annotations total. You do not need to annotate every reading in the assignment.) A quality annotation is one in which you synthesize concepts, ask thought-provoking questions, or connect ideas to external issues. I have found that students get the most out of Perusall when they respond to each other’s annotations. Annotations must be completed before class to receive credit.\n\n\nCommunity Labor\nEthnography is at its best when it involves collaborative inquiry and interpretation. Because of this, I want to encourage us to foster a cooperative community in our classroom. Ethnographers know that building and sustaining strong communities are important and often invisible forms of labor. In an effort to foreground and reward that labor, I’ve built opportunities to contribute to the course community into our grading contract. There are four opportunities for earning community labor points in this course. It will be your responsibility to keep track of your community labor via our course labor log (see FAQ).\n\nContributing on Slack\nThe first opportunity for earning community labor points is through posting in the #sds-237-discussions Slack channel. For every conversation that you initiate in this channel, you will earn 1 community labor point. For every conversation that you respond to in this channel with substantive summary, critique, or reflection, you will earn 1 community labor point. Finally, for every question that you answer in the #sds-237-questions channel, you will earn 1 community labor point.\n\n\nCompleting Group Evaluations\nMid-way through the semester you will have an opportunity to evaluate your own contributions to your group work, along with that of your peers. Your feedback will be shared with members of your group. Completing group evaluations will count for 1 community labor point.\n\n\nParticipating in Peer Review Workshops\nThroughout the semester, I will set up workshops where students may submit their written work for peer review in preparation for assignment submissions. Each peer review workshop that you participate in will count for 2 community labor points.\n\n\nContributing Class Notes\nFollowing a class period, up to two students may type up a 1-page outline of what was covered in that class period and post a link to that outline in #sds-237-class-notes. You can sign-up to serve as the notetaker for a certain class here. These notes should be a full, single-space page, and should make sense to someone that was not present in class. Each class note outline that you contribute will count for 2 community labor points.\nNote that throughout the semester, I may offer additional opportunities to earn community labor points as unexpected forms of course labor arise.\n\nThe final project will be completed in groups, and considerable chunks of the group project will be completed in class on Thursdays. While I will not formally be taking attendance for this course, I reserve the right to adjust your final grade by a letter grade if you’ve missed more than three classes involving final project group work. Be sure to reach out to me early on if there are extenuating circumstances that will consistently impact your attendance."
  },
  {
    "objectID": "slides/Day22-Credibility.html#take-out-a-sheet-of-paper-and-draw-your-map-of-science.",
    "href": "slides/Day22-Credibility.html#take-out-a-sheet-of-paper-and-draw-your-map-of-science.",
    "title": "Day Twenty-Two: Credibility",
    "section": "Take out a sheet of paper and draw your “map of science”.",
    "text": "Take out a sheet of paper and draw your “map of science”.\n\nWhat are the other features on the map?\nWhat is central and what is in the periphery?\nIs there a place for art/religion?"
  },
  {
    "objectID": "slides/Day22-Credibility.html#turn-to-a-neighbor-and-discuss",
    "href": "slides/Day22-Credibility.html#turn-to-a-neighbor-and-discuss",
    "title": "Day Twenty-Two: Credibility",
    "section": "Turn to a neighbor and discuss:",
    "text": "Turn to a neighbor and discuss:\n\nWhy did you draw the map the way that you did?\nCan you think of stakeholders who might disagree with your map of science? Why?"
  },
  {
    "objectID": "slides/Day22-Credibility.html#boundary-work",
    "href": "slides/Day22-Credibility.html#boundary-work",
    "title": "Day Twenty-Two: Credibility",
    "section": "Boundary Work",
    "text": "Boundary Work\n\nThomas Gieryn, Cultural Cartographies of Science\nAcknowledges the lack of stable criteria for demarcating science from non-science.\nDifferent people justify what makes something scientific vs unscientific differently.\nAs credibility contests emerge, people make claims based on their own maps of science.\nCulturally chart the boundaries around what we consider scientific."
  },
  {
    "objectID": "slides/Day22-Credibility.html#how-do-we-draw-the-boundaries-of-credibility-in-data-work",
    "href": "slides/Day22-Credibility.html#how-do-we-draw-the-boundaries-of-credibility-in-data-work",
    "title": "Day Twenty-Two: Credibility",
    "section": "How do we draw the boundaries of credibility in data work?",
    "text": "How do we draw the boundaries of credibility in data work?\n\nWho gets seen as a legitimate claims-maker in data science work, and whose voices are often denied a seat at the table?"
  },
  {
    "objectID": "slides/Day22-Credibility.html#example-lois-gibbs-and-love-canal",
    "href": "slides/Day22-Credibility.html#example-lois-gibbs-and-love-canal",
    "title": "Day Twenty-Two: Credibility",
    "section": "Example: Lois Gibbs and Love Canal",
    "text": "Example: Lois Gibbs and Love Canal"
  },
  {
    "objectID": "slides/Day22-Credibility.html#deficit-model",
    "href": "slides/Day22-Credibility.html#deficit-model",
    "title": "Day Twenty-Two: Credibility",
    "section": "Deficit Model",
    "text": "Deficit Model\n\nBelief that the reason people distrust science is because they lack knowledge\nOften casts scientific illiteracy as both a technical problem and a moral problem\nPresumed solution to increasing public trust in science is to teach more science\n\n\nSTS rejects the deficit model…\n\n\nIgnores public’s situated knowledge\nSuggests knowledge is context-free\nDoesn’t get at the root of distrust"
  },
  {
    "objectID": "slides/Day22-Credibility.html#enactments-of-expertise",
    "href": "slides/Day22-Credibility.html#enactments-of-expertise",
    "title": "Day Twenty-Two: Credibility",
    "section": "Enactments of Expertise",
    "text": "Enactments of Expertise\n\n\n\nExpertise as a signal of authority\nEnacted through credentialing, use of certain vocabularies, creation of exclusive social circles, clothing, norms of behavior\nEnactments also serve a gate-keeping role in determining who gets to contribute to science/data science\n\n\nIn her history of the medical activism by the Black Panthers, Alondra Nelson discusses how one way the Black Panthers enacted their expertise was in their choice to wear white lab coats.\n > Sickle cell anemia testing. Oakland, Calif. 1972. credit NY Times"
  },
  {
    "objectID": "slides/Day22-Credibility.html#citizen-science",
    "href": "slides/Day22-Credibility.html#citizen-science",
    "title": "Day Twenty-Two: Credibility",
    "section": "Citizen Science",
    "text": "Citizen Science\n\nExclusionary science as a democratic problem\nExamples of citizen engagement:\n\nCounting declining bird populations\nAir and water quality monitoring\nWriting health books for underrepresented populations\n\nMust learn how to enact expertise to earn a seat at the table"
  },
  {
    "objectID": "slides/Day22-Credibility.html#social-movement-theory",
    "href": "slides/Day22-Credibility.html#social-movement-theory",
    "title": "Day Twenty-Two: Credibility",
    "section": "Social Movement Theory",
    "text": "Social Movement Theory\n\nSociological research that studies how social movements form, operate, sustain, and fizzle out\nPolitical Process Theory: suggests that certain political formations enable social movements to form and operate\nResource Mobilization Theory: suggests that access to certain resources enable social movements to mobilize\nFraming: Suggests that collective ideologies and values bring social movements into fruition"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#feminist-arguments-on-the-study-of-ignorance",
    "href": "slides/Day23-Ignorance.html#feminist-arguments-on-the-study-of-ignorance",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Feminist arguments on the study of ignorance",
    "text": "Feminist arguments on the study of ignorance\n\nIgnorance is more than a gap in knowledge.\n“Ignorance, like knowledge, is situated.”\n\n\nTuana, Nancy. 2006. “The Speculum of Ignorance: The Women’s Health Movement and Epistemologies of Ignorance.” Hypatia 21 (3): 1–19. https://doi.org/10.1111/j.1527-2001.2006.tb01110.x."
  },
  {
    "objectID": "slides/Day23-Ignorance.html#taxonomy-of-ignorance",
    "href": "slides/Day23-Ignorance.html#taxonomy-of-ignorance",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Taxonomy of Ignorance",
    "text": "Taxonomy of Ignorance\n\nEngineered Ignorance\nUndone Science\nOrganized Ignorance\nLoving Ignorance"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#big-tobacco-hides-cancer-risks",
    "href": "slides/Day23-Ignorance.html#big-tobacco-hides-cancer-risks",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Big Tobacco Hides Cancer Risks",
    "text": "Big Tobacco Hides Cancer Risks\n\nEarly 1950s, considerable expansion of research on tobacco health risks (e.g. lung cancer)\nTobacco industry seeks to produce knowledge that will undo effects of emerging research:\n\nEnlisted public relations firm Hill & Knowlton\nDetermined that advertising won’t work because self-interested by definition\nSought out credentialed medical skeptics to engineer controversy\nCreated Tobacco Industry Research Committee and funded research to sew doubt/uncertainty"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#merchants-of-doubt",
    "href": "slides/Day23-Ignorance.html#merchants-of-doubt",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Merchants of Doubt",
    "text": "Merchants of Doubt"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#undone-science-areas-of-research-that-go-unfunded-left-incomplete-or-get-ignored",
    "href": "slides/Day23-Ignorance.html#undone-science-areas-of-research-that-go-unfunded-left-incomplete-or-get-ignored",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Undone science: Areas of research that go unfunded, left incomplete, or get ignored",
    "text": "Undone science: Areas of research that go unfunded, left incomplete, or get ignored\n\nFrickel, Scott, Sahra Gibbon, Jeff Howard, Joanna Kempner, Gwen Ottinger, and David J. Hess. 2010. “Undone Science: Charting Social Movement and Civil Society Challenges to Research Agenda Setting.” Science, Technology & Human Values 35 (4): 444–73. https://doi.org/10.1177/0162243909345836."
  },
  {
    "objectID": "slides/Day23-Ignorance.html#medical-funding",
    "href": "slides/Day23-Ignorance.html#medical-funding",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Medical Funding",
    "text": "Medical Funding\n\nNature reports that much medical funding goes to the “big three” - HIV/AIDS, malaria and tuberculosis\nFunding diverted away from “neglected tropical diseases”\n\nImpact billions of people and disproportionately impact most vulnerable populations\nExamples: dengue, leprosy, trachoma\n\nCovid-19 further diverted funding from these programs"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#our-bodies-ourselves",
    "href": "slides/Day23-Ignorance.html#our-bodies-ourselves",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Our Bodies Ourselves",
    "text": "Our Bodies Ourselves\n\n\n\nTuana, Nancy. 2006. “The Speculum of Ignorance: The Women’s Health Movement and Epistemologies of Ignorance.” Hypatia 21 (3): 1–19. https://doi.org/10.1111/j.1527-2001.2006.tb01110.x."
  },
  {
    "objectID": "slides/Day23-Ignorance.html#environmental-testing-following-hurricane-katrina",
    "href": "slides/Day23-Ignorance.html#environmental-testing-following-hurricane-katrina",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Environmental Testing following Hurricane Katrina",
    "text": "Environmental Testing following Hurricane Katrina\n\nOnly test contaminants designated by law (<200 of 8200 in TSCA) on public properties\nTend to test where there was flooding, not where there may be the most contaminants\n\nMost serious flooding escaped “sliver along the river” - location of the city’s industrial corridor\nUntested areas include several brownfields and areas with history of manufacturing expansion"
  },
  {
    "objectID": "slides/Day23-Ignorance.html#colony-collapse-disease",
    "href": "slides/Day23-Ignorance.html#colony-collapse-disease",
    "title": "Day Twenty-Three: Ignorance",
    "section": "Colony Collapse Disease",
    "text": "Colony Collapse Disease\n\nUS beekeepers have lost almost 1/3 of bees every year since 2006\nScientific studies of insecticides on bees were designed to test the individual lethal effects of a chemical on a bee population\n\nPart of a “control-oriented” scientific culture\n\nFailed to account for slow, cumulative effects over time and the interactions of chemicals and pathogens\n\n\nKleinman, Daniel Lee, and Sainath Suryanarayanan. 2013. “Dying Bees and the Social Production of Ignorance.” Science, Technology & Human Values 38 (4): 492–517. https://doi.org/10.1177/0162243912442575."
  },
  {
    "objectID": "assignments.html#fieldnotes",
    "href": "assignments.html#fieldnotes",
    "title": "Assignments",
    "section": "Fieldnotes",
    "text": "Fieldnotes\nInstructions for the fieldnote assignment can be found here."
  },
  {
    "objectID": "assignments.html#mini-projects-substantive-revision",
    "href": "assignments.html#mini-projects-substantive-revision",
    "title": "Assignments",
    "section": "Mini-Projects + Substantive Revision",
    "text": "Mini-Projects + Substantive Revision\nInstructions for the mini-projects can be found here."
  },
  {
    "objectID": "assignments.html#final-project",
    "href": "assignments.html#final-project",
    "title": "Assignments",
    "section": "Final Project",
    "text": "Final Project\nThis semester your project group will develop a user guide for a federal dataset. You will complete a series of exercises to support you in writing the guide.\n\nThese exercises are not graded; they are meant to frame your research and help you generate material for the project.\nBecause each group is working on a different dataset, there will likely be components of each exercise that are not relevant to your group; I only expect you to complete about 70% of each exercise. Skip the parts that aren’t relevant to you.\nYou should be meeting with your groups at least one hour each week outside of class to coordinate your work and plan to work an additional hour independently to make progress towards your research.\nWhile these exercises will include both qualitative and computational exercises, the point of this project is not to perform a statistical analysis on this dataset. Instead, you will study the dataset ethnographically and strive to effectively communicate how the dataset came to be, how it has disseminated, how it can be used, and what some of its limitations are.\nProject Description\nRose Evard’s Project Guide Sheet\nDataset Loading Instructions\nExample User Guide"
  },
  {
    "objectID": "assignments.html#reading-annotations",
    "href": "assignments.html#reading-annotations",
    "title": "Assignments",
    "section": "Reading Annotations",
    "text": "Reading Annotations\nEach week a selection of course readings will be posted as a single assignment on Perusall - a system for students to collaboratively annotate course readings. To earn this credit, you will be expected to post 3 quality annotations per assignment to Perusall. (Note that a single assignment can have multiple readings, but you need only submit 3 annotations total. You do not need to annotate every reading in the assignment.) A quality annotation is one in which you synthesize concepts, ask thought-provoking questions, or connect ideas to external issues. I have found that students get the most out of Perusall when they respond to each other’s annotations. Annotations must be completed before class to receive credit."
  },
  {
    "objectID": "assignments.html#community-labor",
    "href": "assignments.html#community-labor",
    "title": "Assignments",
    "section": "Community Labor",
    "text": "Community Labor\nEthnography is at its best when it involves collaborative inquiry and interpretation. Because of this, I want to encourage us to foster a cooperative community in our classroom. Ethnographers know that building and sustaining strong communities are important and often invisible forms of labor. In an effort to foreground and reward that labor, I’ve built opportunities to contribute to the course community into our grading contract. There are four opportunities for earning community labor points in this course. It will be your responsibility to keep track of your community labor via our course labor log.\n\nContributing on Slack\nThe first opportunity for earning community labor points is through posting in the #sds-237-discussions Slack channel. For every conversation that you initiate in this channel, you will earn 1 community labor point. For every conversation that you respond to in this channel with substantive summary, critique, or reflection, you will earn 1 community labor point. Finally, for every question that you answer in the #sds-237-questions channel, you will earn 1 community labor point.\n\n\nCompleting Group Evaluations\nMid-way through the semester you will have an opportunity to evaluate your own contributions to your group work, along with that of your peers. Your feedback will be shared with members of your group. Completing group evaluations will count for 1 community labor point.\n\n\nParticipating in Peer Review Workshops\nThroughout the semester, I will set up workshops where students may submit their written work for peer review in preparation for assignment submissions. Each peer review workshop that you participate in will count for 2 community labor points.\n\n\nContributing Class Notes\nFollowing a class period, up to two students may type up a 1-page outline of what was covered in that class period and post a link to that outline in #sds-237-class-notes. You can sign-up to serve as the notetaker for a certain class here. These notes should be a full, single-space page, and should make sense to someone that was not present in class. Each class note outline that you contribute will count for 2 community labor points.\nNote that throughout the semester, I may offer additional opportunities to earn community labor points as unexpected forms of course labor arise."
  },
  {
    "objectID": "assignments.html#enrichment",
    "href": "assignments.html#enrichment",
    "title": "Assignments",
    "section": "Enrichment",
    "text": "Enrichment\nInstructions for enrichment assignments can be found here."
  },
  {
    "objectID": "schedule.html#september-05-2023",
    "href": "schedule.html#september-05-2023",
    "title": "Schedule",
    "section": "September 05, 2023",
    "text": "September 05, 2023\n\nIntroductions\n\nDue TodayFurther Resources\n\n\n Fill out the First Day of Class Questionnaire"
  },
  {
    "objectID": "schedule.html#september-07-2023",
    "href": "schedule.html#september-07-2023",
    "title": "Schedule",
    "section": "September 07, 2023",
    "text": "September 07, 2023\n\nIntroductions\n\nDue TodayFurther Resources\n\n\n Fill out the First Day of Class Questionnaire\n\n\n Course slides here"
  },
  {
    "objectID": "schedule.html#september-12-2023",
    "href": "schedule.html#september-12-2023",
    "title": "Schedule",
    "section": "September 12, 2023",
    "text": "September 12, 2023\n\nSituating Data\n\nDue TodayFurther Resources\n\n\n D’Ignazio, Catherine and Lauren Klein (2020). “3. On Rational, Scientific, Objective Viewpoints from Mythical, Imaginary, Impossible Standpoints”. In: Data Feminism. MIT Press. (Visited on Aug. 24, 2021). Read in Perusall\n TechCrunch (2021). Tackling Deep-Seated Bias in Tech with Haben Girma, Mutale Nkonde and Safiya Noble. (Visited on Sep. 01, 2021). Read in Perusall\n Fill out the Trigger Warnings Questionnaire in Moodle.\n Install Desktop version of Slack and configure notifications for our course.\n Create and Share Labor Log\n Sign up for notetaking or leading a class opening check-in"
  },
  {
    "objectID": "schedule.html#september-14-2023",
    "href": "schedule.html#september-14-2023",
    "title": "Schedule",
    "section": "September 14, 2023",
    "text": "September 14, 2023\n\nLab: Fundamentals of Data\n\nDue TodayFurther Resources\n\n\n Acknowledge that you’ve read and understand the grading contract by completing the Grading Contract Acknowledgement in Moodle\n Start working on Checkpoint 1\n\n\n Lab: Data Fundamentals"
  },
  {
    "objectID": "schedule.html#september-19-2023",
    "href": "schedule.html#september-19-2023",
    "title": "Schedule",
    "section": "September 19, 2023",
    "text": "September 19, 2023\n\nData Definitions and Counting\n\nDue TodayFurther Resources\n\n\n Martin, Aryn and Michael Lynch (2009). “Counting Things and People: The Practices and Politics of Counting”. In: Social Problems 56.2, pp. 243-266. (Visited on Aug. 26, 2019). Read in Perusall\n Ducharme, Jamie and Arpita Aneja (2020). Why It’s So Hard to Calculate Death Tolls From Hurricanes. (Visited on Sep. 03, 2020). Read in Perusall\n Rangarajan, Sinduja (2021). We Still Don’t Know How Many Americans Are Killed or Injured by Police Every Year. (Visited on Sep. 01, 2021). Read in Perusall\n NASA (2015). When a Definition Makes a Forest Disappear. Text.Article (Visited on Jan. 07, 2019). Read in Perusall\n Checkpoint 1 Due"
  },
  {
    "objectID": "schedule.html#september-21-2023",
    "href": "schedule.html#september-21-2023",
    "title": "Schedule",
    "section": "September 21, 2023",
    "text": "September 21, 2023\n\nLab: Intersections of Poverty\n\nDue TodayFurther Resources\n\n\n Redden, Joanna, Jessica Brand, and Vanesa Terzieva (2017). Data Harm Record. (Visited on Aug. 25, 2023). Read in Perusall\n\n\n Lab: Intersections of Poverty"
  },
  {
    "objectID": "schedule.html#september-26-2023",
    "href": "schedule.html#september-26-2023",
    "title": "Schedule",
    "section": "September 26, 2023",
    "text": "September 26, 2023\n\nCategorical Silencing\n\nDue TodayFurther Resources\n\n\n Star, Susan Leigh and Geoffrey C. Bowker (2007). “Enacting Silence: Residual Categories as a Challenge for Ethics, Information Systems, and Communication”. In: Ethics and Information Technology 9.4, pp. 273-280. (Visited on Jan. 05, 2019). Read in Perusall\n Nagle, Rebecca (2020). Native Americans Being Left out of US Coronavirus Data and Labelled as ‘Other’. (Visited on Feb. 17, 2021). Read in Perusall\n Broussard, Meredith (2019). The Next Frontier in Gender Rights Is Inside Databases. (Visited on Sep. 01, 2021). Read in Perusall\n Part 1 of Intersections of Poverty Lab"
  },
  {
    "objectID": "schedule.html#september-28-2023",
    "href": "schedule.html#september-28-2023",
    "title": "Schedule",
    "section": "September 28, 2023",
    "text": "September 28, 2023\n\nLab: Analyzing Data Semiotics\n\nDue TodayFurther Resources\n\n\n Start working on Checkpoint 2\n\n\n Lab: Data Semiotics"
  },
  {
    "objectID": "schedule.html#october-03-2023",
    "href": "schedule.html#october-03-2023",
    "title": "Schedule",
    "section": "October 03, 2023",
    "text": "October 03, 2023\n\nHealth Equity\n\nDue TodayFurther Resources\n\n\n Krieger, Nancy (1992). “The Making of Public Health Data: Paradigms, Politics, and Policy”. In: Journal of Public Health Policy 13.4, pp. 412-427. (Visited on Dec. 17, 2020). Read in Perusall\n Sexton Joe, Robin Fields (2021). How Many American Women Die From Causes Related to Pregnancy or Childbirth? No One Knows. (Visited on Feb. 17, 2021). Read in Perusall\n Health, United States Department of, uman Services (US DHHS),, Centers for Disease Control, et al. (2020). Underlying Cause of Death 1999-2019 on CDC WONDER Online Database. (Visited on Apr. 05, 2021). Read in Perusall\n Continue working on Checkpoint 2"
  },
  {
    "objectID": "schedule.html#october-05-2023",
    "href": "schedule.html#october-05-2023",
    "title": "Schedule",
    "section": "October 05, 2023",
    "text": "October 05, 2023\n\nLab: Visualizing Health Equity\n\nDue TodayFurther Resources\n\n\n Checkpoint 2 Due\n\n\n Lab: Health Equity"
  },
  {
    "objectID": "schedule.html#october-10-2023",
    "href": "schedule.html#october-10-2023",
    "title": "Schedule",
    "section": "October 10, 2023",
    "text": "October 10, 2023\n\nData Rhetoric and Persuasion\n\nDue TodayFurther Resources\n\n\n Start working on Blog Post 1"
  },
  {
    "objectID": "schedule.html#october-12-2023",
    "href": "schedule.html#october-12-2023",
    "title": "Schedule",
    "section": "October 12, 2023",
    "text": "October 12, 2023\n\nFall Break\n\nDue TodayFurther Resources\n\n\n Continue working on Blog Post 1"
  },
  {
    "objectID": "schedule.html#october-17-2023",
    "href": "schedule.html#october-17-2023",
    "title": "Schedule",
    "section": "October 17, 2023",
    "text": "October 17, 2023\n\nMaking Claims with Data\n\nDue TodayFurther Resources\n\n\n Continue working on Blog Post 1"
  },
  {
    "objectID": "schedule.html#october-19-2023",
    "href": "schedule.html#october-19-2023",
    "title": "Schedule",
    "section": "October 19, 2023",
    "text": "October 19, 2023\n\nData Distortion\n\nDue TodayFurther Resources\n\n\n Chalabi, Mona (2017). 3 Ways to Spot a Bad Statistic. (Visited on Sep. 01, 2021). Read in Perusall\n list() Read in Perusall\n Start working on Checkpoint 3\n Continue working on Blog Post 1"
  },
  {
    "objectID": "schedule.html#october-24-2023",
    "href": "schedule.html#october-24-2023",
    "title": "Schedule",
    "section": "October 24, 2023",
    "text": "October 24, 2023\n\nPolicing Injustice and NYPD’s Stop, Question, and Frisk Database\n\nDue TodayFurther Resources\n\n\n Smith, Chris (2018). The Crime-Fighting Program That Changed New York Forever. (Visited on Jul. 16, 2019). Read in Perusall\n Richardson, R., Jason Schultz, and K. Crawford (2019). “Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice”. In: NYU Law Review 94.192, pp. 192-233. (Visited on Sep. 01, 2021). Read in Perusall\n list() Read in Perusall\n Continue working on Checkpoint 3\n Blog Post 1 Due"
  },
  {
    "objectID": "schedule.html#october-26-2023",
    "href": "schedule.html#october-26-2023",
    "title": "Schedule",
    "section": "October 26, 2023",
    "text": "October 26, 2023\n\nLab: Policing Injustice and NYPD’s Stop, Question, and Frisk Database\n\nDue TodayFurther Resources\n\n\n Checkpoint 3 Due\n Start Blost Post Peer Review\n\n\n Lab: Policing Justice"
  },
  {
    "objectID": "schedule.html#october-31-2023",
    "href": "schedule.html#october-31-2023",
    "title": "Schedule",
    "section": "October 31, 2023",
    "text": "October 31, 2023\n\nLab: Detecting Data Fallacies\n\nDue TodayFurther Resources\n\n\n Continue working on Blog Post Peer Review\n\n\n Lab: Detecting Data Fallacies"
  },
  {
    "objectID": "schedule.html#november-02-2023",
    "href": "schedule.html#november-02-2023",
    "title": "Schedule",
    "section": "November 02, 2023",
    "text": "November 02, 2023\n\nCromwell Day\n\nDue TodayFurther Resources\n\n\n Peer Review Due"
  },
  {
    "objectID": "schedule.html#november-07-2023",
    "href": "schedule.html#november-07-2023",
    "title": "Schedule",
    "section": "November 07, 2023",
    "text": "November 07, 2023\n\nHoning Claims and Evidence Workshop\n\nDue TodayFurther Resources\n\n\n Start Blog Post 1 Revision"
  },
  {
    "objectID": "schedule.html#november-09-2023",
    "href": "schedule.html#november-09-2023",
    "title": "Schedule",
    "section": "November 09, 2023",
    "text": "November 09, 2023\n\nErasures in Data Collection and Cleaning\n\nDue TodayFurther Resources\n\n\n Joy Buolamwini (2021). Voicing Erasure - A Spoken Word Piece Exploring Bias in Voice Recognition Technology. (Visited on Sep. 01, 2021). Read in Perusall\n Organizational Transformation (2018). AI, Ain’t I A Woman? Presented by Organizational Transformation. (Visited on Sep. 01, 2021). Read in Perusall\n Start working on Checkpoint 4\n Continue working on Blog Post 1 Revision"
  },
  {
    "objectID": "schedule.html#november-14-2023",
    "href": "schedule.html#november-14-2023",
    "title": "Schedule",
    "section": "November 14, 2023",
    "text": "November 14, 2023\n\nHousing Justice and the HMDA\n\nDue TodayFurther Resources\n\n\n cfpbvideo (2013). What Is HMDA? (Visited on Sep. 03, 2023). Read in Perusall\n Martinez, Emmanuel and Lauren Kirchner (2021). The Secret Bias Hidden in Mortgage-Approval Algorithms. (Visited on Sep. 03, 2023). Read in Perusall\n Martinez, Emmanuel and Lauren Kirchner (2021). How We Investigated Racial Disparities in Federal Mortgage Data . (Visited on Sep. 03, 2023). Read in Perusall\n Richardson, Jason (2022). The Critical Need to Address Missing Data in HMDA » NCRC. (Visited on Sep. 03, 2023). Read in Perusall\n Continue working on Checkpoint 4\n Continue working on Blog Post 1 Revision"
  },
  {
    "objectID": "schedule.html#november-16-2023",
    "href": "schedule.html#november-16-2023",
    "title": "Schedule",
    "section": "November 16, 2023",
    "text": "November 16, 2023\n\nLab: Housing Justice and the HMDA\n\nDue TodayFurther Resources\n\n\n Checkpoint 4 Due\n Blog Post 1 Revision Due\n\n\n Lab: Housing Justice"
  },
  {
    "objectID": "schedule.html#november-21-2023",
    "href": "schedule.html#november-21-2023",
    "title": "Schedule",
    "section": "November 21, 2023",
    "text": "November 21, 2023\n\nWork on Final Project\n\nDue TodayFurther Resources\n\n\n Start working on Checkpoint 5\n Start working on Blog Post 2"
  },
  {
    "objectID": "schedule.html#november-23-2023",
    "href": "schedule.html#november-23-2023",
    "title": "Schedule",
    "section": "November 23, 2023",
    "text": "November 23, 2023\n\nThanksgiving\n\nDue TodayFurther Resources\n\n\n Continue working on Checkpoint 5\n Continue working on Blog Post 2"
  },
  {
    "objectID": "schedule.html#november-28-2023",
    "href": "schedule.html#november-28-2023",
    "title": "Schedule",
    "section": "November 28, 2023",
    "text": "November 28, 2023\n\nEnvironmemtal Justice and the Toxic Release Inventory\n\nDue TodayFurther Resources\n\n\n Villarosa, Linda (2020). “Pollution Is Killing Black Americans. This Community Fought Back.” In: The New York Times. (Visited on Sep. 01, 2021). Read in Perusall\n U.S. Environmental Protection Agency (2016). The Power of Community Right-to-Know. (Visited on Aug. 24, 2021). Read in Perusall\n Hiar, Corbin (2012). EPA’s Toxics Release Inventory Doesn’t Offer Full Picture of Pollution. (Visited on Aug. 30, 2019). Read in Perusall\n list() Read in Perusall\n list() Read in Perusall\n Checkpoint 5 Due\n Continue working on Blog Post 2"
  },
  {
    "objectID": "schedule.html#november-30-2023",
    "href": "schedule.html#november-30-2023",
    "title": "Schedule",
    "section": "November 30, 2023",
    "text": "November 30, 2023\n\nLab: Environmemtal Justice and the Toxic Release Inventory\n\nDue TodayFurther Resources\n\n\n Continue working on Blog Post 2"
  },
  {
    "objectID": "schedule.html#december-05-2023",
    "href": "schedule.html#december-05-2023",
    "title": "Schedule",
    "section": "December 05, 2023",
    "text": "December 05, 2023\n\nData Liberation\n\nDue TodayFurther Resources\n\n\n Crooks, Roderic (2022). “Seeking Liberation: Surveillance, Datafication, and Race”. In: Surveillance & Society 20.4, pp. 413-419. (Visited on Sep. 01, 2023). Read in Perusall\n Blog Post 2 Due"
  },
  {
    "objectID": "schedule.html#december-07-2023",
    "href": "schedule.html#december-07-2023",
    "title": "Schedule",
    "section": "December 07, 2023",
    "text": "December 07, 2023\n\nData Refusal\n\nDue TodayFurther Resources\n\n\n Garcia, Patricia, Tonia Sutherland, Marika Cifor, et al. (2020). “No: Critical Refusal as Feminist Data Practice”. In: Conference Companion Publication of the 2020 on Computer Supported Cooperative Work and Social Computing. CSCW ’20 Companion. New York, NY, USA: Association for Computing Machinery, pp. 199-202. ISBN: 978-1-4503-8059-1. (Visited on May. 11, 2021). Read in Perusall\n Milner, Yeshimabeit (2021). Data 4 Black Lives II Welcome. (Visited on Aug. 24, 2021). Read in Perusall\n Work on final assignments"
  },
  {
    "objectID": "schedule.html#december-12-2023",
    "href": "schedule.html#december-12-2023",
    "title": "Schedule",
    "section": "December 12, 2023",
    "text": "December 12, 2023\n\nFinal Projects\n\nDue TodayFurther Resources\n\n\n Work on final assignments"
  },
  {
    "objectID": "schedule.html#december-14-2023",
    "href": "schedule.html#december-14-2023",
    "title": "Schedule",
    "section": "December 14, 2023",
    "text": "December 14, 2023\n\nFinal Projects\n\nDue TodayFurther Resources\n\n\n Final Project Due\n Community Labor Due\n Enrichment Due"
  },
  {
    "objectID": "schedule.html#calendar-view",
    "href": "schedule.html#calendar-view",
    "title": "Schedule",
    "section": "Calendar View",
    "text": "Calendar View"
  },
  {
    "objectID": "schedule.html#date-view",
    "href": "schedule.html#date-view",
    "title": "Schedule",
    "section": "Date View",
    "text": "Date View\n\nSeptember 05, 2023\n\nIntroductions\nBECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n Fill out the First Day of Class Questionnaire\n\n\n Course slides are here.\n\n\n\n\n\n\nSeptember 07, 2023\n\nHegemonic Backdrops of Big Data\nEPISTEMOLOGY DISCOURSE ANALYSIS BECOMING OBSERVANT\n\nDue TodayFurther Resources\n\n\n boyd, danah and Kate Crawford (2012). “Critical Questions for Big Data”. In: Information, Communication & Society 15.5, pp. 662-679. (Visited on Jan. 19, 2018).\n Fill out the Trigger Warnings Questionnaire in Moodle.\n Install Desktop version of Slack and configure notifications for our course.\n\n\n Course slides are here\n Kitchin, Rob (2014). “Big Data, new epistemologies and paradigm shifts”. En. In: Big Data & Society 1.1, p. 2053951714528481. (Visited on Jul. 16, 2019).\n Leonelli, S. (2014). “What difference does quantity make? On the epistemology of Big Data in biology:”. En. In: Big Data & Society. Publisher: SAGE PublicationsSage UK: London, England. (Visited on Mar. 28, 2020).\n Onuoha, Mimi (2016). The Point of Collection. En. (Visited on Aug. 20, 2021).\n\n\n\n\n\n\nSeptember 12, 2023\n\nMetaphors of Big Data\nDISCOURSE ANALYSIS DISCOURSE\n\nDue TodayFurther Resources\n\n\n Levy Karen, Tim Hwang (2015). ‘The Cloud’ and Other Dangerous Metaphors. En. Section: Technology. (Visited on Aug. 29, 2021).\n Puschmann, Cornelius and Jean Burgess (2014). “Metaphors of Big Data”. En. In: International Journal of Communication 8.0, p. 20. (Visited on May. 02, 2016).\n Create a GitHub account if you don’t have one\n Click on the Student Portfolio GitHub Repo in Moodle to create your portfolio\n Acknowledge that you’ve read and understand the grading contract by completing the Grading Contract Acknowledgement in Moodle\n\n\n Course slides are here\n Here is the article we will engage in today’s activity.\n Discourse Analysis in Nine Steps is here.\n Watson, Sarah M. (2021). Metaphors of Big Data. (Visited on Aug. 30, 2021).\n\n\n\n\n\n\nSeptember 14, 2023\n\nBinary Oppositions in Big Data Discourse\nDISCOURSE ANALYSIS INTERPRETING CULTURAL MEANING\n\nDue TodayFurther Resources\n\n\n Complete course infrastructure set-up by following instructions in the setting-up-r-environment directory in your GitHub portfolio\n DM Professor if you’d like to lead a class discussion for enrichment\n\n\n Course slides are here\n\n\n\n\n\n\nSeptember 19, 2023\n\nThick Data for Big Data\nTHICK DESCRIPTION BECOMING OBSERVANT COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Fiore-Silfvast, Brittany (2014). Hacked Ethnographic Fieldnotes. En. (Visited on Feb. 18, 2021).\n Burrell, Jenna (2012). The Ethnographer’s Complete Guide to Big Data: Small Data People in a Big Data World. (Visited on Aug. 20, 2021).\n Fill out CATME Survey (link sent to your email)\n DM Professor if you’d like to lead a class discussion for enrichment\n Start working on Fieldnote 1\n\n\n Course slides are here\n Here’s an example of some very short “thick description” write-ups of two data environments from my own research.\n Wang, Tricia (2013). Big Data Needs Thick Data. (Visited on Sep. 10, 2019).\n\n\n\n\n\n\nSeptember 21, 2023\n\nScheduling Workshop - Class on Zoom\n\nDue TodayFurther Resources\n\n\n Start working on Team Contract\n Continue working on Fieldnote 1\n\n\n\n\n\n\n\n\n\nSeptember 26, 2023\n\nEthnography in Data Land\nANALYZING SOCIAL FORCES AND SYSTEMS EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n Introduction , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Team Contract Due\n Fieldnote 1 Due\n\n\n Course slides are here\n\n\n\n\n\n\nSeptember 28, 2023\n\nDocumenting Datasets\nDATA DOCUMENTATION COMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Gebru, Timnit, Jamie Morgenstern, Briana Vecchione, et al. (2020). “Datasheets for Datasets”. In: arXiv:1803.09010 [cs]. arXiv: 1803.09010. (Visited on Jan. 24, 2021).\n Get approval for dataset\n Start working on Fieldnote 2\n\n\n Course slides are here\n Bender, Emily M. and Batya Friedman (2018). “Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science”. In: Transactions of the Association for Computational Linguistics 6, pp. 587-604. (Visited on Aug. 20, 2021).\n\n\n\n\n\n\nOctober 03, 2023\n\nMaking Measures Commensurate: Translation and Reductionism\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING TRANSLATION INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Chapter 1 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Continue working on Fieldnote 2\n\n\n Course slides are here\n Activity link is here and here and here\n Espeland, Wendy Nelson and Mitchell L. Stevens (1998). “Commensuration as a Social Process”. In: Annual Review of Sociology 24.1. Publisher: Annual Reviews, pp. 313-343. (Visited on Aug. 30, 2021).\n Merry, Sally Engle (2016). The Seductions of Quantification: Measuring Human Rights, Gender Violence, and Sex Trafficking. En. Google-Books-ID: 0FcqDAAAQBAJ. University of Chicago Press. ISBN: 978-0-226-26131-7.\n\n\n\n\n\n\nOctober 05, 2023\n\nEthnographies of Infrastructure\nCULTURAL ANALYSIS OF INFRASTRUCTURE BECOMING OBSERVANT INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Star, Susan Leigh (1999). “The Ethnography of Infrastructure”. En. In: American Behavioral Scientist 43.3, pp. 377-391. (Visited on Feb. 18, 2016).\n Fieldnote 2 Due\n\n\n Course slides are here\n Lampland, Martha and Susan Leigh Star, ed. (2008). Standards and Their Stories: How Quantifying, Classifying, and Formalizing Practices Shape Everyday Life. 1 edition. Ithaca: Cornell University Press. ISBN: 978-0-8014-7461-3.\n Ottinger, Gwen (2010). “Buckets of Resistance: Standards and the Effectiveness of Citizen Science”. En. In: Science, Technology, & Human Values 35.2, pp. 244-270. (Visited on Oct. 05, 2019).\n Timmermans, Stefan and Steven Epstein (2010). “A World of Standards but not a Standard World: Toward a Sociology of Standards and Standardization*“. In: Annual Review of Sociology 36.1, pp. 69-89. (Visited on Oct. 16, 2014).\n\n\n\n\n\n\nOctober 10, 2023\n\nSorting Things Out: Cultural Analyses of Categories\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Bowker, Geoffrey C. (1998). “The Kindness of Strangers: Kinds and Politics in Classification Systems”. En. In: Library Trends 47.2, pp. 255-292. (Visited on Oct. 14, 2019).\n Work on semiotic analysis\n Start working on Mini-Project 1\n Be sure to get approval for the TED Talks you plan to view for Mini-Project 1.\n\n\n Bowker, Geoffrey C. and Susan Leigh Star (1999). Sorting Things Out: Classification and Its Consequences. En. Cambridge, MA: MIT Press. ISBN: 978-0-262-52295-3.\n Waterton, Claire (2002). “From Field to Fantasy: Classifying Nature, Constructing Europe”. En. In: Social Studies of Science 32.2, pp. 177-204. (Visited on May. 15, 2019).\n Kirksey, Eben (2015). “Species: a praxiographic study”. Fr. In: Journal of the Royal Anthropological Institute 21.4, pp. 758-780. (Visited on Oct. 05, 2019).\n\n\n\n\n\n\nOctober 12, 2023\n\nAutumn Recess\n\nDue TodayFurther Resources\n\n\n Work on semiotic analysis\n Start working on Fieldnote 3\n Continue working on Mini-Project 1\n\n\n\n\n\n\n\n\n\nOctober 17, 2023\n\nInfrastructure Field Day\nCULTURAL ANALYSIS OF INFRASTRUCTURE INTERPRETING CULTURAL MEANING INFRASTRUCTURES\n\nDue TodayFurther Resources\n\n\n Work on stakeholder analysis\n Continue working on Fieldnote 3\n Continue working on Mini-Project 1\n\n\n\n\n\n\n\n\n\nOctober 19, 2023\n\nData Ghost Work\nINTERVIEWING ANALYZING SOCIAL FORCES AND SYSTEMS LABOR\n\nDue TodayFurther Resources\n\n\n Chapter 1 , Gray, Mary L. and Siddharth Suri (2019). Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. Illustrated edition. Boston: Mariner Books. ISBN: 978-1-328-56624-9.\n Work on stakeholder analysis\n Fieldnote 3 Due\n Continue working on Mini-Project 1\n\n\n Course slides are here\n Irani, Lilly (2015). Justice for “Data Janitors”. En-US. (Visited on Dec. 13, 2018).\n Plantin, Jean-Christophe (2019). “Data Cleaners for Pristine Datasets: Visibility and Invisibility of Data Processors in Social Science”. En. In: Science, Technology, & Human Values 44.1. Publisher: SAGE Publications Inc, pp. 52-73. (Visited on Aug. 20, 2021).\n Forsythe, Diana E. (1993). “The Construction of Work in Artificial Intelligence”. En. In: Science, Technology, & Human Values 18.4. Publisher: SAGE Publications Inc, pp. 460-479. (Visited on Aug. 20, 2021).\n\n\n\n\n\n\nOctober 24, 2023\n\nSocial Constructions of Expertise in Data Work\nINTERVIEWING INTERPRETING CULTURAL MEANING LABOR\n\nDue TodayFurther Resources\n\n\n Chapter 2 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Work on stakeholder analysis\n Continue working on Mini-Project 1\n\n\n Gieryn, Thomas F. (1999). Cultural Boundaries of Science: Credibility on the Line. En. University of Chicago Press. ISBN: 978-0-226-29261-8.\n\n\n\n\n\n\nOctober 26, 2023\n\nHow Data Domesticates Us: Rituals for Data Cleaning\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n Ribes, David and Steven J Jackson (2013). “Data bite man: The work of sustaining a long-term study”. In: Raw data” is an oxymoron. Ed. by Lisa Gitelman. Cambridge, MA: MIT Press, pp. 147-166.\n Work on ritual analysis\n Mini-Project 1 Due\n\n\n Course slides are here\n Bowker, Geoffrey C. (2000). “Biodiversity Datadiversity”. En. In: Social Studies of Science 30.5, pp. 643-683. (Visited on May. 14, 2014).\n Walford, Antonia (2017). “Raw Data: Making Relations Matter”. En_US. In: Social Analysis 61.2. Publisher: Berghahn Journals Section: Social Analysis, pp. 65-80. (Visited on Aug. 20, 2021).\n Pink, Sarah, Shanti Sumartojo, Deborah Lupton, et al. (2017). “Mundane data: The routines, contingencies and accomplishments of digital living”. En. In: Big Data & Society 4.1. Publisher: SAGE Publications Ltd, p. 2053951717700924. (Visited on Aug. 30, 2021).\n\n\n\n\n\n\nOctober 31, 2023\n\nData Collection Rituals\nPARTICIPANT OBSERVATION COMMUNICATING (IN) CONTEXT RITUALS\n\nDue TodayFurther Resources\n\n\n Work on ritual analysis\n Group evaluations open\n Start working on Mini-Project 2\n\n\n Course slides are here\n\n\n\n\n\n\nNovember 02, 2023\n\nCromwell Day\n\nDue TodayFurther Resources\n\n\n Work on ritual analysis\n Start working on Fieldnote 4\n Continue working on Mini-Project 2\n\n\n\n\n\n\n\n\n\nNovember 07, 2023\n\nWork on Group Project\n\nDue TodayFurther Resources\n\n\n Group Evaluations Due\n Work on user guide\n Continue working on Fieldnote 4\n Continue working on Mini-Project 2\n\n\n\n\n\n\n\n\n\nNovember 09, 2023\n\nWork on Group Project\n\nDue TodayFurther Resources\n\n\n Work on user guide\n Fieldnote 4 Due\n Continue working on Mini-Project 2\n\n\n\n\n\n\n\n\n\nNovember 14, 2023\n\nInstitutional Incentives\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n Work on institutional analysis\n Continue working on Mini-Project 2\n\n\n Course slides are here\n\n\n\n\n\n\nNovember 16, 2023\n\nEconomies of Data Production\nANALYZING SOCIAL FORCES AND SYSTEMS INCENTIVES\n\nDue TodayFurther Resources\n\n\n Chapter 3 , Biruk, Cal (2018). Cooking Data: Culture and Politics in an African Research World. Illustrated edition. Durham: Duke University Press Books. ISBN: 978-0-8223-7074-1.\n Work on institutional analysis\n Mini-Project 2 Due\n\n\n Gerlitz, Carolin and Anne Helmond (2013). “The like economy: Social buttons and the data-intensive web”. En. In: New Media & Society 15.8. Publisher: SAGE Publications, pp. 1348-1365. (Visited on Aug. 30, 2021).\n Beer, David (2015). “Productive measures: Culture and measurement in the context of everyday neoliberalism”. En. In: Big Data & Society 2.1. Publisher: SAGE Publications Ltd, p. 2053951715578951. (Visited on Aug. 29, 2021).\n\n\n\n\n\n\nNovember 21, 2023\n\nMobilizing Data: Making Numbers Actionable\nDISCOURSE ANALYSIS SITUATING KNOWLEDGE MOBILIZATION\n\nDue TodayFurther Resources\n\n\n Ottinger, Gwen and Rachel Zurer (2011). New Voices, New Approaches: Drowning in Data. En-US. (Visited on Dec. 13, 2018).\n Work on discourse analysis\n\n\n Course slides are here.\n Pine, Kathleen H. and Max Liboiron (2015). “The Politics of Measurement and Action”. In: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery, pp. 3147-3156. ISBN: 978-1-4503-3145-6. (Visited on Aug. 30, 2021).\n Dourish, Paul and Edgar Gómez Cruz (2018). “Datafication and data fiction: Narrating data and narrating with data”. En. In: Big Data & Society 5.2. Publisher: SAGE Publications Ltd, p. 2053951718784083. (Visited on Apr. 05, 2021).\n\n\n\n\n\n\nNovember 23, 2023\n\nThanksgiving Break\n\nDue TodayFurther Resources\n\n\n Work on discourse analysis\n\n\n\n\n\n\n\n\n\nNovember 28, 2023\n\nMobilizing Data Otherwise: Citizen Science and Sensing\nDISCOURSE ANALYSIS COMMUNICATING (IN) CONTEXT MOBILIZATION\n\nDue TodayFurther Resources\n\n\n Gabrys, Jennifer, Helen Pritchard, and Benjamin Barratt (2016). “Just good enough data: Figuring data citizenships through air pollution sensing and data stories”. En. In: Big Data & Society 3.2. Publisher: SAGE Publications Ltd, p. 2053951716679677. (Visited on Mar. 28, 2020).\n Work on user guide\n Start working on Mini-Project Revisions\n\n\n Course slides are here.\n Calvillo, Nerea (2018). “Political airs: From monitoring to attuned sensing air pollution”. En. In: Social Studies of Science 48.3, pp. 372-388. (Visited on Sep. 24, 2019).\n Jalbert, Kirk and Abby J. Kinchy (2016). “Sense and Influence: Environmental Monitoring Tools and the Power of Citizen Science”. In: Journal of Environmental Policy & Planning 18.3. Publisher: Routledge _ eprint: https://doi.org/10.1080/1523908X.2015.1100985, pp. 379-397. (Visited on Aug. 30, 2021).\n\n\n\n\n\n\nNovember 30, 2023\n\nData Activism and Advocacy\nDISCOURSE SITUATING KNOWLEDGE MOBILIZATION CREDIBILITY\n\nDue TodayFurther Resources\n\n\n Liboiron, Max (2015). “Disaster Data, Data Activism : Grassroots Responses to Representing Superstorm Sandy”. En. In: Extreme Weather and Global Media. Ed. by Julia Leyda and Diane Negra. Taylor & Francis Group. (Visited on Aug. 27, 2019).\n Work on user guide\n Continue working on Mini-Project Revisions\n Start working on Fieldnote 5\n\n\n Bruno, Isabelle, Emmanuel Didier, and Tommaso Vitale (2014). Statactivism: Forms of Action between Disclosure and Affirmation. En. SSRN Scholarly Paper ID 2466882. Rochester, NY: Social Science Research Network. (Visited on Dec. 18, 2018).\n Milan, Stefania and Lonneke van der Velden (2016). “The Alternative Epistemologies of Data Activism”. In: Digital Culture & Society 2.2, pp. 57-74. (Visited on Jul. 16, 2019).\n Currie, Morgan, Britt S Paris, Irene Pasquetto, et al. (2016). “The conundrum of police officer-involved homicides: Counter-data in Los Angeles County”. En. In: Big Data & Society 3.2, p. 2053951716663566. (Visited on Aug. 08, 2018).\n\n\n\n\n\n\nDecember 05, 2023\n\nData Agnotology: Ignorance and Knowledge Gaps\nEPISTEMOLOGY IGNORANCE SITUATING KNOWLEDGE\n\nDue TodayFurther Resources\n\n\n mimimimimi (2021). On Missing Data Sets. original-date: 2016-02-03T16:30:28Z. (Visited on Aug. 20, 2021).\n Milan, Stefania and Emiliano Treré (2020). “The Rise of the Data Poor: The COVID-19 Pandemic Seen From the Margins”. En. In: Social Media + Society 6.3. Publisher: SAGE Publications Ltd, p. 2056305120948233. (Visited on Aug. 31, 2021).\n First Draft Due\n Continue working on Mini-Project Revisions\n Continue working on Fieldnote 5\n\n\n Course slides are here\n D’Ignazio, Catherine and Lauren F. Klein (2020). Data Feminism. Cambridge, Massachusetts: The MIT Press. ISBN: 978-0-262-04400-4.\n\n\n\n\n\n\nDecember 07, 2023\n\nData and Algorithmic Power\nPOWER SITUATING KNOWLEDGE EVALUATING ETHICAL DILEMMAS\n\nDue TodayFurther Resources\n\n\n Eubanks, Virginia (2018). “A Child Abuse Prediction Model Fails Poor Families”. In: Wired. (Visited on Mar. 28, 2019).\n Fieldnote 5 Due\n Continue working on Mini-Project Revisions\n\n\n Brayne, Sarah (2017). “Big Data Surveillance: The Case of Policing”. In: American Sociological Review 82.5. Publisher: SAGE Publications Inc, pp. 977-1008. (Visited on Aug. 18, 2021).\n Christin, Angèle (2020). “The ethnographer and the algorithm: beyond the black box”. En. In: Theory and Society 49.5, pp. 897-918. (Visited on Aug. 31, 2021).\n Seaver, Nick (2017). “Algorithms as culture: Some tactics for the ethnography of algorithmic systems”. En. In: Big Data & Society 4.2. Publisher: SAGE Publications Ltd, p. 2053951717738104. (Visited on Jan. 22, 2021).\n\n\n\n\n\n\nDecember 12, 2023\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Work on user guide revisions\n MP Revisions Due\n\n\n\n\n\n\n\n\n\nDecember 14, 2023\n\nFinal Projects\nCOMMUNICATING (IN) CONTEXT\n\nDue TodayFurther Resources\n\n\n Final Project Due\n Enrichment Due\n Community Labor Due"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Instructions for the fieldnote assignment can be found here."
  },
  {
    "objectID": "grading_contract.html#why-a-grading-contract",
    "href": "grading_contract.html#why-a-grading-contract",
    "title": "Grading Contract",
    "section": "Why a grading contract?",
    "text": "Why a grading contract?\nThere are many benefits to contract grading. Here are there reasons why I’ve opted for a grading contract in this course:\n\nI want you to feel as though you can experiment with your writing in this course. Rather than focusing on what you think I want out of your assignments or “writing to the rubric,” grading contracts empower you to take more risks.\nGrading contracts value the time and effort you put into the course and reward students who invest extra time in their learning.\nGrading contracts make it easier for you to anticipate the grade you will receive and plan for achieving that grade.\nGrading contracts promote equity. With grades based entirely on labor, students aren’t penalized for not entering the course with the same experience or background knowledge as their peers."
  },
  {
    "objectID": "grading_contract.html#assignment-completion",
    "href": "grading_contract.html#assignment-completion",
    "title": "Grading Contract",
    "section": "Assignment completion",
    "text": "Assignment completion\nFor an assignment to be considered complete (i.e. not missed), it must meet the minimum criteria outlined in Moodle. It also must be completed “in good faith” - meaning in a way that demonstrates integrity to the spirit of the assignment. Note that you have at least one “gimme” for each assignment in this course. This means that if for some reason there was a misunderstanding of the expectations for completion, in most cases, you will have an opportunity to try again as long as you haven’t already missed other assignments in the same category."
  },
  {
    "objectID": "grading_contract.html#assignments",
    "href": "grading_contract.html#assignments",
    "title": "Grading Contract",
    "section": "Assignments",
    "text": "Assignments\n\nBlog Posts\nFor each blog post, you will use data we study in the course to produce a compelling data visualization in Tableau documenting an issue you believe warrants public concern. Referencing case study materials and the data documentation, you will write an 800-word blog post that presents your data visualization and helps the audience responsibly interpret the visualization by describing “what counts” in the data, providing some context on the social contexts of the data’s production, and detailing what people and issues have been erased from the data and why. You will reflect on the decisions you made in producing the visualization, summarize some conclusions we can draw it, and conclude with a call to action outlining something that should be done based on these conclusions.\n\n\nFinal Project\nFor the final project, you will choose a dataset on a social justice topic of interest to you and evaluate how data analysis techniques could be applied to the dataset to support diverse, and sometimes conflicting claims. There are 4 components to the final paper:\n\nYou will study various sources to unpack the cultural history of the dataset and the contexts of its production.\nYou will produce two compelling visualizations of the dataset in Tableau to support a particular claim.\nYou will then produce two visualizations of the same dataset in Tableau that refute that claim.\nYou will then be expected to write a 1500-word argumentative paper that makes a claim, provides data-based evidence to support that claim, presents counter-arguments with the same data, and finally discusses why these arguments fail to refute the claim.\n\nThroughout this paper, you will be expected to present the evidence in ways that foreground the cultural contexts of the data’s production and reflect on the choices made in data visualization. You will complete checkpoints towards this final project each week of the semester to ensure that there is plenty of time to incorporate feedback provided by me and your peers into the final product.\n\n\nReading Annotations\nEach week a selection of course readings will be posted on Perusall. For each selection, you will be expected to post 3 quality annotations. A quality annotation is one in which you synthesize concepts, ask thought-provoking questions, or connect ideas to external issues. I have found that students get the most out of Perusall when they respond to each other’s annotations. Annotations must be completed before class to receive credit.\n\n\nCommunity Labor Points\nIt’s important to me that we establish a collaborative learning environment in this course. Work to build and sustain communities is often an invisible form of labor. In an effort to foreground and reward that labor, I’ve built opportunities to contribute to the course community into our grading contract. To earn a ‘B’ or higher in the course, you will need to earn at least 8 community labor points. Note that there are certain forms of labor that you can perform more than once, but there are max points that you can earn in each category.\n\n\n\n\n\n\n\n\nPoints\nLabor\nMax Points\n\n\n\n\n+1\nStart a discussion thread on course-relevant topic in the #fys-189-discussions channel on Slack.1\nNone\n\n\n+1\nRespond to a discussion thread on Slack.\nNone\n\n\n+1\nLead an opening check-in.2\n1\n\n\n+2\nContribute class notes3\n2\n\n\n+3\nRecord a Tableau “skill share” and post it on Slack.\nNone\n\n\n\n\n1Note that this is separate from asking a question about the course administration or assignments in the #fys-189-questions channel.\n\n\n2Each class we will start out by participating in a collaborative poll to check-in with where our heads are. If you sign up to lead an opening check-in, you will create this opening poll by adding a slide to a deck I will make available on Moodle. Instructions for doing so will be available on the Slide. Then at the start of class, you will be called upon to launch/lead your check-in poll. You can sign-up to lead this opening session via a Scheduler on Moodle.\n\n\n3 Following a class period, up to two students may type up a 1-page outline of what was covered in that class period and post a link to that outline in #fys-189-class-notes. You can sign-up to serve as the notetaker for a certain class here. These notes should be a full, single-space page, and should make sense to someone that was not present in class.\n\nNote that throughout the semester, I may offer additional opportunities to earn community labor points as unexpected forms of course labor arise."
  },
  {
    "objectID": "grading_contract.html#enrichment",
    "href": "grading_contract.html#enrichment",
    "title": "Grading Contract",
    "section": "Enrichment",
    "text": "Enrichment\n‘A’ grades will be assigned to students that meet the requirements to earn a ‘B’ in the course and enrich those assignments by doing three of the following. Timelines for completing enrichment must be coordinated with me in student consultation hours by the end of the third week of the semester.\n\nWrite a 500 to 750-word memo reflecting on your standpoint in relation to the arguments made in your first blog post. What gives you unique insight on the topic? What limits your knowledge on the topic? You should consider how your background, culture, education, and experiences have shaped the knowledge you have on the topic. Conclude your memo by outlining ideas that you have for transforming the blog post assignment to ensure that the data work pursues a “stronger objectivity.” Be sure to cite and define standpoint theory and strong objectivity in your response.\nVisceralize the dataset you are studying for your final project. Your visceralization should represent information derived from all of the observations in at least one variable in the dataset. It should also evoke at least one of the five senses. You can submit the visceralization in any format, but it should include a 250-word caption describing what you are intending to convey. Read more about data visceralization here and here.\nEarn the maximum (16) community labor points.\nCreate a concept map for our course. To create a concept map, you can begin by listing out ideas, concepts, datasets, people, institutions, and events that we’ve covered in this course. Begin organizing components of your lists into a series of nodes. When creating nodes, be sure to distinguish between topical details and course concepts. Organize the nodes into a meaningful visual representation of what we’ve been covering in the course. Use lines and arrows to indicate connections. You can also use varying colors and shapes to draw out differences. You can be as creative as you wish in designing the map, but it must include at least 25 nodes interconnected with lines and arrows. In a 250-word accompanying memo, describe your rationale for the organization of concepts in your map."
  },
  {
    "objectID": "checkpoints/checkpoint1.html",
    "href": "checkpoints/checkpoint1.html",
    "title": "Checkpoint 1: Tableau Basics",
    "section": "",
    "text": "The goal of this assignment is to get you started with Tableau. This data analysis in this assignment is admittedly pretty boring at least for me it is). …but it’s necessary to get some basic terminology and exposure to Tableau before we can do more interesting things with it.\n\n\n\n\n\n\nTip\n\n\n\nYou may run into issues with install that I have not foreseen. If that happens, reach out to me on Slack as soon as possible, and we will see what we can do to address those issues."
  },
  {
    "objectID": "checkpoints/checkpoint1.html#instructions",
    "href": "checkpoints/checkpoint1.html#instructions",
    "title": "Checkpoint 1: Tableau Basics",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: Install Tableau\n\nThe latest version of Tableau Desktop can be found here.\nClick on the link above and select “Download Tableau Desktop.” On the form, enter your school email address for Business E-mail and enter the name of your school for Organization.\nActivate with your product key: Find key here\nAlready have a copy of Tableau Desktop installed? Update your license in the application: Help menu → Manage Product Keys\n\n\n\nPart 2: Get Acquainted with Tableau\n\nNavigate to Tableau’s Getting Started Video Playlist.\nEnter information about Smith College in order to access the videos. You do not need to leave a personal phone number. Feel free to list my office phone number.\nDownload Sample - Superstore.xls - an Excel file listed at the bottom of the page.\nWatch all videos (about 20 minutes), and follow along by recreating the dashboard shown in the video in Tableau Desktop. Note that you are working with the Desktop version of Tableau, not the Cloud version. The differences will be very minor, but just keep it in mind. Save the workbook.\nOnce you are finished with both workbooks, export them from Tableau Desktop, and upload them to Moodle in the checkpoint 1 assignment."
  },
  {
    "objectID": "checkpoints/checkpoint2.html",
    "href": "checkpoints/checkpoint2.html",
    "title": "Checkpoint 2: Getting to Know Your Dataset",
    "section": "",
    "text": "The goal of this assignment is to help you historicize and familiarize yourself with the dataset you will be examining in the final project."
  },
  {
    "objectID": "checkpoints/checkpoint2.html#instructions",
    "href": "checkpoints/checkpoint2.html#instructions",
    "title": "Checkpoint 2: Getting to Know Your Dataset",
    "section": "Instructions",
    "text": "Instructions\n\nNavigate to the data dictionary and data documentation for your dataset.\nRead through these documents carefully. Be sure to note the types of variables present in the data and the definitions provided throughout the documentation. Pay close attention to how categories are divided and how quantities are calculated.\nFill out this worksheet.\nOnce you are finished, upload the worksheet to Moodle in the checkpoint 2 assignment.\n\n\n\n\n\n\n\nTip\n\n\n\nYour dataset may not have any categorical variables, or it may not have any numeric variables. If this is the case, just indicate so in the worksheet and then leave the remainder of that section blank. You will not lose credit if this is the case."
  },
  {
    "objectID": "assignments/blogpost1.html",
    "href": "assignments/blogpost1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Using data downloaded from the CDC’s WONDER API, produce a compelling data visualization in Tableau. Referencing case study materials and the data documentation, write an 800-word blog post that presents a claim of fact by leveraging your data visualization as evidence. Help the audience responsibly interpret the visualization by describing “what counts” in the data, providing some context on the social contexts of the data’s production, and detailing what people and issues have been erased from the data and why. When finished, submit your blog post and visualization on Moodle.\n\n\n\n\n\n\nImportant\n\n\n\nI need to be able to see your data visualization when I review your blog post. It is easier for me to review all submissions when the blog post is directly embedded in the document. Be sure to export the visualization as a .PNG file from Tableau and include it in the document that you submit on Moodle."
  },
  {
    "objectID": "assignments/blogpost1.html#suggested-blog-post-structure",
    "href": "assignments/blogpost1.html#suggested-blog-post-structure",
    "title": "Blog Post 1",
    "section": "Suggested Blog Post Structure",
    "text": "Suggested Blog Post Structure\n\nIntroduction and Main Argument (100)\n\nBlog posts often open with a catchy quote, story, or statement\nThey also provide guidance on where your writing is taking a reader\nYour thesis statement should be clear from your introduction. Be sure that you are making a claim of fact.\n\n\n\nBackground on the issue your blog is addressing (100)\n\nWhy should we care about what’s in your data visualization?\nWhat is at stake here? Be sure to consider your rhetorical positioning.\nBe sure to cite sources.\n\n\n\nBackground on the Dataset and your Subset (150)\n\nWho produced this data?\nHow was it collected? When and where?\nWhat counts in this data? How is it categorized?\nWhat subset of the data are you working with, and how did you prepare it for analysis/visualization?\n\n\n\nExplanation (200)\n\nWhat steps did you take to produce this visualization? Make sure these steps are described for a general audience that may not have experience working in Tableau. Avoid using Tableau-specific language.\nWhat does your plot show?\nWhat are some quantitative facts that we can summarize from the plot?\n\n\n\nExplication (150)\n\nHow should we interpret this plot?\nWhat are some issues that go unaddressed in the plot?\nHow might the insights we derive from the plot be improved if different variables or modes of categorization were available?\n\n\n\nConclusion and call to action (100)\n\nRestate what you learned\nOffer a normative suggestion for what should happen based on your analysis"
  },
  {
    "objectID": "assignments/blogpost1.html#accessing-cdc-wonder-data",
    "href": "assignments/blogpost1.html#accessing-cdc-wonder-data",
    "title": "Blog Post 1",
    "section": "Accessing CDC WONDER Data",
    "text": "Accessing CDC WONDER Data\n\nNavigate to https://wonder.cdc.gov/ucd-icd10.html, read the Data Restrictions, and click I Agree.\nIn section 1 of the WONDER form, determine how you want to aggregate (group) your results. This is what we are looking to show differences in death rates by. Do you want to show differences in death rates by race, over time, by geography, by gender, by ethnicity? Three important notes:\n\nYou may select any grouping variables except for anything in the Cause of Death section. This is because we are going to filter to one cause of death.\nYou should select 2-3 grouping variables.\nIf you group by age-groups, be sure to select the checkbox for age-adjusted crude rate. Refer to the data documentation to learn why this is so important!\n\nBe sure to also title your dataset in Section 1.\n\n\n\nIn sections 2-5, you have the option to filter your results. Perhaps you just want to look at death rates in one state, in one year, for one demographic, etc. You would set those options here. Important notes:\n\nYou don’t have to apply any filters, but you may. If you don’t, your data will represent the death rates in the entire US from 1999 to 2021.\nIf you group by a variable, I don’t recommend you also filter by that variable. For example, if I choose to compare death rates across states, I will group my results by state. But if then I filter my data to MA, I’m not going to be able to compare across states because my data will only have one state.\nThe more specific your data is (i.e. the more you filter) the more likely you will have suppressed values. It’s ok to have some suppressed values in your analysis, but we don’t want all suppressed data!\n\nIn section 6, you should filter to one cause of death, and it can either be a specific cause, or a more general cause. For instance, I could select the entire set of codes for O00-O99 (Pregnancy, childbirth and the puerperium) to visualize pregnancy-related deaths. Alternatively, I could click on that category, and the click the button “Open” at the bottom of the screen to select a more specific cause in that category, such as O00-O07 (Pregnancy with abortive outcome).\n\nIf you are not sure where to find a certain cause, you can search for it via the Search button. If that doesn’t work feel free to ask in #fys-189-questions!\n\n\n\n\nIn section 7:\n\nCheck the box for Export results\nUncheck the box for Show totals\nCheck the boxes for Show 0 and Suppressed Values\nSet the Precision to 2 decimal places\n\n\n\n\nClick Send\nLoad the data into your visualization software, and remove the Notes column.\nHappy visualizing!"
  },
  {
    "objectID": "checkpoints/checkpoint3.html",
    "href": "checkpoints/checkpoint3.html",
    "title": "Checkpoint 3: Supporting a Claim with Evidence",
    "section": "",
    "text": "The goal of this assignment is to help you formalize a claim for your final project and to develop data-based evidence in support of that claim. In this checkpoint, you will be writing about one-third of the text that will appear in your final project essay.\nA claim is a statement that something is a certain way or happened a certain way. A claim needs to be proven or disproven with evidence. It’s a suggestion for what is true, even though not everyone might agree that that thing is true. A claim is different than empirical evidence. When we report what a visualization empirically shows us (more people in the US died of x than y in 2020), this is evidence. The claim that you record should not be a summary of what we see in any visualization; it should be a more debatable statement that the visualization would serve as evidence of (Populations that have been historically marginalized by the medical community continue to be underserved when it comes to x)."
  },
  {
    "objectID": "checkpoints/checkpoint3.html#instructions",
    "href": "checkpoints/checkpoint3.html#instructions",
    "title": "Checkpoint 3: Supporting a Claim with Evidence",
    "section": "Instructions",
    "text": "Instructions\n\nLoad your dataset into Tableau.\nCreate at least four visualizations with your dataset.\nWrite captions for each that include the following:\n\n\nDescription: What is this a visualization of? How did you create it? Reference the source, the selected variables, the geographic and temporal scope, and the plot type. If you applied filters, explain that.\nSummary: What is one fact we can derive from the visualization?\nInterpretation: How we can interpret that fact? What claim might it support?\n\n\nSelect two of the visualizations that you created in order to develop a claim about your final project topic. Make sure you are making a claim of fact. Also make sure that your visualizations directly support that claim.\n\n\nFor these two visualizations, add clear labels, titles, and captions. Ensure that the visualizations are self-explanatory, meaning that a reader shouldn’t have to look up values to interpret them. Ensure that the visualizations follow visual analytics fundamentals. Export these visualizations as images.\n\n\nComplete this worksheet.\nOnce you are finished, upload the worksheet to Moodle in the checkpoint 3 assignment. You don’t need to submit all of the visualizations you created in earlier steps."
  },
  {
    "objectID": "checkpoints/checkpoint4.html",
    "href": "checkpoints/checkpoint4.html",
    "title": "Checkpoint 4: Anticipating Counter-Arguments",
    "section": "",
    "text": "The goal of this assignment is to help you anticipate how an opponent of your claim may develop data-based evidence in refutation of your claim. This assignment will give you an opportunity to think through strategies of data wrangling and visualization that can produce distorted depictions of social phenomena. Further, you will produce text that anticipates and responds to potential counter-arguments, showing how they may be invalid, irrelevant, or insufficient. In this checkpoint, you will be writing about one-third of the text that will appear in your final project essay."
  },
  {
    "objectID": "checkpoints/checkpoint4.html#instructions",
    "href": "checkpoints/checkpoint4.html#instructions",
    "title": "Checkpoint 4: Anticipating Counter-Arguments",
    "section": "Instructions",
    "text": "Instructions\n\nConsider some of the counter-arguments wielded against your claim. Search for articles (i.e. newspaper, blog post, journal articles) where an individual either directly or indirectly opposes your claim. Note how they frame their arguments. What kind of evidence do they use?\nLoad your dataset into Tableau.\nCreate at least three visualizations with your dataset that engage one of the following data distortion strategies:\n\n\nSelect: How might someone cherry-pick variables to produce a competing claim?\nFilter: How might someone subset the data to produce a competing claim?\nNot filter: How, in not filtering the data to a certain subset, might someone gloss over issues that we can only see when the data is zoomed in?\nGroup-by: How might someone aggregate the data into groups in order to hide details we can only see at individual record levels?\nUngroup: How might someone divide grouped portions of the data into individual records to hide issues that we can only see when the data is aggregated?\nPlot Selection or Aesthetics: How might someone use specific plotting techniques to produce a data visualization that would refute your claim?\n\n\nWrite captions for each that include the following:\n\n\nDescription: What is this a visualization of? How did you create it? Reference the source, the selected variables, the geographic and temporal scope, and the plot type. If you applied filters, explain that.\nSummary: What is one fact we can derive from the visualization?\nInterpretation: How we can interpret that fact? What claim might it support?\n\n\nSelect one of the visualizations that you created that an opponent might leverage to refute your claim.\n\n\nFor this visualization, add clear labels, a title, and a caption. Ensure that the visualization is self-explanatory, meaning that a reader shouldn’t have to look up values to interpret it. Export the visualization as an image.\n\n\nConduct research to further your understanding of why this evidence may be invalid, irrelevant, or insufficient. Be sure to record citations for each source you encounter.\nComplete this worksheet.\nOnce you are finished, upload the worksheet to Moodle in the checkpoint 4 assignment."
  },
  {
    "objectID": "checkpoints/checkpoint5.html",
    "href": "checkpoints/checkpoint5.html",
    "title": "Checkpoint 5: Full Draft",
    "section": "",
    "text": "In this assignment, you will submit a full draft of your final essay. In addition to aggregating text that you wrote in other checkpoints, you will write an Introduction, Background, and Conclusion section. Keep in mind that this is a draft. Not everything has to be perfectly polished at this point. However, your document should contain at least 1500 words (not including citations); it must include text covering all sections listed below, and all sources need to be cited. Please embed the data visualizations you created as images directly in the document. Do not submit them as separate files. Once you are finished, upload the draft to Moodle in the checkpoint 5 assignment."
  },
  {
    "objectID": "checkpoints/checkpoint5.html#full-draft-outline",
    "href": "checkpoints/checkpoint5.html#full-draft-outline",
    "title": "Checkpoint 5: Full Draft",
    "section": "Full Draft Outline",
    "text": "Full Draft Outline\nYour full draft should follow the attached outline:\n\nIntroduction (~200 words)\n\nIntroduce the topic you are investigating, providing background information critical to understanding the significance of the thesis statement/claim\nIndicate your thesis statement/claim\n\n\n\nOverview of the dataset (~300 words)\n\nSuggested language: To support this claim, I examined a dataset produced by _____ that documents _____.\n\n\nThis section should include at least the following:\n\nWhat the data represents\nWho produced it\nIts observational unit\nSome variables that describe that observational unit\nA bit of its history/context of the dataset from earlier labs\nA few data limitations\n\n\n\n\n\n\n\n\nExample Paragraph\n\n\n\nTo examine this claim, I studied a dataset published by the EPA [<-- who produced it] that documents the environmental compliance and enforcement history of every EPA-regulated facility in the US, including prisons [<-- what it represents]. For every EPA-regulated facility in the US in a given year [<-- observational unit], the dataset reports information such as the permits the facility has been awarded, enforcement actions taken against the facility, and penalties it has assessed [<-- variables]. The EPA has been integrating this data from a number of different compliance databases for major federal regulations (such as the Clean Air Act and the Safe Drinking Water Act) for over ten years [<-- history/context]. The data tends to be more comprehensive for larger facilities than for smaller facilities and does not include information about compliance with all environmental laws [<--limitations].\n\n\n\n\nEvidence supporting your claim, including plots (~400 words)\n\nFor now, copy from a previous checkpoint\n\n\n\nCounter-evidence, including plots (~300 words)\n\nFor now, copy from a previous checkpoint\n\n\n\nRefutation of the counter-evidence (~200 words)\n\nFor now, copy from a previous checkpoint\n\n\n\nConclusion (~200 words)\n\nRestate what you’ve shown in your essay\nOffer a normative evaluation of your research. In other words, tell us how we should think about this topic or what should be done based on your findings. This section should not outline your personal opinion on what should be done. Be sure you can back up all of your suggestions with evidence - either through your data or through external research.\n\n\n\n\n\n\n\nExample Normative Evaluation\n\n\n\nMy analysis shows how important critical access hospitals are for ensuring that rural populations have access to adequate hospital care. Since critical access hospitals are often the only providers of health care in their communities, there is critical need for federal funding to be allocated towards supporting this healthcare infrastructure. Research by McFayden et al (2023) has shown how the operating profitability of critical access hospitals increased significantly during Covid-19 as a result of government-issued Public Health Emergency Funding. In the absence of this funding, profitability was much lower, and there were more hospitals with negative margins. McFayden et al (2023) thus argue that federal funding is a particularly important source of revenue for supporting the financial well-being of critical access hospitals. Ensuring critical access hospitals have the resources they need to operate is essential for providing equitable access to healthcare.\nMcFayden, Laura B., George H. Ping, Susie Gurzenda, Kristie Thompson, and Kristin L. Reiter. “The Impact of COVID-19 Funding on Profitability of Critical Access Hospitals.” Flex Monitoring Team (2023). https://www.flexmonitoring.org/sites/flexmonitoring.umn.edu/files/media/Impact_of_COVID19_funding_on_Profitability_of_CAHs.pdf"
  },
  {
    "objectID": "assignments/blogpost1-revision.html",
    "href": "assignments/blogpost1-revision.html",
    "title": "Blog Post 1 Revision",
    "section": "",
    "text": "For this assignment, you will submit two things: 1) a revision plan, and 2) a revised blog post. First, you should read this document on how to create a revision plan. Then you should begin writing your revision plan. Your revision plan can be submitted as a Word document that follows the guidelines below:\n\nSummarize in your own words the most recurring comments you received from me and from your peers as a series of bullet points. You should list at least three bullet points, and they should be written in complete, descriptive sentences.\nHighlight the comments you plan to address. Add a sub-bullet point below each comment you plan to address, indicating specifically how you will address that comment in your revision. For comments you don’t plan to address, include a sub-bullet point indicating why you don’t plan to address it. You should be able to provide appropriate rationale for why you don’t plan to address certain feedback. It’s not enough to say that you can’t fit something within the word limit.\n\nFinally, revise your blog post following your revision plan. Remember that grammar, spelling, and punctuation concerns should not be included in a revision plan. Those concerns are addressed in a proofreading stage, not a revising stage.\nWhen finished, submit your revised blog post and revision plan on Moodle."
  },
  {
    "objectID": "assignments/blogpost2.html",
    "href": "assignments/blogpost2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "Using either the Eviction Lab data, NYC Stop and Frisk data, or the EPA’s Toxic Release Inventory data, produce a compelling data visualization in Tableau. Referencing case study materials and the data documentation, write an 800-word blog post that presents a claim of fact by leveraging your data visualization as evidence. Help the audience responsibly interpret the visualization by describing “what counts” in the data, providing some context on the social contexts of the data’s production, and detailing what people and issues have been erased from the data and why. When finished, submit your blog post and visualization on Moodle.\n\n\n\n\n\n\nImportant\n\n\n\nI need to be able to see your data visualization when I review your blog post. It is easier for me to review all submissions when the blog post is directly embedded in the document. Be sure to export the visualization as a .PNG file from Tableau and include it in the document that you submit on Moodle."
  },
  {
    "objectID": "assignments/blogpost2.html#suggested-blog-post-structure",
    "href": "assignments/blogpost2.html#suggested-blog-post-structure",
    "title": "Blog Post 2",
    "section": "Suggested Blog Post Structure",
    "text": "Suggested Blog Post Structure\n\nIntroduction and Main Argument (100)\n\nBlog posts often open with a catchy quote, story, or statement\nThey also provide guidance on where your writing is taking a reader\nYour thesis statement should be clear from your introduction. Be sure that you are making a claim of fact.\n\n\n\nBackground on the issue your blog is addressing (100)\n\nWhy should we care about what’s in your data visualization?\nWhat is at stake here? Be sure to consider your rhetorical positioning.\nBe sure to cite sources.\n\n\n\nBackground on the Dataset and your Subset (150)\n\nWho produced this data?\nHow was it collected? When and where?\nWhat counts in this data? How is it categorized?\nWhat subset of the data are you working with, and how did you prepare it for analysis/visualization?\n\n\n\nExplanation (200)\n\nWhat steps did you take to produce this visualization? Make sure these steps are described for a general audience that may not have experience working in Tableau. Avoid using Tableau-specific language.\nWhat does your plot show?\nWhat are some quantitative facts that we can summarize from the plot?\n\n\n\nExplication (150)\n\nHow should we interpret this plot?\nWhat are some issues that go unaddressed in the plot?\nHow might the insights we derive from the plot be improved if different variables or modes of categorization were available?\n\n\n\nConclusion and call to action (100)\n\nRestate what you learned\nOffer a normative suggestion for what should happen based on your analysis"
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Lab 1: Fundamentals of Data",
    "section": "",
    "text": "In today’s activity, you are going to generate two rectangular datasets documenting information about the values held by students in our classroom. Your first dataset will be an individual dataset, and your second should be an aggregate dataset based on summarized information from the first."
  },
  {
    "objectID": "labs/lab1.html#instructions",
    "href": "labs/lab1.html#instructions",
    "title": "Lab 1: Fundamentals of Data",
    "section": "Instructions",
    "text": "Instructions\n\nAs a group discuss questions you would like to ask your classmates as part of a survey. (Please consider questions you would be comfortable answering).\n\nYou should have at least four questions, such that your final dataset will have at least one nominal categorical variable, one ordinal categorical variable, one discrete numeric variable, and one continuous numeric variable.\nThink about whether you will restrict survey-takers to particular responses.\n\nGive each of your questions a variable name. Variable names should be concise but descriptive and contain no spaces. You can use underscores for separating words (e.g. shirt_color)\nCreate a Google Form for collecting survey responses. When you are done, share the link to a Preview of the form in the random channel in Slack.\nData Collection:\n\n\nGroup 1: Respond to Groups 2 and 3\nGroup 2: Respond to Groups 3 and 4\nGroup 3: Respond to Groups 4 and 1\nGroup 4: Respond to Groups 1 and 2\n\n\nBack in your original groups, open the spreadsheet of survey responses. Discuss how a rectangular dataset was created from the individual survey responses.\nBe prepared to share your dataset with the class, characterizing 1) What is the unit of observation? 2) What are the variables/what types of variables are they?\nWe will discuss as a class how each dataset could be transformed into aggregate data."
  },
  {
    "objectID": "labs/lab-tableau.html",
    "href": "labs/lab-tableau.html",
    "title": "Tableau Workshop",
    "section": "",
    "text": "Today, you are going to work through a series of exercises to get you acquainted with the visualization features in Tableau. You are going to produce a series of worksheets in Tableau that showcase the intersections of poverty and race/ethnicity in the United States, using the 2021 American Community Census Supplemental Poverty Measure public use research extracts. We will be working this dataset throughout the semester as we learn to plot, analyze, and map various kinds of data. Throughout this exercise and the semester, we will refer to the Supplemental Poverty Measure as SPM.\nThe primary goal of this exercise is not to memorize a series of Tableau features and workflows. We are going to cover a lot of ground today, and I do not expect you to remember everything. The primary goal is twofold - first, to give you a sense of the expansiveness of Tableau’s capabilities, and second, to give you practice problem-solving in Tableau by following reference material. In most sections of this exercise, I’m not going to explain to you exactly how to complete the step …but I am going to give you the resources that you need to figure it out. This is really important skill-building for this course and for data analysis in general."
  },
  {
    "objectID": "labs/lab-tableau.html#the-dataset",
    "href": "labs/lab-tableau.html#the-dataset",
    "title": "Tableau Workshop",
    "section": "The Dataset",
    "text": "The Dataset\nThere are multiple standards that the U.S. federal government uses to assess poverty. The first and most common measure - the official poverty measure (OPM) - has been in use since the 1960s. This measure defines poverty by analyzing a family’s pre-tax income to a certain poverty threshold and adjusting for the size of the family. While this measure has a long history, many stakeholders were concerned that it paints an inadequate picture of poverty. With the support of the U.S. Bureau of Labor Statistics, the SPM was introduced in 2011 to factor in a number of other vectors that mark poverty - access to government programs like food stamps, federal and state taxes, work expenses, food expenses, and geographic location.\nThe data that you will see today documents poverty in the U.S according to both measures. It was collected via the U.S. Census Bureau’s Current Population Survey Annual Social and Economic Supplements (CPS ASEC). Each row in the dataset is one surveyed person in a U.S. household, and there are columns to mark the person’s demographics (age, race, ethnicity, gender, marital status), the person’s poverty status, the person’s income and expenses, and the person’s access to various government subsidies. The CPS is directed to the U.S. civilian noninstitutional population, and thus excludes incarcerated individuals, individuals in nursing homes, and the homeless population.\nIt’s important to note that this is not a survey of every person in the U.S. There are a number of reasons why it would be difficult to survey everyone in the U.S - it’s expensive, it takes a lot of time, not everyone wants to be surveyed, among other reasons. Instead, a subset of the total population (or, in other words, a sample of households) are surveyed. …but there are reasons why this sample might not be representative of the whole U.S. even if respondents were selected randomly. Certain communities may be under-surveyed if they live in areas that are difficult to reach, if they tend to refuse participation, or if they are more likely to be unavailable for surveying. Sometimes, when we look at the demographics of those that actually participated in a survey, the distributions of age, race, gender, etc do not match those of the US. To account for this, the CPS assigns weights to each survey response. The weight represents the theoretical number of people that a survey response represents within the total population. So if one survey response was assigned a weight of 144, this indicates that the survey collectors estimate that this survey response represents about 144 people in the total population.\nThis is a really important concept, so if you had trouble following the paragraph above, check out this video for further explanation:"
  },
  {
    "objectID": "labs/lab-tableau.html#getting-started",
    "href": "labs/lab-tableau.html#getting-started",
    "title": "Tableau Workshop",
    "section": "Getting Started",
    "text": "Getting Started\nOpen Tableau and create a New Workbook called spm_poverty_2021. Click the Connect to Data in the upper left hand corner of Tableau. Download this data file and load it into Tableau, using the Statistical File link on the Connect page. It may take a few moments to load. Open the data dictionary for this dataset here, and make sure you have it available to you throughout these exercises. Read through the data dictionary to acquaint yourself with the variables that might appear in this dataset.\n\n\n\n\n\n\nTip\n\n\n\nIn the data dictionary, you may notice that beneath field names, there are a list of numbers followed by a series of labels. For example, consider this section:\n\nUnder the SEX heading, the dictionary is indicating that whenever you see a 1 in the dataset under the SEX variable, it refers to Male, and whenever you see a 2 in the dataset under the SEX variable, it refers to a Female.\n\n\nCreate a new Sheet in your Tableau Workbook called ‘Poverty Counts - Official Poverty Measure’. Rename the worksheet tab at the bottom of the screen to some abbreviated version of this. (I called mine Off-Pov)."
  },
  {
    "objectID": "labs/lab-tableau.html#understanding-pill-types",
    "href": "labs/lab-tableau.html#understanding-pill-types",
    "title": "Tableau Workshop",
    "section": "Understanding Pill Types",
    "text": "Understanding Pill Types\nVariables are treated differently in Tableau depending on whether they are assumed to be Dimensions or Measures, and whether they are treated as Discrete or Continuous. Pill types impact what kinds of calculations we can perform, what kinds of plots we can create, and what kinds of formulas we can write.\nWatch this video, which explains pill types further.\nThere are a number of categorical variables in this dataset that are incorrectly coded as Measures. This is because the dataset uses numbers as labels for the categorical variables (e.g. 1 refers to Male in the SEX variable). When Tableau imported our dataset, it defaulted to treating these variables as measures because it saw a series of numbers in the columns. …but we won’t ever add, average, or perform any other numerical calculations with the numbers in these columns because they are actually labels for categorical information, not measures.\n\nQuestion\n\nBased on what you learned in the last video, convert the following categorical variables in the dataset to Dimensions : Education, Hispanic, Mar, OFF Poor, Puma, Race, Sex, SPM Poor, SPM Ten MortStatus, SPM wCohabit, SPM wUI LT15, ST."
  },
  {
    "objectID": "labs/lab-tableau.html#managing-metadata",
    "href": "labs/lab-tableau.html#managing-metadata",
    "title": "Tableau Workshop",
    "section": "Managing Metadata",
    "text": "Managing Metadata\nThere are a whole lot of variables for us to parse through in this dataset, and it would be helpful if we had some way of further organizing them.\nWatch this video, which explains how to manage metadata in Tableau.\n\nQuestion\n\nCreate the following folders in your Worksheet:\n\nIDs\nDemographics\nGeography\nHousing Status\nHousehold Properties\nIncome\nExpenses\nFinancial Resources\n\nOrganize as many of the variables into these folders as you can."
  },
  {
    "objectID": "labs/lab-tableau.html#aliases",
    "href": "labs/lab-tableau.html#aliases",
    "title": "Tableau Workshop",
    "section": "Aliases",
    "text": "Aliases\nGo ahead and drag the OFF Poor variable onto the Rows field. You’ll notice a table appears, with 0 and 1 listed in the first column and empty text in the next column.\nYou’ll remember that you can look up the values corresponding to 0 and 1 in the OFF Poor variable in the Data Dictionary. To make compelling data visualizations, we likely want to swap out these numbers with their actual labels in the visualization. To do this, we can hover over the number 0 in the visualization, right click, and then click ‘Edit Alias’.\n\nThen you can type the label name in the field that appears. This label will appear in place of 0 whenever you use this variable again.\n\nQuestion\n\nEdit the Aliases for both of the values in OFF Poor according to the labels from the Data Dictionary."
  },
  {
    "objectID": "labs/lab-tableau.html#working-with-special-pill-types",
    "href": "labs/lab-tableau.html#working-with-special-pill-types",
    "title": "Tableau Workshop",
    "section": "Working with Special Pill Types",
    "text": "Working with Special Pill Types\nLet’s say that we wanted to know the count of individuals in this dataset that were considered to be in poverty according to the OFF Poor variable. To do so, we want to count how many times 1 appeared in the dataset in this column, along with how many times 0 appeared in the dataset in this column. There is a special pill in the Measures section of Tableau that facilitates this. It’s the file name of your dataset followed by the word (Count).\n\nWith OFF Poor still in the Rows field of your worksheet, drag spm_pu_2021.sas7bdat (Count) to the Label field. You’ll see a table that looks like this.\n\nThis indicates to us how many survey respondents in this dataset were classified as in poverty according to the official poverty measure. …but recall from above that this dataset is a sample not a total count of every person in the U.S. and that certain categories of people might be more represented than others. Certain communities may have been over-surveyed, and others might have been under-surveyed. Zooming out to the entire U.S., we can’t assume that this is a representative ratio of individuals in poverty. To address this, we will need to factor in the survey weights.\nDrag the Wt pill to the Label field. Remember that the Wt field represents how many people in the population that the survey respondent represents. If Wt is 144 for one row in the dataset, it is assumed that there are 144 people in the U.S. that are represented by this survey response. This also means that the response will count more than a survey response that was assigned a weight of 80.\nBy default, Tableau sums this number, giving us an estimate of the total population classified as in poverty according to this measure. The table is difficult to read though, right? We can guess, but there are no labels that indicate which number is associated with the survey count vs. which number is associated with the weighted sum.\nWatch this video, which explains how to have different measures appear side-by-side in a plot.\n\nQuestion\n\nBased on the video, see if you can adjust the table we’ve been creating in these steps to look like this:\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can Edit Alias of the column names in your table to match my column names above.\n\n\n\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “Poverty Counts - Supplemental Poverty Measure”. Rename the worksheet tab to match this title. Repeat the steps above to create a table that shows both the survey counts and weighted sum for the SPM Poor indicator. With which definition of poverty is the weighted sum greater? Any guesses as to why?\n\n\n\n\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “SPM Poverty By Race” and rename the worksheet tab to something similar. Drag the Race variable to the Rows field, the SPM Poor variable to the Columns field, and the Wt variable to the label field. Ensure that the Wt field is being aggregated with SUM. Edit the aliases to display the correct Race labels from the data dictionary."
  },
  {
    "objectID": "labs/lab-tableau.html#table-calculations",
    "href": "labs/lab-tableau.html#table-calculations",
    "title": "Tableau Workshop",
    "section": "Table Calculations",
    "text": "Table Calculations\nWhen producing tables like this, we are often not just concerned with the total number of people in poverty in different social groups, but the percentage of people in poverty across different social groups. To adjust our tables to show this, we are going to use the Table Calculation features in Tableau.\nWatch this video, which explains how to create table calculations and this video, which explains how to modify table calculations.\n\nQuestion\n\nUsing the Quick Table Calculation feature, convert the sum in your “SPM Poverty By Race” table to percentages. Experiment with adjusting the value selected in “Compute Using…” What are the differences between the following three tables?\n   Which table would I use if I wanted to know which racial group has the highest percentage of individuals in poverty? Set “Compute Using…” accordingly."
  },
  {
    "objectID": "labs/lab-tableau.html#sorting",
    "href": "labs/lab-tableau.html#sorting",
    "title": "Tableau Workshop",
    "section": "Sorting",
    "text": "Sorting\nOften times, it can help us interpret tables and visualizations when rows, bars, etc. are ordered from largest to smallest. There are number of ways to re-sort your data visualizations in Tableau.\nWatch this video on sorting in Tableau.\n\nQuestion\n\nSort the “SPM Poverty By Race” table that you just created such that the racial group with the highest percentage of individuals in poverty appears at the top, and the group with the lowest percentage of individuals in poverty appears at the bottom."
  },
  {
    "objectID": "labs/lab-tableau.html#reformatting-to-do-no-harm",
    "href": "labs/lab-tableau.html#reformatting-to-do-no-harm",
    "title": "Tableau Workshop",
    "section": "Reformatting to Do No Harm",
    "text": "Reformatting to Do No Harm\nThis week you read examples of “data harm” curated by the Data Justice Lab. As we start designing tables and visualizations in Tableau, it is important to think about how we can minimize harm in our data design practices.\nWatch this video, which details 10 “do no harm” recommendations from the Urban Institute.\nFollowing this, watch this video which details some formatting features in Tableau.\n\nQuestion\n\nIn the top right hand corner of the “SPM Poverty By Race” worksheet, click Show Me and select the icon with horizontal bars to convert the table that you just created to a bar chart.\n Right click “Not in Poverty” in your table and select “Hide”.\n Using some of the formatting features that you just learned, identify and apply at least two techniques to minimize harm in the plot. You can also use skills that you learned earlier in this workshop.\n\n\n\nQuestion\n\nCreate a new Worksheet called “SPM Poverty by Hispanic”, and rename the worksheet tab to something similar. Recreate “SPM Poverty by Race” but with the Hispanic variable."
  },
  {
    "objectID": "labs/lab-tableau.html#submission",
    "href": "labs/lab-tableau.html#submission",
    "title": "Tableau Workshop",
    "section": "Submission",
    "text": "Submission\nCreate a New Dashboard in your workbook, and drag all four of your worksheets onto it in any order. Be sure to revisit checkpoint 1 if you can’t remember how to create a dashboard. In the top menu bar, click on Dashboard > Export Image, and then save an image of your dashboard as a .png file. Upload the image to Moodle under the Tableau Workshop assignment."
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Lab 2: Data Semiotics",
    "section": "",
    "text": "Definitions are operating in the background of every statistic. When I report the number or percentage of people that play sports, I have to first define what counts as a sport and what it means for someone to be a sports player (i.e. how often they play? how long they’ve been playing?) When I report the number or percentage of green spaces in a city, I have to first define what counts as a green space.\nWe often don’t take the time to critically examine definitions. We’re pretty used to seeing definitions reported in dictionaries or reference documents - documents that we don’t tend to classify as persuasive, rhetorical, or political. …but in fact, definitions are often a site of intense social and political debate. What counts as a life in the context of abortion politics? What counts as a terrorist in the context of domestic security? These terms may have formal definitions in laws and/or dictionaries, but those definitions are rarely stable and are continuously subject to contestation. They create boundaries of inclusion/exclusion, while necessarily leaving certain issues unaddressed.\nIn today’s activity, you are going to analyze the definitions a dataset denotatively, connotatively, and deconstructively:\n\nDenotatively, we are going to reference data documentation to examine the official/encoded definitions underpinning a dataset. You are going to reflect upon how these definitions set the boundaries of what counts.\nConnotatively, we are going to examine the provenance of that definition. When has the definition changed? Who or what prompted the definition to change, and with what social consequences? How did the numbers change as a result?\nDeconstructively, we are going to consider what the definition eclipses. What social groups or social issues get overshadowed as a result of this definition?\nWe’re also going to look at the categorizations of a dataset to determine which individuals may be categorically excluded, and which groups of people are rendered residual through the data."
  },
  {
    "objectID": "labs/lab2.html#instructions",
    "href": "labs/lab2.html#instructions",
    "title": "Lab 2: Data Semiotics",
    "section": "Instructions",
    "text": "Instructions\nLast week, you worked with a dataset that offered two different definitions of poverty - the official poverty measure, and the supplemental poverty measure.\n\nPart 1: Denotative Reading\nIn your group find documentation of the official differences between these two definitions. Fill out the following table based on what you learn:\n\n\n\n\n\n\n\n\n\nOfficial Poverty Measure\nSupplemental Poverty Measure\n\n\n\n\nIn Poverty\n\n\n\n\nNot In Poverty\n\n\n\n\n\n\n\nPart 2: Connotative Reading\nIn 2019, the U.S. Office of Management and Budgeting's Chief Statistician established an Interagency Technical Working Group on Evaluating Alternative Measures of Poverty. It had been almost 25 years since the establishment of the Supplemental Poverty Measure and 50 years since the establishment of the Official Poverty Measure. The goal of the working group was to address growing concerns about the quality of survey-based data (e.g. the accuracy of what individuals report in surveys). The Committee came up with a number of ideas on how an alternative measure of poverty might be determined. The video following summarizes some of the recommendations they came up with. (We will watch just a few clips in class).\n\n\nRegulations.gov is a website where the public can review and comment upon proposed changes to federal agency regulations. On February 14, 2020, a “Request for Comment on Considerations for Additional Measures of Poverty” was posted on Regulations.gov. 193 comments were submitted in response to the recommendation.\nIn your groups, click through a number of these public comments. Take notes on the following for each:\n\nWho is making the comment, and what stakeholder group are they a part of?\nWhat stakes do they have in the way poverty gets defined?\nWhere do they stand in relation to these recommendations?\nHow do they justify their stance?\n\nAs a group, we will compare your findings in order to consider the role of social advocacy in shaping the definitions underpinning this data. We will also consider stakeholder groups that might not be represented on Regulations.gov.\n\n\nPart 3: Deconstructive Reading\nCreate a hypothetical “profiles” for two individuals that this dataset eclipses. Try and bring these individuals to life, telling us about them. Why is it that those individuals go uncounted? Indicate specific consequences that may result from be uncounted. Also indicate some benefits to uncounted in this data.\n\n\nPart 4: Analyzing Categories\nWhen working with this dataset last week, you may have been surprised regarding how race and ethnicity were subdivided in the dataset. Demographic categories used in most federal government data collection programs in the U.S. are standardized by the Office of Management and Budget. These standards were last revised in 1997, but proposals to change them were made in 2016 and generated a great deal of public commentary on Regulations.gov.\nIn your groups, check out this site, which documents how racial categorization has changed in the census since 1790. Note what surprises you the most.\nAfter this, check out what was proposed in 2016 regarding standards for collecting data on race and ethnicity, and read through some of the public comments. What were some rationales for changing the standards, and what were some rationales for maintaining the current standards? What social groups had stakes in these decisions, and how did they advocate?"
  },
  {
    "objectID": "labs/lab2.html#other-contested-data-defitions",
    "href": "labs/lab2.html#other-contested-data-defitions",
    "title": "Lab 2: Data Semiotics",
    "section": "Other contested data defitions:",
    "text": "Other contested data defitions:\n\nUnemployment\n\n\n\n\nHurricane Deaths\n\n\n\n\nDisability\n\n\n\n\nHomelessness"
  },
  {
    "objectID": "checkpoints/checkpoint1.html#other-helpful-tableau-resources",
    "href": "checkpoints/checkpoint1.html#other-helpful-tableau-resources",
    "title": "Checkpoint 1: Tableau Basics",
    "section": "Other Helpful Tableau Resources",
    "text": "Other Helpful Tableau Resources\nTableau Workspace\nTableau Starter Kit\nWhich Chart or Graph is Right for You?"
  },
  {
    "objectID": "labs/lab2.html#other-contested-data-definitions",
    "href": "labs/lab2.html#other-contested-data-definitions",
    "title": "Lab 2: Data Semiotics",
    "section": "Other contested data definitions:",
    "text": "Other contested data definitions:\n\nUnemployment\n\n\n\n\nHurricane Deaths\n\n\n\n\nDisability\n\n\n\n\nHomelessness"
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Lab 3: Health Equity",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding racial inequities in maternal mortality rates in the United States. Specifically, you will practice producing both uni-variate and multi-variate column plots and line plots from aggregate data in Tableau."
  },
  {
    "objectID": "labs/lab3.html#the-dataset",
    "href": "labs/lab3.html#the-dataset",
    "title": "Lab 3: Health Equity",
    "section": "The Dataset",
    "text": "The Dataset\nThrough the National Vital Statistics System, the US National Center for Health Statistics aggregates data about population health (including births, deaths, and pregnancies) from states in order to guide public health policy and decision-making. The Center for Disease Control makes this data available to the public through a series of public use files, along with an online data query interface called WONDER (Wide-ranging OnLine Data for Epidemiologic Research). Navigating to the WONDER interface, an analyst can access and download US mortality and population data, spanning the years from 1999 to 2019, aggregated at national, state, and county levels. With the data gathered from US death certificates, which report an individuals’ underlying cause of death according to the Tenth Revision of the International Classification of Diseases, the death counts can be disaggregated into hundreds of different causes of death. The death counts can also be disaggregated by a series of demographic variables, including gender, age, race, and Hispanic ethnicity.\nBy adjusting the query parameters on the WONDER request form to indicate how the CDC’s data should be aggregated and filtered, data analysts can produce a series of different rectangular datasets. For example, an analyst can opt to group the results by Year and Race and filter the Cause of Death to ICD-10 codes O00-O99 (Pregnancy, childbirth and the puerperium) to produce a dataset that tracks the death counts and crude death rate due to pregnancy-related causes for different racial demographics in the US from 1999 to 2021. Alternatively, an analyst could opt to group the results by State and Cause of Death and filter the data to 2021 to determine the leading causes of death in each state in that year."
  },
  {
    "objectID": "labs/lab3.html#instructions",
    "href": "labs/lab3.html#instructions",
    "title": "Lab 3: Health Equity",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: What counts in this dataset?\nNavigate the data documentation here in order to determine when and how a “death” is counted in this dataset.\n\n\nPart 2: Explore the WONDER Interface\nFor timing purposes, I’m going to link the datasets that you need for today’s Tableau exercises here. However, I will take some time during class to walk you through the different components of the interface.\n\n\nPart 3: Cleaning Data Files\nDownload the following files to your computer:\n\nrace_pregnancy_2020.txt\nyear_pregnancy.txt\nrace_age_pregnancy_2020.txt\nrace_year_pregnancy.txt\n\nOpen Tableau, and create a new workbook called cdc_maternal_deaths. Click “Connect to Data” and the race_age_pregnancy_2020.txt file.\nYou’re going to notice when you import the file that the table needs some cleaning.\n\nFirst, there is a column at the start of each table labeled “Notes.” If you scroll down, you will eventually see a series of notes that we need to consider when analyzing the data:\n\n\n\n\n\n\nWarning\n\n\n\nDataset: Underlying Cause of Death, 1999-2020\nQuery Parameters:\nTitle: race_age_pregnancy_2020\nICD-10 Codes: O00-O99 (Pregnancy, childbirth and the puerperium)\nYear/Month: 2020\nGroup By: Race; Ten-Year Age Groups\nShow Totals: Disabled\nShow Zero Values: True\nShow Suppressed: True\nCalculate Rates Per: 100,000\nRate Options: Default intercensal populations for years 2001-2009 (except Infant Age Groups)\nHelp: See http://wonder.cdc.gov/wonder/help/ucd.html for more information.\nQuery Date: Sep 1, 2023 5:41:50 PM\nSuggested Citation: Centers for Disease Control and Prevention, National Center for Health Statistics. National Vital Statistics System, Mortality 1999-2020 on CDC WONDER Online Database, released in 2021. Data are from the Multiple Cause of Death Files, 1999-2020, as compiled from data provided by the 57 vital statistics jurisdictions through the Vital Statistics Cooperative Program. Accessed at http://wonder.cdc.gov/ucd-icd10.html on Sep 1, 2023 5:41:50 PM\nMessages:\n\nTotals are not available for these results due to suppression constraints. More Information: http://wonder.cdc.gov/wonder/help/faq.html#Privacy.\n\nCaveats:\n\nData are Suppressed when the data meet the criteria for confidentiality constraints. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Assurance of Confidentiality.\nDeath rates are flagged as Unreliable when the rate is calculated with a numerator of 20 or less. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Unreliable.\nDeaths of persons with Age Not Stated are included in All counts and rates, but are not distributed among age groups, so are not included in age-specific counts, age-specific rates or in any age-adjusted rates. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Not Stated.\nInformation included on the death certificate about the race and Hispanic ethnicity of the decedent is reported by the funeral director as provided by an informant, often the surviving next of kin, or, in the absence of an informant, on the basis of observation. Race and ethnicity information from the census is by self-report. To the extent that race and Hispanic origin are inconsistent between these two data sources, death rates will be biased. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Racial Differences.\nThe population figures for year 2020 are bridged-race estimates of the July 1 resident population, from the Vintage 2020 postcensal series released by NCHS on September 22, 2021. The population figures for year 2019 are bridged-race estimates of the July 1 resident population, from the Vintage 2019 postcensal series released by NCHS on July 9, 2020. The population figures for year 2018 are bridged-race estimates of the July 1 resident population, from the Vintage 2018 postcensal series released by NCHS on June 25, 2019. The population figures for year 2017 are bridged-race estimates of the July 1 resident population, from the Vintage 2017 postcensal series released by NCHS on June 27, 2018. The population figures for year 2016 are bridged-race estimates of the July 1 resident population, from the Vintage 2016 postcensal series released by NCHS on June 26, 2017. The population figures for year 2015 are bridged-race estimates of the July 1 resident population, from the Vintage 2015 postcensal series released by NCHS on June 28, 2016. The population figures for year 2014 are bridged-race estimates of the July 1 resident population, from the Vintage 2014 postcensal series released by NCHS on June 30, 2015. The population figures for year 2013 are bridged-race estimates of the July 1 resident population, from the Vintage 2013 postcensal series released by NCHS on June 26, 2014. The population figures for year 2012 are bridged-race estimates of the July 1 resident population, from the Vintage 2012 postcensal series released by NCHS on June 13, 2013. The population figures for year 2011 are bridged-race estimates of the July 1 resident population, from the Vintage 2011 postcensal series released by NCHS on July 18, 2012. Population figures for 2010 are April 1 Census counts. The population figures for years 2001 - 2009 are bridged-race estimates of the July 1 resident population, from the revised intercensal county-level 2000 - 2009 series released by NCHS on October 26, 2012. Population figures for 2000 are April 1 Census counts. Population figures for 1999 are from the 1990-1999 intercensal series of July 1 estimates. Population figures for the infant age groups are the number of live births. Note: Rates and population figures for years 2001 - 2009 differ slightly from previously published reports, due to use of the population estimates which were available at the time of release.\nThe population figures used in the calculation of death rates for the age group ‘under 1 year’ are the estimates of the resident population that is under one year of age. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Age Group.\nBeginning with the 2018 data, changes have been implemented that affect the counts for ICD-10 cause of death codes O00-O99 compared to previous practice. In addition, data for the cause of death codes O00-O99 for 2003 through 2017 reflect differences in information available to individual states and probable errors. Caution should be used in interpreting these data. More information can be found at: https://www.cdc.gov/nchs/maternal-mortality/.\n\n\n\nThis is all important information and we should keep it in mind as we go about our analysis. …but this is metadata, not data for analysis. or the purposes of our data analysis, we are going to Hide that column.\n\nQuestion\n\nClick on the downward triangle on the Notes column and select Hide.\n\n\nNow that we have hidden that column, there are a series of empty rows at the bottom of our dataset. We are going to filter those out.\n\n\nQuestion\n\nClick on the “Add” link next to Filters in the top right corner of Tableau. Click Add, and select Race - a variable that shouldn’t have any missing values in this dataset. Click OK, and then check all boxes, except for “Null” to filter out the null values.\n\n\nYou will also notice that both the Deaths column and the Crude Rate column were assumed to contain text data, even though those columns are supposed to report numeric quantities. This is because, in certain subsets, the CDC “Suppressed” the data or determined it to be “Unreliable”. Any time fewer than 10 deaths would be reported in a subset of data, the CDC suppressed the death count to protect the privacy of the individuals in that subset. This means that the more specific you make your data request, the more likely it will be that data gets suppressed (because fewer people will be represented in each subset). Any time fewer than 20 deaths are reported, the crude rate is considered to be “Unreliable.” While this is helpful information for us, in order to plot the data, we need those columns to both be numeric.\n\n\nQuestion\n\nClick on the number ‘Abc’ symbol in both the Deaths column and the Crude Rate column and convert the columns to numeric. Make sure you select the Crude Rate column is displayed in decimals.\n\n\nWe need to repeat this for the remainder of files we will use in the lab. However one of the files has some special formatting issues.\n\n\nQuestion\n\nIn the top menu, click Data > New Data Source. Add either year_pregnancy.txt or race_year_pregnancy.txt.\nRepeat the formatting steps for the file you choose, and then repeat this process for the two other text files.\nWhen you get to race_pregnancy_2020.txt, we need to take one additional step. Tableau does not recognize the delimiters in this file. Add the file to see what I mean. See how the table looks quite off?\n To fix this, click on the downward arrow next to the file name in your data view, and then select “Text File Properties”. Set the Field Separator to “Tab”.\n After that you should be able to edit the file the same way you did the rest of them.\n\nFinally, we are ready to do some analysis!\n\n\n\nPart 4: Data Analysis\n\nColumn Plots\nColumn plots are particularly useful for comparing the numeric values associated with different categories. They typically involve a categorical variable on the x-axis and a numeric variable on the y-axis. We can make sense of how categories differ by comparing the heights of each bar. In column plots, height serves as a visual aesthetic - some feature of a plot that communicates something about the values in our data.\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality, 2020”. Name the tab “race_2020”. Click on race_pregnancy_2020 in the “Data” tab. Drag Race to the Rows field and Crude Rate to the Columns field. Sort the bars from longest to shortest.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nKeep in mind that all of this data has already been aggregated. We do not need to sum, average, or perform any other operation on the reported values because both the Deaths value and the Crude Rate are calculated for a specific subset of people. They are Attributes not Measures. By default, Tableau will SUM the measure when you drag it onto your worksheet. You can keep it this way as long as you are sure that values represented on the plot are specific to one row of data (meaning there’s nothing being aggregated in the worksheet).\n\n\n\n\n\nQuestion\n\nDuplicate the last plot that you created, and rename the tab “race_2020_tree”. Click on the “Show Me” button and select the treemap. Adjust the title of the legend to “Crude Rate”.\n\n\n\nNote how, in this new plot, we are no longer using height to visualize differences across categories. Instead, we are using both area and color to visualize the differences. Area and color are also visual aesthetics.\nNotably, we are visualizing both area and color in a continuous way. Larger boxes are associated with larger values, and smaller boxes are associated with smaller values. Color is displayed on a gradient with darker colors associated with larger values and lighter colors associated with smaller values. The area size is specific to a numeric value, and the shade of color is specific to a numeric value. Indeed, it makes sense to use a color gradient when visualizing numeric data.\nThis differs from visualizing color in a discrete way.\n\n\n\nQuestion\n\nDuplicate the last plot that you created, and rename the tab “race_2020_tree_cat”. Drag Race to the Color field.\n\n\n\nNote how in this plot, colors are not displayed on a gradient. Instead, there are discrete colors associated with each race. This is because we differentiating color along a categorical variable, where there are discrete divisions between categories. In general, we want to use discrete color palettes when associating color with a categorical variable and continuous color palettes when associated color with a numeric variable.\nWhich of the plots that we just created do you find the most compelling and why?\n\n\n\n\nStacked Column Plots\nIn the last series of plots, we were only visualizing one categorical variable. …but sometimes, we want to compare numeric values across some intersection of categorical variables. In this case, we will create a stacked column plot, using both height and color as visual aesthetics.\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality, 2020”. Name the tab “race_2020_age”. Click on race_age_pregnancy_2020 in the “Data” tab. Drag Ten-Year Age Groups to the Columns field and Crude Rate to the Rows field. Drag Race to the Color field. Note how a discrete color palette is created.\nClick on the “Show Me” button, and select the side-by-side bars. I personally prefer this type of plot over a stacked bar plot because I find it easier to compare across categories when the bars are side-by-side. Move around the order of the variables to make the most compelling plot. Add a Filter to only show the relevant age groups.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nLine Plots\nLine plots are particularly useful for showing change over time. They typically involve a date on the x-axis and a numeric variable on the y-axis. The height of each point tells us something about the time period represented.\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality - 1999-2020”. Name the tab “by_year”. Click on year_pregnancy in the “Data” tab. Drag Year to the Columns field and Crude Rate to the Rows field.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\nSometimes we want to compare the changes across different groups over time. To do so, we can use color to differentiate lines across different groups.\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality - 1999-2020”. Name the tab “by_year_race”. Click on year_race_pregnancy in the “Data” tab. Drag Year to the Columns field and Crude Rate to the Rows field. Convert Crude Rate to an attribute. Drag Race to the Color field.\n\nWhat kind of color palette was created here?\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\nPart 5: Reflection\nHow might we summarize what we just learned into a factual claim?\nNote that this data is often cited as evidence of racial disparities in healthcare. The CDC website includes a webpage titled “Working Together to Reduce Black Maternal Mortality,” and cites this data as evidence of racial disparities. Here are just a few examples of other articles that also do so:\n\nRacial Disparities in Maternal and Infant Health: Current Status and Efforts to Address Them\nAmerican Black women face disproportionately high rates of maternal mortality\nRacial Disparities in Maternal Health\nWhy Racial Gaps In Maternal Mortality Persist\nVisualizing the stark maternal health inequities in the United States\n\nIn my research, I came across one article that countered these claims in spite of the data evidence. “A Woke Panic on Maternal Mortality” argues that activists and academics have exploited the data to push a narrative of systemic racism in healthcare. In small groups, read through this article and try to identify the arguments that the authors use to counter the claims often made from the data. How would you respond to their counter-arguments? What evidence could you provide in your response?"
  },
  {
    "objectID": "labs/lab4.html",
    "href": "labs/lab4.html",
    "title": "Lab 4: Policing Justice",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding discriminatory policing practices in New York City in the early 2011 - the height of stop and frisk. Specifically, you will learn how to create various bar plots that aggregate individual level data by various categories. You will also practice creating table calculations, combining variables, and pivoting variables."
  },
  {
    "objectID": "labs/lab4.html#the-dataset",
    "href": "labs/lab4.html#the-dataset",
    "title": "Lab 4: Policing Justice",
    "section": "The Dataset",
    "text": "The Dataset\nEvery time an NYPD officer stops an individual based on “reasonable suspicion” that they committed or were about to commit a crime, the officer is required to fill out a form documenting information about the stop, including the reason for the stop, the demographics of the individual stopped, any actions taken during the stop, and any contraband found on the individual stopped. These reports get aggregated into a database that became available for public download in 2008 as a result of considerable advocacy efforts by the New York Civil Liberties Union in the wake of high-profile police shootings.\nIn the 1990s, crime reduction strategies implemented in major cities across the country demanded the production of statistics to generate evidence of policing effectiveness. With certain consequences tied to failures to demonstrate reductions in crime, the policies institutionally incentivized data manipulation - an issue colloquially referred to as “juking the stats.” Despite these data quality issues, the publication of the data in 2008 showed an incredible increase in the number of police stops over a 5-year period, and by 2011, the number of stops had increased 700% from when data collection began in 2002. 88% of the time the individuals stopped were found innocent. In the following years, the data became integral in the New York District Court case Floyd, et al. v. City of New York, et al., which ultimately ruled that stop and frisk was being carried out unconstitutionally in New York City and led to a considerable scaling back of the practice. The New York Civil Liberties Union continues to publish annual reports leveraging the data to assess the current state of discriminatory policing in NYC.\nToday, we are going to analyze 2011 stop and frisk data."
  },
  {
    "objectID": "labs/lab4.html#instructions",
    "href": "labs/lab4.html#instructions",
    "title": "Lab 4: Policing Justice",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: Explore the data dictionary\nDownload the data dictionary here. After downloading the zip file, open the Excel file for the 2011 SQF File Spec. Check out both tabs of the spreadsheet: the first defines variables in the dataset, and the second lists the values that might appear in those variables. Note how each variable maps onto a field on the UF-250 form.\n\n\nImage from Dan Nguyen: http://blog.danwin.com/request-nypd-form-uf250/\n\n\n\nPart 2: Download the 2011 SQF Data\nDownload the 2011 SQF Data here.\n\n\nPart 3: Data Analysis\nOpen Tableau, and create a new workbook called sqf_2011. Click “Connect to Data” and the 2011.csv file. Note that this is the largest dataset we will work with this semester, and it may take time to load in Tableau.\nIn the last lab, we created a series of column plots. In that lab, we supplied a categorical variable for one axis and a numeric variable to set the height of the bar to on another axis. In that lab, we could do so because we were working with data that had already been aggregated. Each row wasn’t a death; it was a count of deaths for a particular demographic group or year.\nIn this lab, we don’t have numeric variables to set the height of the bar to. This is because we have unaggregated individual data; each row represents one stop. In this case, we want to do the aggregating. If each row represents one stop, we want to count the number rows (or stops) along a number of different categories.\nTo do so, we are going to create bar plots. With bar plots, we don’t supply the height of the bar. Instead, the height of the bar gets set to a count of each observation in a category.\n\nQuestion\n\nCreate a new worksheet called “NYPD Stops per Race, 2011”. Name the tab “by_race”.\nDrag the Race pill to Rows. Edit the aliases based on the values in the data dictionary. After this, drag the 2011.csv (Count) pill to Columns. Recall from a previous lab that this variable is a count of the all rows in the dataset. Since each row in this dataset is one stop, using this variable counts the numbers of stops per category.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Arrest or Summons per Race, 2011”. Name the tab “per_guilty”.\nDrag the Race pill to Rows. After this, drag the 2011.csv (Count) pill to Columns.\nNow we need to drag over a variable that indicates whether the individual was found guilty. …but there are actually two variables for this: Arstmade and Sumissue, and each have possible values of ‘Y’ or ‘N’. We want to combine this into one variable that return ‘Y’ if either Arstmade and Sumissue are ‘Y’ and ‘N’ otherwise. Highlight both Arstmade and Sumissue with the Cmd/Cntl key, and then click on one pill > Create > Combined Field.\nClick on the newly created Combined Field > Create Group. Change the name of the field to “Guilty”, add a group for the “N,N” value called “No”, and change the name of the remaining group to “Yes”.\n\nDrag Guilty onto the Rows field behind Race.\n\n\n\nThis tells us the total number of stops that resulted in an arrest or summons per race, but since we know that certain races are disproportionately stopped, we really want to see the percentage of stops that result in an arrest or summons per race.\nTo do this, we are going to add a Table Calculation to these plots such that each bar displays a “Percent of Total”. Adding this calculation does not change anything about the underlying data; it only changes how the data gets displayed.\n\n\n\nQuestion\n\nClick on 2011.csv (Count) in the Column field > Table Calculation > Percent of Total. Note that, since we are displaying a few different values on this plot, there are a number of different values that can serve as a denominator for the calculated percentage. We want to know the percentage deemed guilty out of all stops, so we are going to click on 2011.csv (Count) again > Compute Using > Guilty.\nFinally, right click on “No” in the plot, and then select “Hide”. Note that this locally filters the data, keeping the original data source the same.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the last exercise, we created a local filter on the data. When applying local filters, the data remains the same in the original Data Source, but we hide certain variables from view in our visualizations. This is different from applying a global filter. With a global filter, we filter the original Data Source such that only a subset of rows get considered in our analysis/visualizations.\nWhy does this difference matter? It mostly matters when we create table calculations on our data that include a denominator (e.g. Percent of Total). If we apply a global filter to such data, the denominator changes - it becomes only the data remaining after the original data source is filtered. …but if we apply a local filter to such data, the denominator remains the same because the original data source doesn’t change. The only thing that changes is our view of that data.\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Frisk per Race, 2011”. Name the tab “per_frisked”.\nRepeat the steps above to create a bar plot that shows the percentage of stops that resulted in a frisk per race. Note that you do not have to create a grouped variable this time around because you have all of the information you need about frisks in the variable Frisked.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Frisks Resulting in a Weapon Found per Race, 2011”. Name the tab “per_wpn”. Drag Frisked to the filters panel, and filter to ‘Y’ so that we are only considering stops that resulted in a frisk. Note, unlike the local filters we applied to the earlier plots by hiding certain values, this is a global filter that filters the original data source.\nRepeat the steps above to create a bar plot that shows the percentage of frisks that resulted in a weapon found per race. Note that you do have to create a grouped variable this time around as there is no existing variable for “Weapon found”. You will need to combine the variables: Pistol, Riflshot, Asltweap, Knifcuti, Machgun, Othrweap such that if any are ‘Y’ the data returns ‘Y’ and otherwise the data returns ‘N’.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Most Stops, 2011”. Name the tab “top_5_pct”. Convert Pct from a Measure to a Dimension. Drag Pct to Rows and 2011.csv (Count) columns. Drag Pct to Filters and select ‘Top’. Configure the filter to display the top 5 according to 2011.csv Count.\n\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Highest Percentage of Frisks, 2011”. Name the tab “pct_frisks”. Based on what you’ve learned, create a bar plot that shows the percentage of stops that resulted in a frisk for each precinct.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nNow let’s say that we want to analyze the documented reasons for a stop. Officers are required to have reasonable suspicion that a crime was committed, so maybe we want to analyze what their reasons for stopping were. You’ll notice that there isn’t one variable that documents the reason for the stop. This is because on that section of the UF-250 form (entitled “What Were Circumstances that Led to Stop?”), the officer is presented with series of checkboxes. The officer can select multiple boxes. Each option is its own variable in this dataset with a ‘Y’ or ‘N’ option.\nWe can’t just drag all of these variables onto the plot because Tableau will combine every ‘Y’/‘N’ option across all variables.\n\nInstead, we want to pivot these variables such that the field names will become one variable, and the values associated with them ‘Y’/‘N’ will become another variable.\n\nCreate a new worksheet called “NYPD Reason for Stops, 2011”. Name the tab “stop_reason”. Using the Cmd/Cntl button select all variables starting with Cs ... Right click on the select pills > Transform > Pivot.\nDrag Pivot Field Names onto the Rows field and 2011.csv (Count) onto the Columns field. Convert the counts to a percent of total, computed using the Pivot Field Values. Locally filter ‘N’ from the plot, using “Hide”.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful. Edit the aliases to the values under the “What Were Circumstances that Led to Stop?” on the UF-250 form.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\nPart 5: Reflection\nHow might we summarize what we just learned into a factual claim? How does the data respond to the “bad apples” narrative? What other data or analysis strategies could be engaged to respond to these counter-claims?\nNote that this data is often cited as evidence of racial profiling in policing. …but some also counter that stop and frisk policies led to the greatest reduction of crime rates in NYC’s history. They reframe racial profiling as proactive policing. Here’s one article that makes such a counter-claim.\nIn small groups, read through this article and try to identify the arguments that the author uses to counter the claims regarding racial profiling. How would you respond to their counter-arguments? What evidence could you provide in your response?"
  },
  {
    "objectID": "labs/lab6.html",
    "href": "labs/lab6.html",
    "title": "Lab 6: Housing Justice",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding lending practices in Chicago, IL. Through today’s exercises, you will be introduced to polygon mapping in Tableau, along with strategies for creatively filtering data."
  },
  {
    "objectID": "labs/lab6.html#the-dataset",
    "href": "labs/lab6.html#the-dataset",
    "title": "Lab 6: Housing Justice",
    "section": "The Dataset",
    "text": "The Dataset\n\n\nIn order to ensure that financial institutions are in compliance with fair lending laws in the U.S. (such as the Equal Credit Opportunity Act and the Fair Housing Act), lenders are required to collect and report data on an applicant’s ethnicity, race, gender, and income when they apply for a mortgage. With the passing of the Home Mortgage Disclosure Act (HMDA) in 1975, financial institutions were at first required to report demographic information about applicants, aggregated by census tracts. The reporting of this data was largely prompted by concerns that banks were contributing to the decline of certain urban neighborhoods by denying qualified borrowers loans, as well as concerns that financial institutions were engaging in discriminatory lending practices and contributing to the redlining of neighborhoods. Growing concerns about individual-level discrimination in lending prompted the passing of the Financial Institutions Reform, Recovery, and Enforcement Act (FIRREA) of 1989, which required institutions to report demographic data (or what they call “government monitoring information”) for every applicant regardless of whether the loan was approved or denied.\nToday, we’re going to analyze 2018 HMDA representing Cook County, Illinois. We’re also going to work a bit with historic redlining maps of Chicago, published by the University of Richmond’s Digital Scholarship Lab.\nRobert K. Nelson, LaDale Winling, Richard Marciano, Nathan Connolly, et al., “Mapping Inequality,” American Panorama, ed. Robert K. Nelson and Edward L. Ayers, accessed September 3, 2023, https://dsl.richmond.edu/panorama/redlining/"
  },
  {
    "objectID": "labs/lab6.html#instructions",
    "href": "labs/lab6.html#instructions",
    "title": "Lab 6: Housing Justice",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: What’s in this dataset?\nNote that every row in the HMDA dataset is one loan application. Navigate the data documentation here in order to see what gets reported in this dataset. Jot down terms that you are unfamiliar with. We will discuss them as a class.\n\n\nPart 2: Explore the Mapping Inequality website\nExplore historic redlining maps of Chicago (published by the University of Richmond’s Digital Scholarship Lab) by navigating here. Click on different neighborhoods on the map. What do the different colors on the map mean? What were some of the reasons different neighborhoods received different ratings?\n\n\nPart 3: Download the datasets\nToday, both of the datasets that we are going to be working contain polygon geometry. What do I mean by this? Check out the map below.\n\nCC BY-SA 4.0, Link\n\nNotice how every state is a polygon? Similarly, the datasets we will be using today are designed to allow us to map polygons of different neighborhoods and census tracts in Chicago.\n\nDownload Chicago’s Historic Redlining Maps by clicking here.\nDownload 2018 HMDA data from Cook County by clicking here\n\n\n\nPart 3: Analyzing the data\nOpen Tableau, and create a new workbook called hmda_chicago. Click “Connect to Data” and the ILChicago1940.zip file as a Spatial File. In the top menu, click Data > New Data Source. Add hmda_chic_2018.geojson as a Spatial File.\nNote that to save time, I’ve already cleaned this data for you. Specifically, I swapped out all of the numeric codes in the dataset with their qualitative labels. I’ve also added geometries of the census tracts associated with each row. However, there is one data type that we will need to fix before we open our first worksheet.\n\nIn the Data Source tab, scroll to the column Combined Loan to Value Ratio and convert it to a Number (Decimal).\n\n\nQuestion\n\nCreate a worksheet in Tableau called “HOLC Maps of Chicago, IL - 1940”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Chicago. Now drag the HOLC Grade to the Color field. Edit the map colors such that A is green, B is blue, C is yellow, and D is red. Finally, add the HOLC ID to the Detail field.\nWhat do you notice about the geographies of segregation across the city?\n\n\n\nThe map that you just created used a qualitative color palette, filling polygons according to the values in a categorical variable.\nWe can also color polygons according to a numeric variable by mapping the values in that variable to a shade of a color along a gradient. When we do so, we create what are called chloropleth maps.\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Minority Population Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Cook County. Drag the Census Tract pill to the Detail field in order to identify each census tract mapped. Now drag Tract Minority Population Percentage onto the Color field.\nNote that each row in this dataset is a loan application, not a census tract. In 2018, there were many loan applications submitted in each tract. Because I’m mapping census tracts, by default, Tableau takes the sum of Tract Minority Population Percentage across every loan application in each tract. This doesn’t make sense, right? …because the value for Tract Minority Population Percentage is specific to the tract not the loan. Every loan application in that tract is going to have the same value listed in Tract Minority Population Percentage. I don’t need to sum across all applications; I just want to show the value for that tract. To do that, I’m going to convert SUM(Tract Minority Population Percentage) to an attribute by clicking on its pill in the Color field. Rename the legend title to something descriptive.\nWhat do you notice about the geographies of minority populations across the city?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “MSA Income Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above but using the Tract to Msa Income Percentage pill.\nWhat do you notice about the geographies of income inequality across the city?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Amounts of Loans Originated per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above but using the Loan Amount pill. This time, leave the aggregation as a SUM, since we want a total of the loans originated in each census tract. Finally, drag the Action Taken pill to the filter panel, and filter the plot to only include loans that were originated.\nWhat do you notice about the geographies of loan resources originated across the city?\n\n\n\nWhen we dragged Action Taken to the filters panel, we created a global filter on the data. This means that we filtered the original Data Source such that only originated loans would be considered in our analysis/visualizations. Recall that this is different from creating a local filter on data. When applying local filters, the data remains the same in the original Data Source, but we hide certain variables from view in our visualizations.\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Denial Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Cook County. Drag the Census Tract pill to the Detail field in order to identify each census tract mapped. Now drag hmda_chic_2018.geojson (Count) onto the Color field. This creates a map indicating how many loan applications were submitted in each census tract in Cook County, IL.\nWe are specifically interested in where applications were denied. Drag the Action Taken pill onto the Rows field. Note how this creates 8 rows of maps - one for each action listed in that variable. Right click on each Action listed on the Tableau canvas except for “Application denied” and click “Hide”. Note that this is a local filter, not a global filter. It filters the data on our screen, but not the data source.\nRight now we have a map that shows us the total number of applications denied in each tract. …but we can’t tell if a tract having numerous denials is a result of a high denial rate or just more applications being submitted in the tract. What if we would like to see denials as a percentage of the all the applications submitted in each tract? Click on the hmda_chic_2018.geojson (Count) pill you mapped onto the Color field, and add a Quick Table Calculation > Percent of Total. We’re trying to see the percentage of denials out of all possible actions taken, so you’ll want to click on the pill again and select “Compute Using…” > Action Taken.\nWhat do you notice about the geographies of denial rates across the city?\n\n\n\nTaken together, what story can you tell about legacies of segregation in Chicago? What additional data would you need to fill in gaps in those stories?\nThese maps provide us with information about lending practices on a census tract level, but what if I wanted to examine potential discriminatory lending practices on an individual level?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Actions by Race, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Action Taken field onto the Rows field, followed by the Derived Race field. Drag the hmda_chic_2018.geojson (Count) field onto the Columns field. Convert the count to a percentage of total, such that the percentage we see is a percentage of a specific action out of all possible actions (i.e. denial rate, origination rate, etc. )\nWhat do you notice about the differences in denial rates and origination rates across racial groups?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Actions by Ethnicity, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above, but for Derived Ethnicity.\nWhat do you notice about the differences in denial rates and origination rates across ethnic groups?\n\n\n\nBanking organizations across the U.S. have countered claims that this data indicates discriminatory lending practices. They note that just looking at denial rates across race and ethnicity fails to take into consideration legitimate reasons for denial - low incomes, high debt, poor credit histories. They argue that it is not bias to reject a loan for these reasons, even if it means rejecting individuals in certain racial and ethnic groups more than others. We know income and debt to be unequally distributed along racial and ethnic lines due to histories of structural inequality. The redlining maps we recreated at the start of this lab are just one form of structural inequality that reshaped racial wealth in the 1900s. …but for a moment, for rhetorical purposes, let’s set this knowledge aside. Assuming that loan originators are just trying to play by the rules, we could assume that two individuals - one white and one black - with similar incomes, and similar debt would see similar outcomes when applying for a similar loan in the same year. Let’s test that out in our data.\n\n\n\nQuestion\n\nOn the worksheet called “Loan Application Actions by Ethnicity, Cook County, IL, 2018”, add filters for Income, Debt to Income Ratio, Combined Loan to Value Ratio. Click on each of these filters in the Filters Panel, and select “Show Filter” in order to show an interactive filter on the worksheet. Finally, drag Denial Reason 1 to the Tooltip field.\nFilter the data such that applications with similar loan to value ratios from individuals with similar incomes and similar debt-to-income ratios appear in the plot.\nWhat changes in regards to denial rates across ethnic groups do you notice?\nAs you filter, click on the bars in the graph to view the underlying full data.\n\n\nHow did the denial reasons differ across racial and ethnic groups?\nClick on each of your interactive filters and select Apply to Worksheets > Selected Worksheets. Add each filter to “Loan Application Actions by Race, Cook County, IL, 2018”. Experiment with the filters on this second worksheet and review the underlying data.\nWhat changes in regards to denial rates across racial groups do you notice?\n\n\n\n\nPart 5: Reflection\nNote that this data does not include the credit scores of applicants, so we can’t assess the role of credit history in decision-making. How might we summarize what we just learned into a factual claim? For one, we can see that historically red-lined neighborhoods in Chicago continue to be segregated and continue to have higher loan denial rates. We can also see that financial resources tend to be concentrated in areas of the city that have historically been prioritized for mortgage lending. Further, we can see that, even when factoring in income, debt, and loan amounts, denial rates are unevenly distributed across racial and ethnic groups in Chicago. Can we go so far as to claim that this data provides evidence of discriminatory lending? If not, what further data would we need to assess this? …and how should we respond to arguments from the lending industry that this data cannot show discrimination?"
  },
  {
    "objectID": "labs/lab4.html#the-counter-claim",
    "href": "labs/lab4.html#the-counter-claim",
    "title": "Lab 4: Policing Justice",
    "section": "The Counter-Claim",
    "text": "The Counter-Claim\nA common response to evidence of racial profiling in policing is that misconduct can be isolated to a few “bad apples.” The idea is that the problem is not with biased policies or problematic cultures of policing, but instead with a few rogue individuals not following protocol. With this framing, solutions to policing injustices tend to be focused on reforms such as mandatory implicit bias training and punishments for individual bad actors. Solutions rarely focus on reimagining the structures and policies that underlie policing as an institution.\nRefuting the “bad apples” narrative requires that we produce evidence of structural inequities that extend beyond examples of individual police encounters. Overall, this lab will demonstrate what we can see in the aggregate that we can’t necessarily see at an individual level."
  },
  {
    "objectID": "labs/poverty.html",
    "href": "labs/poverty.html",
    "title": "Intersections of Poverty",
    "section": "",
    "text": "Today and next week, you are going to work through a series of exercises to get you acquainted with the visualization features in Tableau. You are going to produce a series of worksheets in Tableau that showcase the intersections of poverty and race/ethnicity/gender in the United States, using the 2021 American Community Census Supplemental Poverty Measure public use research extracts. Throughout this exercise, we will refer to the Supplemental Poverty Measure as SPM.\nThe primary goal of this exercise is not to memorize a series of Tableau features and workflows. We are going to cover a lot of ground today, and I do not expect you to remember everything. The primary goal is twofold - first, to give you a sense of the expansiveness of Tableau’s capabilities, and second, to give you practice problem-solving in Tableau by following reference material. In most sections of this exercise, I’m not going to explain to you exactly how to complete the step …but I am going to give you the resources that you need to figure it out. This is really important skill-building for this course and for data analysis in general."
  },
  {
    "objectID": "labs/poverty.html#the-counter-claim",
    "href": "labs/poverty.html#the-counter-claim",
    "title": "Intersections of Poverty",
    "section": "The Counter-Claim",
    "text": "The Counter-Claim\nA common response to campaigns and policies focused on anti-racism and anti-sexism is this: “I believe everyone should be treated equally.” The suggestion is that everyone should have access to the same exact resources and opportunities. The problem with this rhetoric is that it ignores that different people start from different positions. We’ve learned this week that focusing on equity over equality ensures that everyone can achieve the same outcomes because resources and opportunities are directed to communities based on where they are at. As we consider equity-based approaches, it’s important to also recognize that disadvantages can be amplified at the intersections of certain social identities.\nRefuting claims that prioritize equality over equity requires highlighting the disadvantages that groups at the intersection of certain social identities face. Overall, this lab will demonstrate what we can see when we compare data across the intersections of race, ethnicity, class, and gender that we can’t see when examining data along a single axis."
  },
  {
    "objectID": "labs/poverty.html#the-dataset",
    "href": "labs/poverty.html#the-dataset",
    "title": "Intersections of Poverty",
    "section": "The Dataset",
    "text": "The Dataset\nThere are multiple standards that the U.S. federal government uses to assess poverty. The first and most common measure - the official poverty measure (OPM) - has been in use since the 1960s. This measure defines poverty by analyzing a family’s pre-tax income to a certain poverty threshold and adjusting for the size of the family. While this measure has a long history, many stakeholders were concerned that it paints an inadequate picture of poverty. With the support of the U.S. Bureau of Labor Statistics, the SPM was introduced in 2011 to factor in a number of other vectors that mark poverty - access to government programs like food stamps, federal and state taxes, work expenses, food expenses, and geographic location.\nThe data that you will see in this lab documents poverty in the U.S according to both measures. It was collected via the U.S. Census Bureau’s Current Population Survey Annual Social and Economic Supplements (CPS ASEC). Each row in the dataset is one surveyed person in a U.S. household, and there are columns to mark the person’s demographics (age, race, ethnicity, gender, marital status), the person’s poverty status, their household’s income and expenses, and the household’s access to various government subsidies. The CPS is directed to the U.S. civilian noninstitutional population, and thus excludes incarcerated individuals, individuals in nursing homes, and the homeless population.\nIt’s important to note that this is not a survey of every person in the U.S. There are a number of reasons why it would be difficult to survey everyone in the U.S - it’s expensive, it takes a lot of time, not everyone wants to be surveyed, among other reasons. Instead, a subset of the total population (or, in other words, a sample of households) are surveyed. …but there are reasons why this sample might not be representative of the whole U.S. even if respondents were selected randomly. Certain communities may be under-surveyed if they live in areas that are difficult to reach, if they tend to refuse participation, or if they are more likely to be unavailable for surveying. Sometimes, when we look at the demographics of those that actually participated in a survey, the distributions of age, race, gender, etc do not match those of the US. To account for this, the CPS assigns weights to each survey response. The weight represents the theoretical number of people that a survey response represents within the total population. So if one survey response was assigned a weight of 144, this indicates that the survey collectors estimate that this survey response represents about 144 people in the total population.\nThis is a really important concept, so if you had trouble following the paragraph above, check out this video for further explanation:"
  },
  {
    "objectID": "labs/poverty.html#instructions",
    "href": "labs/poverty.html#instructions",
    "title": "Intersections of Poverty",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: Getting Started\nOpen Tableau and create a New Workbook called spm_poverty_2021. Click the Connect to Data in the upper left hand corner of Tableau. Download this data file and load it into Tableau, using the Statistical File link on the Connect page. It may take a few moments to load. Open the data dictionary for this dataset here, and make sure you have it available to you throughout these exercises. Read through the data dictionary to acquaint yourself with the variables that might appear in this dataset.\n\n\n\n\n\n\nTip\n\n\n\nIn the data dictionary, you may notice that beneath field names, there are a list of numbers followed by a series of labels. For example, consider this section:\n\nUnder the SEX heading, the dictionary is indicating that whenever you see a 1 in the dataset under the SEX variable, it refers to Male, and whenever you see a 2 in the dataset under the SEX variable, it refers to a Female.\n\n\nCreate a new Sheet in your Tableau Workbook called ‘Poverty Counts - Official Poverty Measure’. Rename the worksheet tab at the bottom of the screen to some abbreviated version of this. (I called mine Off-Pov).\n\nUnderstanding Pill Types\nVariables are treated differently in Tableau depending on whether they are assumed to be Dimensions or Measures, and whether they are treated as Discrete or Continuous. Pill types impact what kinds of calculations we can perform, what kinds of plots we can create, and what kinds of formulas we can write.\nWatch this video, which explains pill types further.\nThere are a number of categorical variables in this dataset that are incorrectly coded as Measures. This is because the dataset uses numbers as labels for the categorical variables (e.g. 1 refers to Male in the SEX variable). When Tableau imported our dataset, it defaulted to treating these variables as measures because it saw a series of numbers in the columns. …but we won’t ever add, average, or perform any other numerical calculations with the numbers in these columns because they are actually labels for categorical information, not measures.\n\nQuestion\n\nBased on what you learned in the last video, convert the following categorical variables in the dataset to Dimensions : Education, Hispanic, Mar, OFF Poor, Puma, Race, Sex, SPM Poor, SPM Ten MortStatus, SPM wCohabit, SPM wUI LT15, ST.\n\n\n\n\n\n\n\nManaging Metadata\nThere are a whole lot of variables for us to parse through in this dataset, and it would be helpful if we had some way of further organizing them.\nWatch this video, which explains how to manage metadata in Tableau.\n\nQuestion\n\nCreate the following folders in your Worksheet:\n\nIDs\nDemographics\nGeography\nHousing Status\nHousehold Properties\nIncome\nExpenses\nFinancial Resources\n\nOrganize as many of the variables into these folders as you can.\n\n\n\n\nAliases\nGo ahead and drag the OFF Poor variable onto the Rows field. You’ll notice a table appears, with 0 and 1 listed in the first column and empty text in the next column.\nYou’ll remember that you can look up the values corresponding to 0 and 1 in the OFF Poor variable in the Data Dictionary. To make compelling data visualizations, we likely want to swap out these numbers with their actual labels in the visualization. To do this, we can hover over the number 0 in the visualization, right click, and then click ‘Edit Alias’.\n\nThen you can type the label name in the field that appears. This label will appear in place of 0 whenever you use this variable again.\n\nQuestion\n\nEdit the Aliases for both of the values in OFF Poor according to the labels from the Data Dictionary.\n\n\n\n\n\nPart 2: Data Analysis\n\nWorking with Special Pill Types\nLet’s say that we wanted to know the count of individuals in this dataset that were considered to be in poverty according to the OFF Poor variable. To do so, we want to count how many times 1 appeared in the dataset in this column, along with how many times 0 appeared in the dataset in this column. There is a special pill in the Measures section of Tableau that facilitates this. It’s the file name of your dataset followed by the word (Count).\n\nWith OFF Poor still in the Rows field of your worksheet, drag spm_pu_2021.sas7bdat (Count) to the Label field. You’ll see a table that looks like this.\n\nThis indicates to us how many survey respondents in this dataset were classified as in poverty according to the official poverty measure. …but recall from above that this dataset is a sample not a total count of every person in the U.S. and that certain categories of people might be more represented than others. Certain communities may have been over-surveyed, and others might have been under-surveyed. Zooming out to the entire U.S., we can’t assume that this is a representative ratio of individuals in poverty. To address this, we will need to factor in the survey weights.\nDrag the Wt pill to the Label field. Remember that the Wt field represents how many people in the population that the survey respondent represents. If Wt is 144 for one row in the dataset, it is assumed that there are 144 people in the U.S. that are represented by this survey response. This also means that the response will count more than a survey response that was assigned a weight of 80.\nBy default, Tableau sums this number, giving us an estimate of the total population classified as in poverty according to this measure. The table is difficult to read though, right? We can guess, but there are no labels that indicate which number is associated with the survey count vs. which number is associated with the weighted sum.\nWatch this video, which explains how to have different measures appear side-by-side in a plot.\n\nQuestion\n\nBased on the video, see if you can adjust the table we’ve been creating in these steps to look like this:\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can Edit Alias of the column names in your table to match my column names above.\n\n\n\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “Poverty Counts - Supplemental Poverty Measure”. Rename the worksheet tab to something similar. Repeat the steps above to create a table that shows both the survey counts and weighted sum for the SPM Poor indicator. With which definition of poverty is the weighted sum greater? Any guesses as to why?\n\n\n\n\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “SPM Poverty By Race” and rename the worksheet tab to something similar. Drag the Race variable to the Rows field, the SPM Poor variable to the Columns field, and the Wt variable to the label field. Ensure that the Wt field is being aggregated with SUM. Edit the aliases to display the correct Race labels from the data dictionary.\n\n\n\n\n\nTable Calculations\nWhen producing tables like this, we are often not just concerned with the total number of people in poverty in different social groups, but the percentage of people in poverty across different social groups. To adjust our tables to show this, we are going to use the Table Calculation features in Tableau.\nWatch this video, which explains how to create table calculations and this video, which explains how to modify table calculations.\n\nQuestion\n\nUsing the Quick Table Calculation feature, convert the sum in your “SPM Poverty By Race” table to percentages. Experiment with adjusting the value selected in “Compute Using…” What are the differences between the following three tables?\n   Which table would I use if I wanted to know which racial group has the highest percentage of individuals in poverty? Set “Compute Using…” accordingly.\n\n\n\n\nSorting\nOften times, it can help us interpret tables and visualizations when rows, bars, etc. are ordered from largest to smallest. There are number of ways to re-sort your data visualizations in Tableau.\nWatch this video on sorting in Tableau.\n\nQuestion\n\nSort the “SPM Poverty By Race” table that you just created such that the racial group with the highest percentage of individuals in poverty appears at the top, and the group with the lowest percentage of individuals in poverty appears at the bottom.\n\n\n\n\nPart 3: Reformatting to Do No Harm\nThis week you read examples of “data harm” curated by the Data Justice Lab. As we start designing tables and visualizations in Tableau, it is important to think about how we can minimize harm in our data design practices.\nWatch this video, which details 10 “do no harm” recommendations from the Urban Institute.\nFollowing this, watch this video which details some formatting features in Tableau.\n\nQuestion\n\nIn the top right hand corner of the “SPM Poverty By Race” worksheet, click Show Me and select the icon with horizontal bars to convert the table that you just created to a bar chart.\n Right click “Not in Poverty” in your table and select “Hide”.\n Using some of the formatting features that you just learned, identify and apply at least two techniques to minimize harm in the plot. You can also use skills that you learned earlier in this workshop.\n\n\n\nQuestion\n\nCreate a new Worksheet called “SPM Poverty by Hispanic”, and rename the worksheet tab to something similar. Recreate “SPM Poverty by Race” but with the Hispanic variable."
  },
  {
    "objectID": "labs/poverty.html#first-half-submission",
    "href": "labs/poverty.html#first-half-submission",
    "title": "Intersections of Poverty",
    "section": "First Half Submission",
    "text": "First Half Submission\nCreate a New Dashboard in your workbook, and drag all four of your worksheets onto it in any order. Be sure to revisit checkpoint 1 if you can’t remember how to create a dashboard. In the top menu bar, click on Dashboard > Export Image, and then save an image of your dashboard as a .png file. Upload the image to Moodle under the Tableau Workshop assignment.\n\n\nPart 4: Data Analysis Continued\nLast week, we examined poverty status along single-axes of identity: race and ethnicity. In part 2, we are going to examine poverty status along multiple-axes of identity in order to demonstrate how individuals with overlapping minority identities can face heightened disadvantages.\nIn the following steps, we are going to be determining the average income and average access to government subsidies across different social groups. To do so, we are going to have to take into consideration the survey weights. We’re going to create a calculated field that calculates a weighted average of income. Calculated fields are variables that we create with customized formulas.\n\nQuestion\n\nCreate a new Worksheet called “Average Income for Single Adult (Age 18-65) Households with Children, 2021”, and rename the worksheet tab to income_race_sex.\nIn the Data side panel, click on the downward black arrow > Create Calculated Field.\n Name the field Weighted Totalval, and then enter the following formula into the text box:\nSUM([Wt] * [SPM Totval]) / SUM([Wt])\nAs a class, we will talk through what this formula does. Click OK.\n\n\n\nQuestion\n\nDrag Age onto the Filters panel. Select “All Values,” and set the bounds to 18-65. Drag the SPM NumAdults to the Filters panel, and set the bounds to 1. Drag the SPM NumKids to the Filters panel, and set the bounds to at least 1.\nDrag Race and Sex onto the Columns field, and drag Color onto the Color field. Drag Education and Weighted Totalval onto the Rows field.\nEdit the Aliases for Sex and Education. Adjust the plot labels to something descriptive.\nWhat do you notice about average income at the intersections of different racial and gender groups for single adult households with children?\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote how when we dragged Weighted Totalval onto the Rows field, the Measure was wrapped in the letters Agg(). This is Tableau’s way of communicating that this data has already been aggregated via the calculation we created. In other words, when we created the calculated field, we determined the weighted average across all the individual values for Totalval in the dataset; we aggregated the data across those values. By wrapping the Measure in Agg(), Tableau is telling us that it is not aggregating the values in the shelf and instead relying on the aggregated values calculated in the field.\n\n\n\n\n\nQuestion\n\nDuplicate the previous tab and rename it income_ethnicity_sex. Swap Race with Ethnicity.\nWhat do you notice about average income at the intersections of different ethnic and gender groups for single adult households with children?\n\n\n\nQuestion\n\nCreate a new calculated field called Subsidies. Set this field as follows:\n[SPM EngVal] + [SPM CapHouseSub] + [SPM SchLunch] + [SPM SnapSub] + [SPM WICval]\nDuplicate the the Weighted Totalval calculated field. Rename the duplicated field to Weighted Subsidies, and set the field as follows:\nSUM([Wt] * [Subsidies]) / SUM([Wt])\n\n\n\nQuestion\n\nDuplicate the income_race_sex tab and rename it “Average Subsidies for Single Adult (Age 18-65) Households with Children, 2021” Also rename the tab. Swap Weighted Totalval with Weighted Subsidies.\nRepeat these steps for the income_etc_sex tab.\nWhat do you notice about average subsidies at the intersections of different ethnic and gender groups for single adult households with children?\n\n\n\n\nPart 5: Reflection\nHow might we summarize what we just learned into a factual claim? What does this data contribute to narratives that prioritize equality over equity? What do we learn by taking an intersectional approach to data analysis that we can’t see otherwise?"
  },
  {
    "objectID": "labs/healthcare.html",
    "href": "labs/healthcare.html",
    "title": "Health Equity",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding racial inequities in maternal mortality rates in the United States. Specifically, you will practice producing both uni-variate and multi-variate column plots and line plots from aggregate data in Tableau."
  },
  {
    "objectID": "labs/healthcare.html#the-counter-claim",
    "href": "labs/healthcare.html#the-counter-claim",
    "title": "Health Equity",
    "section": "The Counter-Claim",
    "text": "The Counter-Claim\nIn a “A Woke Panic on Maternal Mortality” Stanley Goldfarb and Benita Cotton-Orr argue that activists and academics have exploited statistics on maternal mortality rates to push a narrative of systemic racism in healthcare. They argue that the data are insufficient for proving discrimination (due to both error-prone reporting and a small sample size) and that “radical activists” and “woke ideologues” are pushing race-based healthcare policies based on ideology and not on science. Their arguments reflect a narrative that efforts to examine disparities are “witch hunts.”\nRefuting the “witch hunt” narrative requires showing that disparities are not coincidental one-off events but are persistent over time and across place. Overall, this lab will demonstrate what we can see when we historicize and geographically situate statistics that we can’t see when only looking at a snapshot of data."
  },
  {
    "objectID": "labs/healthcare.html#the-dataset",
    "href": "labs/healthcare.html#the-dataset",
    "title": "Health Equity",
    "section": "The Dataset",
    "text": "The Dataset\nThrough the National Vital Statistics System, the US National Center for Health Statistics aggregates data about population health (including births, deaths, and pregnancies) from states in order to guide public health policy and decision-making. The Center for Disease Control makes this data available to the public through a series of public use files, along with an online data query interface called WONDER (Wide-ranging OnLine Data for Epidemiologic Research). Navigating to the WONDER interface, an analyst can access and download US mortality and population data, spanning the years from 1999 to 2019, aggregated at national, state, and county levels. With the data gathered from US death certificates, which report an individuals’ underlying cause of death according to the Tenth Revision of the International Classification of Diseases, the death counts can be disaggregated into hundreds of different causes of death. The death counts can also be disaggregated by a series of demographic variables, including gender, age, race, and Hispanic ethnicity.\nBy adjusting the query parameters on the WONDER request form to indicate how the CDC’s data should be aggregated and filtered, data analysts can produce a series of different rectangular datasets. For example, an analyst can opt to group the results by Year and Race and filter the Cause of Death to ICD-10 codes O00-O99 (Pregnancy, childbirth and the puerperium) to produce a dataset that tracks the death counts and crude death rate due to pregnancy-related causes for different racial demographics in the US from 1999 to 2021. Alternatively, an analyst could opt to group the results by State and Cause of Death and filter the data to 2021 to determine the leading causes of death in each state in that year."
  },
  {
    "objectID": "labs/healthcare.html#instructions",
    "href": "labs/healthcare.html#instructions",
    "title": "Health Equity",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: What counts in this dataset?\nNavigate the data documentation here in order to determine when and how a “death” is counted in this dataset.\n\n\nPart 2: Explore the WONDER Interface\nFor timing purposes, I’m going to link the datasets that you need for today’s Tableau exercises here. However, I will take some time during class to walk you through the different components of the interface.\n\n\nPart 3: Cleaning Data Files\nDownload the following files to your computer:\n\nrace_pregnancy_2020.txt\nyear_pregnancy.txt\nrace_age_pregnancy_2020.txt\nrace_year_pregnancy.txt\n\nOpen Tableau, and create a new workbook called cdc_maternal_deaths. Click “Connect to Data” and the race_age_pregnancy_2020.txt file.\nYou’re going to notice when you import the file that the table needs some cleaning.\n\nFirst, there is a column at the start of each table labeled “Notes.” If you scroll down, you will eventually see a series of notes that we need to consider when analyzing the data:\n\n\n\n\n\n\nWarning\n\n\n\nDataset: Underlying Cause of Death, 1999-2020\nQuery Parameters:\nTitle: race_age_pregnancy_2020\nICD-10 Codes: O00-O99 (Pregnancy, childbirth and the puerperium)\nYear/Month: 2020\nGroup By: Race; Ten-Year Age Groups\nShow Totals: Disabled\nShow Zero Values: True\nShow Suppressed: True\nCalculate Rates Per: 100,000\nRate Options: Default intercensal populations for years 2001-2009 (except Infant Age Groups)\nHelp: See http://wonder.cdc.gov/wonder/help/ucd.html for more information.\nQuery Date: Sep 1, 2023 5:41:50 PM\nSuggested Citation: Centers for Disease Control and Prevention, National Center for Health Statistics. National Vital Statistics System, Mortality 1999-2020 on CDC WONDER Online Database, released in 2021. Data are from the Multiple Cause of Death Files, 1999-2020, as compiled from data provided by the 57 vital statistics jurisdictions through the Vital Statistics Cooperative Program. Accessed at http://wonder.cdc.gov/ucd-icd10.html on Sep 1, 2023 5:41:50 PM\nMessages:\n\nTotals are not available for these results due to suppression constraints. More Information: http://wonder.cdc.gov/wonder/help/faq.html#Privacy.\n\nCaveats:\n\nData are Suppressed when the data meet the criteria for confidentiality constraints. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Assurance of Confidentiality.\nDeath rates are flagged as Unreliable when the rate is calculated with a numerator of 20 or less. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Unreliable.\nDeaths of persons with Age Not Stated are included in All counts and rates, but are not distributed among age groups, so are not included in age-specific counts, age-specific rates or in any age-adjusted rates. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Not Stated.\nInformation included on the death certificate about the race and Hispanic ethnicity of the decedent is reported by the funeral director as provided by an informant, often the surviving next of kin, or, in the absence of an informant, on the basis of observation. Race and ethnicity information from the census is by self-report. To the extent that race and Hispanic origin are inconsistent between these two data sources, death rates will be biased. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Racial Differences.\nThe population figures for year 2020 are bridged-race estimates of the July 1 resident population, from the Vintage 2020 postcensal series released by NCHS on September 22, 2021. The population figures for year 2019 are bridged-race estimates of the July 1 resident population, from the Vintage 2019 postcensal series released by NCHS on July 9, 2020. The population figures for year 2018 are bridged-race estimates of the July 1 resident population, from the Vintage 2018 postcensal series released by NCHS on June 25, 2019. The population figures for year 2017 are bridged-race estimates of the July 1 resident population, from the Vintage 2017 postcensal series released by NCHS on June 27, 2018. The population figures for year 2016 are bridged-race estimates of the July 1 resident population, from the Vintage 2016 postcensal series released by NCHS on June 26, 2017. The population figures for year 2015 are bridged-race estimates of the July 1 resident population, from the Vintage 2015 postcensal series released by NCHS on June 28, 2016. The population figures for year 2014 are bridged-race estimates of the July 1 resident population, from the Vintage 2014 postcensal series released by NCHS on June 30, 2015. The population figures for year 2013 are bridged-race estimates of the July 1 resident population, from the Vintage 2013 postcensal series released by NCHS on June 26, 2014. The population figures for year 2012 are bridged-race estimates of the July 1 resident population, from the Vintage 2012 postcensal series released by NCHS on June 13, 2013. The population figures for year 2011 are bridged-race estimates of the July 1 resident population, from the Vintage 2011 postcensal series released by NCHS on July 18, 2012. Population figures for 2010 are April 1 Census counts. The population figures for years 2001 - 2009 are bridged-race estimates of the July 1 resident population, from the revised intercensal county-level 2000 - 2009 series released by NCHS on October 26, 2012. Population figures for 2000 are April 1 Census counts. Population figures for 1999 are from the 1990-1999 intercensal series of July 1 estimates. Population figures for the infant age groups are the number of live births. Note: Rates and population figures for years 2001 - 2009 differ slightly from previously published reports, due to use of the population estimates which were available at the time of release.\nThe population figures used in the calculation of death rates for the age group ‘under 1 year’ are the estimates of the resident population that is under one year of age. More information: http://wonder.cdc.gov/wonder/help/ucd.html#Age Group.\nBeginning with the 2018 data, changes have been implemented that affect the counts for ICD-10 cause of death codes O00-O99 compared to previous practice. In addition, data for the cause of death codes O00-O99 for 2003 through 2017 reflect differences in information available to individual states and probable errors. Caution should be used in interpreting these data. More information can be found at: https://www.cdc.gov/nchs/maternal-mortality/.\n\n\n\nThis is all important information and we should keep it in mind as we go about our analysis. …but this is metadata, not data for analysis. or the purposes of our data analysis, we are going to Hide that column.\n\nQuestion\n\nClick on the downward triangle on the Notes column and select Hide.\n\n\nNow that we have hidden that column, there are a series of empty rows at the bottom of our dataset. We are going to filter those out.\n\n\nQuestion\n\nClick on the “Add” link next to Filters in the top right corner of Tableau. Click Add, and select Race - a variable that shouldn’t have any missing values in this dataset. Click OK, and then check all boxes, except for “Null” to filter out the null values.\n\n\nYou will also notice that both the Deaths column and the Crude Rate column were assumed to contain text data, even though those columns are supposed to report numeric quantities. This is because, in certain subsets, the CDC “Suppressed” the data or determined it to be “Unreliable”. Any time fewer than 10 deaths would be reported in a subset of data, the CDC suppressed the death count to protect the privacy of the individuals in that subset. This means that the more specific you make your data request, the more likely it will be that data gets suppressed (because fewer people will be represented in each subset). Any time fewer than 20 deaths are reported, the crude rate is considered to be “Unreliable.” While this is helpful information for us, in order to plot the data, we need those columns to both be numeric.\n\n\nQuestion\n\nClick on the number ‘Abc’ symbol in both the Deaths column and the Crude Rate column and convert the columns to numeric. Make sure you select the Crude Rate column is displayed in decimals.\n\n\nWe need to repeat this for the remainder of files we will use in the lab. However one of the files has some special formatting issues.\n\n\nQuestion\n\nIn the top menu, click Data > New Data Source. Add either year_pregnancy.txt or race_year_pregnancy.txt.\nRepeat the formatting steps for the file you choose, and then repeat this process for the two other text files.\nWhen you get to race_pregnancy_2020.txt, we need to take one additional step. Tableau does not recognize the delimiters in this file. Add the file to see what I mean. See how the table looks quite off?\n To fix this, click on the downward arrow next to the file name in your data view, and then select “Text File Properties”. Set the Field Separator to “Tab”.\n After that you should be able to edit the file the same way you did the rest of them.\n\nFinally, we are ready to do some analysis!\n\n\n\nPart 4: Data Analysis\n\nColumn Plots\nColumn plots are particularly useful for comparing the numeric values associated with different categories. They typically involve a categorical variable on the x-axis and a numeric variable on the y-axis. We can make sense of how categories differ by comparing the heights of each bar. In column plots, height serves as a visual aesthetic - some feature of a plot that communicates something about the values in our data.\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality, 2020”. Name the tab “race_2020”. Click on race_pregnancy_2020 in the “Data” tab. Drag Race to the Rows field and Crude Rate to the Columns field. Sort the bars from longest to shortest.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nKeep in mind that all of this data has already been aggregated. We do not need to sum, average, or perform any other operation on the reported values because both the Deaths value and the Crude Rate are calculated for a specific subset of people. They are Attributes not Measures. By default, Tableau will SUM the measure when you drag it onto your worksheet. You can keep it this way as long as you are sure that values represented on the plot are specific to one row of data (meaning there’s nothing being aggregated in the worksheet).\n\n\n\n\n\nQuestion\n\nDuplicate the last plot that you created, and rename the tab “race_2020_tree”. Click on the “Show Me” button and select the treemap. Adjust the title of the legend to “Crude Rate”.\n\n\n\nNote how, in this new plot, we are no longer using height to visualize differences across categories. Instead, we are using both area and color to visualize the differences. Area and color are also visual aesthetics.\nNotably, we are visualizing both area and color in a continuous way. Larger boxes are associated with larger values, and smaller boxes are associated with smaller values. Color is displayed on a gradient with darker colors associated with larger values and lighter colors associated with smaller values. The area size is specific to a numeric value, and the shade of color is specific to a numeric value. Indeed, it makes sense to use a color gradient when visualizing numeric data.\nThis differs from visualizing color in a discrete way.\n\n\n\nQuestion\n\nDuplicate the last plot that you created, and rename the tab “race_2020_tree_cat”. Drag Race to the Color field.\n\n\n\nNote how in this plot, colors are not displayed on a gradient. Instead, there are discrete colors associated with each race. This is because we differentiating color along a categorical variable, where there are discrete divisions between categories. In general, we want to use discrete color palettes when associating color with a categorical variable and continuous color palettes when associated color with a numeric variable.\nWhich of the plots that we just created do you find the most compelling and why?\n\n\n\n\nStacked Column Plots\nIn the last series of plots, we were only visualizing one categorical variable. …but sometimes, we want to compare numeric values across some intersection of categorical variables. In this case, we will create a stacked column plot, using both height and color as visual aesthetics.\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality, 2020”. Name the tab “race_2020_age”. Click on race_age_pregnancy_2020 in the “Data” tab. Drag Ten-Year Age Groups to the Columns field and Crude Rate to the Rows field. Drag Race to the Color field. Note how a discrete color palette is created.\nClick on the “Show Me” button, and select the side-by-side bars. I personally prefer this type of plot over a stacked bar plot because I find it easier to compare across categories when the bars are side-by-side. Move around the order of the variables to make the most compelling plot. Add a Filter to only show the relevant age groups.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nLine Plots\nLine plots are particularly useful for showing change over time. They typically involve a date on the x-axis and a numeric variable on the y-axis. The height of each point tells us something about the time period represented.\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality - 1999-2020”. Name the tab “by_year”. Click on year_pregnancy in the “Data” tab. Drag Year to the Columns field and Crude Rate to the Rows field.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\nSometimes we want to compare the changes across different groups over time. To do so, we can use color to differentiate lines across different groups.\n\n\nQuestion\n\nCreate a new worksheet in Tableau called “U.S. Maternal Mortality - 1999-2020”. Name the tab “by_year_race”. Click on year_race_pregnancy in the “Data” tab. Drag Year to the Columns field and Crude Rate to the Rows field. Convert Crude Rate to an attribute. Drag Race to the Color field.\n\nWhat kind of color palette was created here?\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\nPart 5: Reflection\nNote that this data is often cited as evidence of racial disparities in healthcare. The CDC website includes a webpage titled “Working Together to Reduce Black Maternal Mortality,” and cites this data as evidence of racial disparities. Here are just a few examples of other articles that also do so:\n\nRacial Disparities in Maternal and Infant Health: Current Status and Efforts to Address Them\nAmerican Black women face disproportionately high rates of maternal mortality\nRacial Disparities in Maternal Health\nWhy Racial Gaps In Maternal Mortality Persist\nVisualizing the stark maternal health inequities in the United States\n\nHow might we summarize what we just learned into a factual claim? How does this data respond to the “witch hunt” narrative? What other data or analysis strategies could be engaged to respond to these counter-claims?"
  },
  {
    "objectID": "labs/policing.html",
    "href": "labs/policing.html",
    "title": "Policing Justice",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding discriminatory policing practices in New York City in the early 2011 - the height of stop and frisk. Specifically, you will learn how to create various bar plots that aggregate individual level data by various categories. You will also practice creating table calculations, combining variables, and pivoting variables."
  },
  {
    "objectID": "labs/policing.html#the-counter-claim",
    "href": "labs/policing.html#the-counter-claim",
    "title": "Policing Justice",
    "section": "The Counter-Claim",
    "text": "The Counter-Claim\nA common response to evidence of racial profiling in policing is that misconduct can be isolated to a few “bad apples.” The idea is that the problem is not with biased policies or problematic cultures of policing, but instead with a few rogue individuals not following protocol. With this framing, solutions to policing injustices tend to be focused on reforms such as mandatory implicit bias training and punishments for individual bad actors. Solutions rarely focus on reimagining the structures and policies that underlie policing as an institution.\nRefuting the “bad apples” narrative requires that we produce evidence of structural inequities that extend beyond examples of individual police encounters. Overall, this lab will demonstrate what we can see in the aggregate that we can’t necessarily see at an individual level."
  },
  {
    "objectID": "labs/policing.html#the-dataset",
    "href": "labs/policing.html#the-dataset",
    "title": "Policing Justice",
    "section": "The Dataset",
    "text": "The Dataset\nEvery time an NYPD officer stops an individual based on “reasonable suspicion” that they committed or were about to commit a crime, the officer is required to fill out a form documenting information about the stop, including the reason for the stop, the demographics of the individual stopped, any actions taken during the stop, and any contraband found on the individual stopped. These reports get aggregated into a database that became available for public download in 2008 as a result of considerable advocacy efforts by the New York Civil Liberties Union in the wake of high-profile police shootings.\nIn the 1990s, crime reduction strategies implemented in major cities across the country demanded the production of statistics to generate evidence of policing effectiveness. With certain consequences tied to failures to demonstrate reductions in crime, the policies institutionally incentivized data manipulation - an issue colloquially referred to as “juking the stats.” Despite these data quality issues, the publication of the data in 2008 showed an incredible increase in the number of police stops over a 5-year period, and by 2011, the number of stops had increased 700% from when data collection began in 2002. 88% of the time the individuals stopped were found innocent. In the following years, the data became integral in the New York District Court case Floyd, et al. v. City of New York, et al., which ultimately ruled that stop and frisk was being carried out unconstitutionally in New York City and led to a considerable scaling back of the practice. The New York Civil Liberties Union continues to publish annual reports leveraging the data to assess the current state of discriminatory policing in NYC.\nToday, we are going to analyze 2011 stop and frisk data."
  },
  {
    "objectID": "labs/policing.html#instructions",
    "href": "labs/policing.html#instructions",
    "title": "Policing Justice",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: Explore the data dictionary\nDownload the data dictionary here. After downloading the zip file, open the Excel file for the 2011 SQF File Spec. Check out both tabs of the spreadsheet: the first defines variables in the dataset, and the second lists the values that might appear in those variables. Note how each variable maps onto a field on the UF-250 form.\n\n\nImage from Dan Nguyen: http://blog.danwin.com/request-nypd-form-uf250/\n\n\n\nPart 2: Download the 2011 SQF Data\nDownload the 2011 SQF Data here.\n\n\nPart 3: Data Analysis\nOpen Tableau, and create a new workbook called sqf_2011. Click “Connect to Data” and the 2011.csv file. Note that this is the largest dataset we will work with this semester, and it may take time to load in Tableau.\nIn the last lab, we created a series of column plots. In that lab, we supplied a categorical variable for one axis and a numeric variable to set the height of the bar to on another axis. In that lab, we could do so because we were working with data that had already been aggregated. Each row wasn’t a death; it was a count of deaths for a particular demographic group or year.\nIn this lab, we don’t have numeric variables to set the height of the bar to. This is because we have unaggregated individual data; each row represents one stop. In this case, we want to do the aggregating. If each row represents one stop, we want to count the number rows (or stops) along a number of different categories.\nTo do so, we are going to create bar plots. With bar plots, we don’t supply the height of the bar. Instead, the height of the bar gets set to a count of each observation in a category.\n\nQuestion\n\nCreate a new worksheet called “NYPD Stops per Race, 2011”. Name the tab “by_race”.\nDrag the Race pill to Rows. Edit the aliases based on the values in the data dictionary. After this, drag the 2011.csv (Count) pill to Columns. Recall from a previous lab that this variable is a count of the all rows in the dataset. Since each row in this dataset is one stop, using this variable counts the numbers of stops per category.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Arrest or Summons per Race, 2011”. Name the tab “per_guilty”.\nDrag the Race pill to Rows. After this, drag the 2011.csv (Count) pill to Columns.\nNow we need to drag over a variable that indicates whether the individual was found guilty. …but there are actually two variables for this: Arstmade and Sumissue, and each have possible values of ‘Y’ or ‘N’. We want to combine this into one variable that return ‘Y’ if either Arstmade and Sumissue are ‘Y’ and ‘N’ otherwise. Highlight both Arstmade and Sumissue with the Cmd/Cntl key, and then click on one pill > Create > Combined Field.\nClick on the newly created Combined Field > Create Group. Change the name of the field to “Guilty”, add a group for the “N,N” value called “No”, and change the name of the remaining group to “Yes”.\n\nDrag Guilty onto the Rows field behind Race.\n\n\n\nThis tells us the total number of stops that resulted in an arrest or summons per race, but since we know that certain races are disproportionately stopped, we really want to see the percentage of stops that result in an arrest or summons per race.\nTo do this, we are going to add a Table Calculation to these plots such that each bar displays a “Percent of Total”. Adding this calculation does not change anything about the underlying data; it only changes how the data gets displayed.\n\n\n\nQuestion\n\nClick on 2011.csv (Count) in the Column field > Table Calculation > Percent of Total. Note that, since we are displaying a few different values on this plot, there are a number of different values that can serve as a denominator for the calculated percentage. We want to know the percentage deemed guilty out of all stops, so we are going to click on 2011.csv (Count) again > Compute Using > Guilty.\nFinally, right click on “No” in the plot, and then select “Hide”. Note that this locally filters the data, keeping the original data source the same.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the last exercise, we created a local filter on the data. When applying local filters, the data remains the same in the original Data Source, but we hide certain variables from view in our visualizations. This is different from applying a global filter. With a global filter, we filter the original Data Source such that only a subset of rows get considered in our analysis/visualizations.\nWhy does this difference matter? It mostly matters when we create table calculations on our data that include a denominator (e.g. Percent of Total). If we apply a global filter to such data, the denominator changes - it becomes only the data remaining after the original data source is filtered. …but if we apply a local filter to such data, the denominator remains the same because the original data source doesn’t change. The only thing that changes is our view of that data.\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Frisk per Race, 2011”. Name the tab “per_frisked”.\nRepeat the steps above to create a bar plot that shows the percentage of stops that resulted in a frisk per race. Note that you do not have to create a grouped variable this time around because you have all of the information you need about frisks in the variable Frisked.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Frisks Resulting in a Weapon Found per Race, 2011”. Name the tab “per_wpn”. Drag Frisked to the filters panel, and filter to ‘Y’ so that we are only considering stops that resulted in a frisk. Note, unlike the local filters we applied to the earlier plots by hiding certain values, this is a global filter that filters the original data source.\nRepeat the steps above to create a bar plot that shows the percentage of frisks that resulted in a weapon found per race. Note that you do have to create a grouped variable this time around as there is no existing variable for “Weapon found”. You will need to combine the variables: Pistol, Riflshot, Asltweap, Knifcuti, Machgun, Othrweap such that if any are ‘Y’ the data returns ‘Y’ and otherwise the data returns ‘N’.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Most Stops, 2011”. Name the tab “top_5_pct”. Convert Pct from a Measure to a Dimension. Drag Pct to Rows and 2011.csv (Count) columns. Drag Pct to Filters and select ‘Top’. Configure the filter to display the top 5 according to 2011.csv Count.\n\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Highest Percentage of Frisks, 2011”. Name the tab “pct_frisks”. Based on what you’ve learned, create a bar plot that shows the percentage of stops that resulted in a frisk for each precinct.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nNow let’s say that we want to analyze the documented reasons for a stop. Officers are required to have reasonable suspicion that a crime was committed, so maybe we want to analyze what their reasons for stopping were. You’ll notice that there isn’t one variable that documents the reason for the stop. This is because on that section of the UF-250 form (entitled “What Were Circumstances that Led to Stop?”), the officer is presented with series of checkboxes. The officer can select multiple boxes. Each option is its own variable in this dataset with a ‘Y’ or ‘N’ option.\nWe can’t just drag all of these variables onto the plot because Tableau will combine every ‘Y’/‘N’ option across all variables.\n\nInstead, we want to pivot these variables such that the field names will become one variable, and the values associated with them ‘Y’/‘N’ will become another variable.\n\nCreate a new worksheet called “NYPD Reason for Stops, 2011”. Name the tab “stop_reason”. Using the Cmd/Cntl button select all variables starting with Cs ... Right click on the select pills > Transform > Pivot.\nDrag Pivot Field Names onto the Rows field and 2011.csv (Count) onto the Columns field. Convert the counts to a percent of total, computed using the Pivot Field Values. Locally filter ‘N’ from the plot, using “Hide”.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful. Edit the aliases to the values under the “What Were Circumstances that Led to Stop?” on the UF-250 form.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\nPart 5: Reflection\nHow might we summarize what we just learned into a factual claim? How does the data respond to the “bad apples” narrative? What other data or analysis strategies could be engaged to respond to these counter-claims?\nNote that this data is often cited as evidence of racial profiling in policing. …but some also counter that stop and frisk policies led to the greatest reduction of crime rates in NYC’s history. They reframe racial profiling as proactive policing. Here’s one article that makes such a counter-claim.\nIn small groups, read through this article and try to identify the arguments that the author uses to counter the claims regarding racial profiling. How would you respond to their counter-arguments? What evidence could you provide in your response?"
  },
  {
    "objectID": "labs/semiotics.html",
    "href": "labs/semiotics.html",
    "title": "Data Semiotics",
    "section": "",
    "text": "Definitions are operating in the background of every statistic. When I report the number or percentage of people that play sports, I have to first define what counts as a sport and what it means for someone to be a sports player (i.e. how often they play? how long they’ve been playing?) When I report the number or percentage of green spaces in a city, I have to first define what counts as a green space.\nWe often don’t take the time to critically examine definitions. We’re pretty used to seeing definitions reported in dictionaries or reference documents - documents that we don’t tend to classify as persuasive, rhetorical, or political. …but in fact, definitions are often a site of intense social and political debate. What counts as a life in the context of abortion politics? What counts as a terrorist in the context of domestic security? These terms may have formal definitions in laws and/or dictionaries, but those definitions are rarely stable and are continuously subject to contestation. They create boundaries of inclusion/exclusion, while necessarily leaving certain issues unaddressed.\nIn today’s activity, you are going to analyze the definitions a dataset denotatively, connotatively, and deconstructively:\n\nDenotatively, we are going to reference data documentation to examine the official/encoded definitions underpinning a dataset. You are going to reflect upon how these definitions set the boundaries of what counts.\nConnotatively, we are going to examine the provenance of that definition. When has the definition changed? Who or what prompted the definition to change, and with what social consequences? How did the numbers change as a result?\nDeconstructively, we are going to consider what the definition eclipses. What social groups or social issues get overshadowed as a result of this definition?\nWe’re also going to look at the categorizations of a dataset to determine which individuals may be categorically excluded, and which groups of people are rendered residual through the data."
  },
  {
    "objectID": "labs/semiotics.html#instructions",
    "href": "labs/semiotics.html#instructions",
    "title": "Data Semiotics",
    "section": "Instructions",
    "text": "Instructions\nLast week, you worked with a dataset that offered two different definitions of poverty - the official poverty measure, and the supplemental poverty measure.\n\nPart 1: Denotative Reading\nIn your group find documentation of the official differences between these two definitions. Fill out the following table based on what you learn:\n\n\n\n\n\n\n\n\n\nOfficial Poverty Measure\nSupplemental Poverty Measure\n\n\n\n\nIn Poverty\n\n\n\n\nNot In Poverty\n\n\n\n\n\n\n\nPart 2: Connotative Reading\nIn 2019, the U.S. Office of Management and Budgeting's Chief Statistician established an Interagency Technical Working Group on Evaluating Alternative Measures of Poverty. It had been almost 25 years since the establishment of the Supplemental Poverty Measure and 50 years since the establishment of the Official Poverty Measure. The goal of the working group was to address growing concerns about the quality of survey-based data (e.g. the accuracy of what individuals report in surveys). The Committee came up with a number of ideas on how an alternative measure of poverty might be determined. The video following summarizes some of the recommendations they came up with. (We will watch just a few clips in class).\n\n\nRegulations.gov is a website where the public can review and comment upon proposed changes to federal agency regulations. On February 14, 2020, a “Request for Comment on Considerations for Additional Measures of Poverty” was posted on Regulations.gov. 193 comments were submitted in response to the recommendation.\nIn your groups, click through a number of these public comments. Take notes on the following for each:\n\nWho is making the comment, and what stakeholder group are they a part of?\nWhat stakes do they have in the way poverty gets defined?\nWhere do they stand in relation to these recommendations?\nHow do they justify their stance?\n\nAs a group, we will compare your findings in order to consider the role of social advocacy in shaping the definitions underpinning this data. We will also consider stakeholder groups that might not be represented on Regulations.gov.\n\n\nPart 3: Deconstructive Reading\nCreate a hypothetical “profiles” for two individuals that this dataset eclipses. Try and bring these individuals to life, telling us about them. Why is it that those individuals go uncounted? Indicate specific consequences that may result from be uncounted. Also indicate some benefits to uncounted in this data.\n\n\nPart 4: Analyzing Categories\nWhen working with this dataset last week, you may have been surprised regarding how race and ethnicity were subdivided in the dataset. Demographic categories used in most federal government data collection programs in the U.S. are standardized by the Office of Management and Budget. These standards were last revised in 1997, but proposals to change them were made in 2016 and generated a great deal of public commentary on Regulations.gov.\nIn your groups, check out this site, which documents how racial categorization has changed in the census since 1790. Note what surprises you the most.\nAfter this, check out what was proposed in 2016 regarding standards for collecting data on race and ethnicity, and read through some of the public comments. What were some rationales for changing the standards, and what were some rationales for maintaining the current standards? What social groups had stakes in these decisions, and how did they advocate?"
  },
  {
    "objectID": "labs/semiotics.html#other-contested-data-definitions",
    "href": "labs/semiotics.html#other-contested-data-definitions",
    "title": "Data Semiotics",
    "section": "Other contested data definitions:",
    "text": "Other contested data definitions:\n\nUnemployment\n\n\n\n\nHurricane Deaths\n\n\n\n\nDisability\n\n\n\n\nHomelessness"
  },
  {
    "objectID": "labs/lab5.html",
    "href": "labs/lab5.html",
    "title": "Lab 5: Data Fallacies",
    "section": "",
    "text": "In this lab, we will examine a series of common errors in reasoning that emerge when presenting data-based evidence or when countering data-based evidence."
  },
  {
    "objectID": "labs/lab5.html#the-dataset",
    "href": "labs/lab5.html#the-dataset",
    "title": "Lab 5: Data Fallacies",
    "section": "The Dataset",
    "text": "The Dataset\nEvery time an NYPD officer stops an individual based on “reasonable suspicion” that they committed or were about to commit a crime, the officer is required to fill out a form documenting information about the stop, including the reason for the stop, the demographics of the individual stopped, any actions taken during the stop, and any contraband found on the individual stopped. These reports get aggregated into a database that became available for public download in 2008 as a result of considerable advocacy efforts by the New York Civil Liberties Union in the wake of high-profile police shootings.\nIn the 1990s, crime reduction strategies implemented in major cities across the country demanded the production of statistics to generate evidence of policing effectiveness. With certain consequences tied to failures to demonstrate reductions in crime, the policies institutionally incentivized data manipulation - an issue colloquially referred to as “juking the stats.” Despite these data quality issues, the publication of the data in 2008 showed an incredible increase in the number of police stops over a 5-year period, and by 2011, the number of stops had increased 700% from when data collection began in 2002. 88% of the time the individuals stopped were found innocent. In the following years, the data became integral in the New York District Court case Floyd, et al. v. City of New York, et al., which ultimately ruled that stop and frisk was being carried out unconstitutionally in New York City and led to a considerable scaling back of the practice. The New York Civil Liberties Union continues to publish annual reports leveraging the data to assess the current state of discriminatory policing in NYC.\nToday, we are going to analyze 2011 stop and frisk data."
  },
  {
    "objectID": "labs/lab5.html#instructions",
    "href": "labs/lab5.html#instructions",
    "title": "Lab 5: Data Fallacies",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: Explore the data dictionary\nDownload the data dictionary here. After downloading the zip file, open the Excel file for the 2011 SQF File Spec. Check out both tabs of the spreadsheet: the first defines variables in the dataset, and the second lists the values that might appear in those variables. Note how each variable maps onto a field on the UF-250 form.\n\n\nImage from Dan Nguyen: http://blog.danwin.com/request-nypd-form-uf250/\n\n\n\nPart 2: Download the 2011 SQF Data\nDownload the 2011 SQF Data here.\n\n\nPart 3: Data Analysis\nOpen Tableau, and create a new workbook called sqf_2011. Click “Connect to Data” and the 2011.csv file. Note that this is the largest dataset we will work with this semester, and it may take time to load in Tableau.\nIn the last lab, we created a series of column plots. In that lab, we supplied a categorical variable for one axis and a numeric variable to set the height of the bar to on another axis. In that lab, we could do so because we were working with data that had already been aggregated. Each row wasn’t a death; it was a count of deaths for a particular demographic group or year.\nIn this lab, we don’t have numeric variables to set the height of the bar to. This is because we have unaggregated individual data; each row represents one stop. In this case, we want to do the aggregating. If each row represents one stop, we want to count the number rows (or stops) along a number of different categories.\nTo do so, we are going to create bar plots. With bar plots, we don’t supply the height of the bar. Instead, the height of the bar gets set to a count of each observation in a category.\n\nQuestion\n\nCreate a new worksheet called “NYPD Stops per Race, 2011”. Name the tab “by_race”.\nDrag the Race pill to Rows. Edit the aliases based on the values in the data dictionary. After this, drag the 2011.csv (Count) pill to Columns. Recall from a previous lab that this variable is a count of the all rows in the dataset. Since each row in this dataset is one stop, using this variable counts the numbers of stops per category.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Arrest or Summons per Race, 2011”. Name the tab “per_guilty”.\nDrag the Race pill to Rows. After this, drag the 2011.csv (Count) pill to Columns.\nNow we need to drag over a variable that indicates whether the individual was found guilty. …but there are actually two variables for this: Arstmade and Sumissue, and each have possible values of ‘Y’ or ‘N’. We want to combine this into one variable that return ‘Y’ if either Arstmade and Sumissue are ‘Y’ and ‘N’ otherwise. Highlight both Arstmade and Sumissue with the Cmd/Cntl key, and then click on one pill > Create > Combined Field.\nClick on the newly created Combined Field > Create Group. Change the name of the field to “Guilty”, add a group for the “N,N” value called “No”, and change the name of the remaining group to “Yes”.\n\nDrag Guilty onto the Rows field behind Race.\n\n\n\nThis tells us the total number of stops that resulted in an arrest or summons per race, but since we know that certain races are disproportionately stopped, we really want to see the percentage of stops that result in an arrest or summons per race.\nTo do this, we are going to add a Table Calculation to these plots such that each bar displays a “Percent of Total”. Adding this calculation does not change anything about the underlying data; it only changes how the data gets displayed.\n\n\n\nQuestion\n\nClick on 2011.csv (Count) in the Column field > Table Calculation > Percent of Total. Note that, since we are displaying a few different values on this plot, there are a number of different values that can serve as a denominator for the calculated percentage. We want to know the percentage deemed guilty out of all stops, so we are going to click on 2011.csv (Count) again > Compute Using > Guilty.\nFinally, right click on “No” in the plot, and then select “Hide”. Note that this locally filters the data, keeping the original data source the same.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the last exercise, we created a local filter on the data. When applying local filters, the data remains the same in the original Data Source, but we hide certain variables from view in our visualizations. This is different from applying a global filter. With a global filter, we filter the original Data Source such that only a subset of rows get considered in our analysis/visualizations.\nWhy does this difference matter? It mostly matters when we create table calculations on our data that include a denominator (e.g. Percent of Total). If we apply a global filter to such data, the denominator changes - it becomes only the data remaining after the original data source is filtered. …but if we apply a local filter to such data, the denominator remains the same because the original data source doesn’t change. The only thing that changes is our view of that data.\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Stops Resulting in Frisk per Race, 2011”. Name the tab “per_frisked”.\nRepeat the steps above to create a bar plot that shows the percentage of stops that resulted in a frisk per race. Note that you do not have to create a grouped variable this time around because you have all of the information you need about frisks in the variable Frisked.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\nQuestion\n\nCreate a new worksheet called “Percent NYPD Frisks Resulting in a Weapon Found per Race, 2011”. Name the tab “per_wpn”. Drag Frisked to the filters panel, and filter to ‘Y’ so that we are only considering stops that resulted in a frisk. Note, unlike the local filters we applied to the earlier plots by hiding certain values, this is a global filter that filters the original data source.\nRepeat the steps above to create a bar plot that shows the percentage of frisks that resulted in a weapon found per race. Note that you do have to create a grouped variable this time around as there is no existing variable for “Weapon found”. You will need to combine the variables: Pistol, Riflshot, Asltweap, Knifcuti, Machgun, Othrweap such that if any are ‘Y’ the data returns ‘Y’ and otherwise the data returns ‘N’.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Most Stops, 2011”. Name the tab “top_5_pct”. Convert Pct from a Measure to a Dimension. Drag Pct to Rows and 2011.csv (Count) columns. Drag Pct to Filters and select ‘Top’. Configure the filter to display the top 5 according to 2011.csv Count.\n\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nQuestion\n\nCreate a new worksheet called “NYPD Precincts with the Highest Percentage of Frisks, 2011”. Name the tab “pct_frisks”. Based on what you’ve learned, create a bar plot that shows the percentage of stops that resulted in a frisk for each precinct.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful.\n\n\n\nNow let’s say that we want to analyze the documented reasons for a stop. Officers are required to have reasonable suspicion that a crime was committed, so maybe we want to analyze what their reasons for stopping were. You’ll notice that there isn’t one variable that documents the reason for the stop. This is because on that section of the UF-250 form (entitled “What Were Circumstances that Led to Stop?”), the officer is presented with series of checkboxes. The officer can select multiple boxes. Each option is its own variable in this dataset with a ‘Y’ or ‘N’ option.\nWe can’t just drag all of these variables onto the plot because Tableau will combine every ‘Y’/‘N’ option across all variables.\n\nInstead, we want to pivot these variables such that the field names will become one variable, and the values associated with them ‘Y’/‘N’ will become another variable.\n\nCreate a new worksheet called “NYPD Reason for Stops, 2011”. Name the tab “stop_reason”. Using the Cmd/Cntl button select all variables starting with Cs ... Right click on the select pills > Transform > Pivot.\nDrag Pivot Field Names onto the Rows field and 2011.csv (Count) onto the Columns field. Convert the counts to a percent of total, computed using the Pivot Field Values. Locally filter ‘N’ from the plot, using “Hide”.\nSort the bars from largest to smallest, and edit the axis labels to something more meaningful. Edit the aliases to the values under the “What Were Circumstances that Led to Stop?” on the UF-250 form.\n\nHow can we summarize what we see in this plot quantitatively?\nHow might we interpret what we see in this plot?\nWhat might it be evidence of?\n\n\n\n\n\n\nPart 5: Reflection\nHow might we summarize what we just learned into a factual claim? How does this refute the “bad apples” narrative?\nNote that this data is often cited as evidence of racial profiling in policing. …but some also counter that stop and frisk policies led to the greatest reduction of crime rates in NYC’s history. They reframe racial profiling as proactive policing. Here’s one article that makes such a counter-claim.\nIn small groups, read through this article and try to identify the arguments that the author uses to counter the claims regarding racial profiling. How would you respond to their counter-arguments? What evidence could you provide in your response?"
  },
  {
    "objectID": "labs/housing.html",
    "href": "labs/housing.html",
    "title": "Housing Justice",
    "section": "",
    "text": "In this lab, you will work through a series of exercises to visualize data regarding lending practices in Chicago, IL. Through today’s exercises, you will be introduced to polygon mapping in Tableau, along with strategies for creatively filtering data."
  },
  {
    "objectID": "labs/housing.html#the-counter-claim",
    "href": "labs/housing.html#the-counter-claim",
    "title": "Housing Justice",
    "section": "The Counter-Claim",
    "text": "The Counter-Claim\nAs you read this week, banking organizations across the U.S. have countered claims that high loan denial rates amongst certain sub-populations can serve as evidence of discriminatory lending practices. They note that just looking at denial rates across race and ethnicity fails to take into consideration the reasons for denial - low incomes, high debt, poor credit histories. They argue that it is not bias to reject a loan for these reasons, even if it means rejecting individuals in certain racial and ethnic groups more than others. Their arguments focus on the merit of certain of loan applicants. Doing so ignores the histories of structural segregation that create impact who has access to wealth and credit.\nRefuting counter-claims based in meritocracy requires that we produce evidence of the legacies of structural inequity that shape people’s current access to resources and opportunities. Overall, this lab will demonstrate what we can see when we look beyond in-the-moment decision-making. It will also show how meritocracy arguments can fail when we zoom in on certain data points."
  },
  {
    "objectID": "labs/housing.html#the-dataset",
    "href": "labs/housing.html#the-dataset",
    "title": "Housing Justice",
    "section": "The Dataset",
    "text": "The Dataset\n\n\nIn order to ensure that financial institutions are in compliance with fair lending laws in the U.S. (such as the Equal Credit Opportunity Act and the Fair Housing Act), lenders are required to collect and report data on an applicant’s ethnicity, race, gender, and income when they apply for a mortgage. With the passing of the Home Mortgage Disclosure Act (HMDA) in 1975, financial institutions were at first required to report demographic information about applicants, aggregated by census tracts. The reporting of this data was largely prompted by concerns that banks were contributing to the decline of certain urban neighborhoods by denying qualified borrowers loans, as well as concerns that financial institutions were engaging in discriminatory lending practices and contributing to the redlining of neighborhoods. Growing concerns about individual-level discrimination in lending prompted the passing of the Financial Institutions Reform, Recovery, and Enforcement Act (FIRREA) of 1989, which required institutions to report demographic data (or what they call “government monitoring information”) for every applicant regardless of whether the loan was approved or denied.\nToday, we’re going to analyze 2018 HMDA representing Cook County, Illinois. We’re also going to work a bit with historic redlining maps of Chicago, published by the University of Richmond’s Digital Scholarship Lab.\nRobert K. Nelson, LaDale Winling, Richard Marciano, Nathan Connolly, et al., “Mapping Inequality,” American Panorama, ed. Robert K. Nelson and Edward L. Ayers, accessed September 3, 2023, https://dsl.richmond.edu/panorama/redlining/"
  },
  {
    "objectID": "labs/housing.html#instructions",
    "href": "labs/housing.html#instructions",
    "title": "Housing Justice",
    "section": "Instructions",
    "text": "Instructions\n\nPart 1: What’s in this dataset?\nNote that every row in the HMDA dataset is one loan application. Navigate the data documentation here in order to see what gets reported in this dataset. Jot down terms that you are unfamiliar with. We will discuss them as a class.\n\n\nPart 2: Explore the Mapping Inequality website\nExplore historic redlining maps of Chicago (published by the University of Richmond’s Digital Scholarship Lab) by navigating here. Click on different neighborhoods on the map. What do the different colors on the map mean? What were some of the reasons different neighborhoods received different ratings?\n\n\nPart 3: Download the datasets\nToday, both of the datasets that we are going to be working contain polygon geometry. What do I mean by this? Check out the map below.\n\nCC BY-SA 4.0, Link\n\nNotice how every state is a polygon? Similarly, the datasets we will be using today are designed to allow us to map polygons of different neighborhoods and census tracts in Chicago.\n\nDownload Chicago’s Historic Redlining Maps by clicking here.\nDownload 2018 HMDA data from Cook County by clicking here\n\n\n\nPart 3: Analyzing the data\nOpen Tableau, and create a new workbook called hmda_chicago. Click “Connect to Data” and the ILChicago1940.zip file as a Spatial File. In the top menu, click Data > New Data Source. Add hmda_chic_2018.geojson as a Spatial File.\nNote that to save time, I’ve already cleaned this data for you. Specifically, I swapped out all of the numeric codes in the dataset with their qualitative labels. I’ve also added geometries of the census tracts associated with each row. However, there is one data type that we will need to fix before we open our first worksheet.\n\nIn the Data Source tab, scroll to the column Combined Loan to Value Ratio and convert it to a Number (Decimal).\n\n\nQuestion\n\nCreate a worksheet in Tableau called “HOLC Maps of Chicago, IL - 1940”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Chicago. Now drag the HOLC Grade to the Color field. Edit the map colors such that A is green, B is blue, C is yellow, and D is red. Finally, add the HOLC ID to the Detail field.\nWhat do you notice about the geographies of segregation across the city?\n\n\n\nThe map that you just created used a qualitative color palette, filling polygons according to the values in a categorical variable.\nWe can also color polygons according to a numeric variable by mapping the values in that variable to a shade of a color along a gradient. When we do so, we create what are called chloropleth maps.\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Minority Population Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Cook County. Drag the Census Tract pill to the Detail field in order to identify each census tract mapped. Now drag Tract Minority Population Percentage onto the Color field.\nNote that each row in this dataset is a loan application, not a census tract. In 2018, there were many loan applications submitted in each tract. Because I’m mapping census tracts, by default, Tableau takes the sum of Tract Minority Population Percentage across every loan application in each tract. This doesn’t make sense, right? …because the value for Tract Minority Population Percentage is specific to the tract not the loan. Every loan application in that tract is going to have the same value listed in Tract Minority Population Percentage. I don’t need to sum across all applications; I just want to show the value for that tract. To do that, I’m going to convert SUM(Tract Minority Population Percentage) to an attribute by clicking on its pill in the Color field. Rename the legend title to something descriptive.\nWhat do you notice about the geographies of minority populations across the city?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “MSA Income Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above but using the Tract to Msa Income Percentage pill.\nWhat do you notice about the geographies of income inequality across the city?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Amounts of Loans Originated per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above but using the Loan Amount pill. This time, leave the aggregation as a SUM, since we want a total of the loans originated in each census tract. Finally, drag the Action Taken pill to the filter panel, and filter the plot to only include loans that were originated.\nWhat do you notice about the geographies of loan resources originated across the city?\n\n\n\nWhen we dragged Action Taken to the filters panel, we created a global filter on the data. This means that we filtered the original Data Source such that only originated loans would be considered in our analysis/visualizations. Recall that this is different from creating a local filter on data. When applying local filters, the data remains the same in the original Data Source, but we hide certain variables from view in our visualizations.\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Denial Percentage per Tract, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Geometry pill onto the Tableau canvas. This will create a map of Cook County. Drag the Census Tract pill to the Detail field in order to identify each census tract mapped. Now drag hmda_chic_2018.geojson (Count) onto the Color field. This creates a map indicating how many loan applications were submitted in each census tract in Cook County, IL.\nWe are specifically interested in where applications were denied. Drag the Action Taken pill onto the Rows field. Note how this creates 8 rows of maps - one for each action listed in that variable. Right click on each Action listed on the Tableau canvas except for “Application denied” and click “Hide”. Note that this is a local filter, not a global filter. It filters the data on our screen, but not the data source.\nRight now we have a map that shows us the total number of applications denied in each tract. …but we can’t tell if a tract having numerous denials is a result of a high denial rate or just more applications being submitted in the tract. What if we would like to see denials as a percentage of the all the applications submitted in each tract? Click on the hmda_chic_2018.geojson (Count) pill you mapped onto the Color field, and add a Quick Table Calculation > Percent of Total. We’re trying to see the percentage of denials out of all possible actions taken, so you’ll want to click on the pill again and select “Compute Using…” > Action Taken.\nWhat do you notice about the geographies of denial rates across the city?\n\n\n\nTaken together, what story can you tell about legacies of segregation in Chicago? What additional data would you need to fill in gaps in those stories?\nThese maps provide us with information about lending practices on a census tract level, but what if I wanted to examine potential discriminatory lending practices on an individual level?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Actions by Race, Cook County, IL, 2018”. Give the tab a descriptive name. Drag the Action Taken field onto the Rows field, followed by the Derived Race field. Drag the hmda_chic_2018.geojson (Count) field onto the Columns field. Convert the count to a percentage of total, such that the percentage we see is a percentage of a specific action out of all possible actions (i.e. denial rate, origination rate, etc. )\nWhat do you notice about the differences in denial rates and origination rates across racial groups?\n\n\n\nQuestion\n\nCreate a worksheet in Tableau called “Loan Application Actions by Ethnicity, Cook County, IL, 2018”. Give the tab a descriptive name. Repeat the steps above, but for Derived Ethnicity.\nWhat do you notice about the differences in denial rates and origination rates across ethnic groups?\n\n\n\nWe know income and debt to be unequally distributed along racial and ethnic lines due to histories of structural inequality. The redlining maps we recreated at the start of this lab are just one form of structural inequality that reshaped racial wealth in the 1900s. …but for a moment, for rhetorical purposes, let’s set this knowledge aside. Assuming that loan originators are just trying to play by the rules, we could assume that two individuals - one white and one black - with similar incomes, and similar debt would see similar outcomes when applying for a similar loan in the same year. Let’s test that out in our data.\n\n\n\nQuestion\n\nOn the worksheet called “Loan Application Actions by Ethnicity, Cook County, IL, 2018”, add filters for Income, Debt to Income Ratio, Combined Loan to Value Ratio. Click on each of these filters in the Filters Panel, and select “Show Filter” in order to show an interactive filter on the worksheet. Finally, drag Denial Reason 1 to the Tooltip field.\nFilter the data such that applications with similar loan to value ratios from individuals with similar incomes and similar debt-to-income ratios appear in the plot.\nWhat changes in regards to denial rates across ethnic groups do you notice?\nAs you filter, click on the bars in the graph to view the underlying full data.\n\n\nHow did the denial reasons differ across racial and ethnic groups?\nClick on each of your interactive filters and select Apply to Worksheets > Selected Worksheets. Add each filter to “Loan Application Actions by Race, Cook County, IL, 2018”. Experiment with the filters on this second worksheet and review the underlying data.\nWhat changes in regards to denial rates across racial groups do you notice?\n\n\n\n\nPart 5: Reflection\nNote that this data does not include the credit scores of applicants, so we can’t assess the role of credit history in decision-making. How might we summarize what we just learned into a factual claim? For one, we can see that historically red-lined neighborhoods in Chicago continue to be segregated and continue to have higher loan denial rates. We can also see that financial resources tend to be concentrated in areas of the city that have historically been prioritized for mortgage lending. Further, we can see that, even when factoring in income, debt, and loan amounts, denial rates are unevenly distributed across racial and ethnic groups in Chicago. Can we go so far as to claim that this data provides evidence of discriminatory lending? If not, what further data would we need to assess this? …and how should we respond to arguments from the lending industry that this data cannot show discrimination?"
  },
  {
    "objectID": "labs/fundamentals.html",
    "href": "labs/fundamentals.html",
    "title": "Fundamentals of Data",
    "section": "",
    "text": "In today’s activity, you are going to generate two rectangular datasets documenting information about the values held by students in our classroom. Your first dataset will be an individual dataset, and your second should be an aggregate dataset based on summarized information from the first."
  },
  {
    "objectID": "labs/fundamentals.html#instructions",
    "href": "labs/fundamentals.html#instructions",
    "title": "Fundamentals of Data",
    "section": "Instructions",
    "text": "Instructions\n\nAs a group discuss questions you would like to ask your classmates as part of a survey. (Please consider questions you would be comfortable answering).\n\nYou should have at least four questions, such that your final dataset will have at least one nominal categorical variable, one ordinal categorical variable, one discrete numeric variable, and one continuous numeric variable.\nThink about whether you will restrict survey-takers to particular responses.\n\nGive each of your questions a variable name. Variable names should be concise but descriptive and contain no spaces. You can use underscores for separating words (e.g. shirt_color)\nCreate a Google Form for collecting survey responses. When you are done, share the link to a Preview of the form in the random channel in Slack.\nData Collection:\n\n\nGroup 1: Respond to Groups 2 and 3\nGroup 2: Respond to Groups 3 and 4\nGroup 3: Respond to Groups 4 and 1\nGroup 4: Respond to Groups 1 and 2\n\n\nBack in your original groups, open the spreadsheet of survey responses. Discuss how a rectangular dataset was created from the individual survey responses.\nBe prepared to share your dataset with the class, characterizing 1) What is the unit of observation? 2) What are the variables/what types of variables are they?\nWe will discuss as a class how each dataset could be transformed into aggregate data."
  },
  {
    "objectID": "labs/fallacies.html",
    "href": "labs/fallacies.html",
    "title": "Data Fallacies",
    "section": "",
    "text": "In this lab, we will examine a series of common errors in reasoning that emerge when presenting data-based evidence or when countering data-based evidence. Then you will identify examples of how these errors in reasoning may emerge in your final projects.\n\n\n\n\nCherry-picking is when an analyst only considers variables that support their claims in data analysis, ignoring other relevant variables that might change the outcome.\n\n\nIn some cases, there’s no easy way to measure a certain phenomena, so an analyst relies on a series of proxy variables - or variables that are meant to stand in for that phenomena. For instance, maybe it’s hard to measure happiness (because it’s not necessarily clear what that even means), so an analyst relies on variables like access to public welfare resources and number of working hours in a week as proxies for happiness. Proxy discrimination occurs when an analyst selects variables that are assumed to be representative of what they’re trying to measure, but those variables are actually correlated with other social markers. Relying on those variables in data analysis and decision-making leads to situations where individuals are discriminated against by proxy.\nFor example, there’s been excellent critical research into an algorithm used in criminal justice settings called COMPAS. Among other things, this algorithm attempts to predict the likelihood that someone recently released from a carceral institution will commit a crime. While the algorithm does not use race in their calculations it does use variables correlated with race - such as high school drop-out rates and family histories of incarceration. In relying on these proxies, the algorithm produces results that factor in race even without explicitly including the variable. That’s proxy discrimination.\n\n\n\n\n\n\n\n\n\nSampling bias occurs when an analyst subsets their data to a sample that is unrepresentative of the broader population in an attempt to make certain claims about the broader population.\n\n\n\nThe ecological fallacy occurs when an analyst assumes that certain characteristics of a broader population can automatically be attributed to individuals in that population. In other words, this fallacy occurs when an analyst calculates population wide statistics and assumes they apply to everyone, failing to consider outliers. I like to think of this fallacy as a “failure to filter.”\n\n\n\n\n\n\nThe base rate fallacy occurs when an analyst prioritizes case-specific information over statistics when making certain judgments. It’s when we let individual instances shape our assumptions about what is generally true. I like to think of this fallacy as a “failure to aggregate.”\n\n\n\nThe flaw of averages occurs when we rely on averages (medians, means, and modes) to shape our understanding of what is generally always true. The problem is that it fails to account for differences and fluctuations that we can only see by disaggregating the data.\nHere’s a really nice video on the “flaws of averages”:\n\n\n\n\n\nSimpson’s paradox refers to a phenomenon in which a trend that appears in data reverses when we disaggregate that data.\n\n\nI recently came across an example of Simpson’s Paradox in my own research. We were investigating the percentage of carceral facilities that were “proximate”* to sites contaminated by a class of chemicals known as PFAS. We found 48% in the U.S. to be proximate. We then compared this to the percentage of hospitals that were proximate to sites contaminated by PFAS and found 56% of hospitals in the U.S. to be proximate. This suggested that there was a higher percentage of hospitals proximate to these sites than carceral institutions. However, when we disaggregated the data by whether the institution was in an urban or rural setting, the percentages were higher for both rural and urban carceral institutions than for hospitals. How did this happen? I’ll draw this out on the board to explain!\n\n\n\n\n\n\nFalse causality occurs when an analyst assumes a causal relationship between variables that they’ve only proven to be correlated. This ignores the possibility that additional confounding variables may be impacting how variables appear to correlate. For instance, let’s say I work for a municipal housing department, and I notice a spike in complaints about lack of heat and hot water in buildings following a November hurricane. At first, I assume that this is due to the hurricane. …but then I zoom out and notice that this same spike occurs every year at that time - because temperatures are dropping. We can’t assume that the hurricance caused the spike in complaints just based on their correlation. Seasonality is the confounding variable here.\nSometimes correlations are coincidental. Check out this website, which includes a number of spurious correlations.\n\n\n\n\n\n\nThe McNamara fallacy refers to instances when an analyst prioritizes numbers and statistics over meaningful and relevant qualitative information. It’s an over-reliance on metrics. The problem with this is that there are many things that can’t easily be measured. We end up only producing knowledge on those things that we can easily measure.\n\n\n\nGoodhart’s Law indicates that as soon as a measure becomes a target, it ceases to be a good measure. This is because treating numbers as targets incentives individuals to “game the system.”"
  },
  {
    "objectID": "labs/fallacies.html#instructions",
    "href": "labs/fallacies.html#instructions",
    "title": "Data Fallacies",
    "section": "Instructions",
    "text": "Instructions\nIn small groups, select five of the above errors in reasoning and discuss examples of how each might lead to specific errors of reasoning in relation to your data. Narrow your conversation down to the two most compelling examples, and see if you can produce data visualizations in Tableau that are demonstrative of these errors in reasoning."
  },
  {
    "objectID": "slides/Day1-Intro.html#exercise-imaginary-scenario",
    "href": "slides/Day1-Intro.html#exercise-imaginary-scenario",
    "title": "Day One: Introductions",
    "section": "Exercise: Imaginary Scenario",
    "text": "Exercise: Imaginary Scenario\n\n\n\nYou just completed your first semester at Smith College and are home for a break. You run into an old peer from high school who proceeds to tell you that they don’t believe women’s colleges should exist because it excludes the male viewpoint and discriminates against men who wish to attend the school.\n\n\n\nWith your neighbor, discuss what data you could present to respond to this individual.\nWhat presumptions are made in the individual’s statement?\nWhy would the data you present offer a compelling response?"
  }
]